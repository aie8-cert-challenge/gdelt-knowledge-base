user_input,retrieved_contexts,response,reference
How is JSON related to the GDELT Global Knowledge Graph (GKG) data format and what considerations should a data scientist keep in mind when working with it?,"['THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', '[23, 28].\nThroughout this work we use the GDELT dataset as a case study.\nGDELT is a massive collection of\nnews reports that provide a real-time computational record of global events that is published every 15\nminutes. It aggregates information from various news sources, blogs, and social media platforms to construct\na large collection of data including information on people, organizations, locations, themes, and emotions.\nEssentially, GDELT offers a snapshot of the world’s collective events, enabling researchers and analysts to\nexplore complex patterns and relationships within global society. By analyzing this data, it’s possible to\nidentify emerging trends, assess risks, understand public sentiment, and track the evolution of various issues\nover time. The applications of GDELT are diverse and far-reaching. Some of the most common use cases\nincluding event monitoring [16, 17, 29], risk assessment and prediction [6, 19, 20, 24, 26, 30], and social\nscience research [2, 3, 4, 12].\nGDELT describes its structure as a Global Knowledge Graph (GKG, specifically, we use the the Global\nKnowledge Graph edition 2 (GKG2) of GDELT). But in fact GDELT-GKG2 is implemented as multiple\nlinked tables recording information about the relationship between articles and events, and thus effectively\nhas the structure of a relational database. Another important contribution of this paper is to actually realize\nGKG2 properly in the mathematical form of a KG, effectively a graph database, derived from and consistent\nwith its native relational database form. To facilitate this effort, we have identified a lightweight ontology\nfor GDELT in the form of its graph schema, realizing its relational database schema in a KG form.\nUsing the KG that we construct from the GDELT-GKG2 dataset, we provide a case study to explore the\nutility of LLM-based tools to extract information and confirm that the KG can be used for question-answering\nin cases where traditional RAG fails. As part of our analysis, we compare to KGs produced from processing\nvarious news articles with an LLM, prompting it to try and adhere to a reduced version of the same ontology.\nThe current state of neurosymbolic work is noted for the plethora of experimental architectures available.\nWhile details are explicated below in Section 3.2, we preview ours in Figure 1, including the five method-\nological pathways which are quantitatively compared: 1) graph queries on the KG (called the DKG) derived\n“directly” from GKG2; 2) use of G-Retriever2 [7] against the same DKG; 3) RAG against a vector store\nrepresentation of GKG2; 4) G-Retriever against a second KG (called the LKG) derived from using Llamain-\ndex3 [1] against the GDELT source articles; and 5) GraphRAG4 Q&A deployed against a third KG (called\nGRKG) using Microsoft’s open-source GraphRAG package with default configuration parameters.\nFigure 1: Pipeline of different experiments ran to analyze the GDELT database using an LLM.\n2https://github.com/XiaoxinHe/G-Retriever\n3https://www.llamaindex.ai/\n4https://microsoft.github.io/graphrag/\n2', '2\nConstructing a Knowledge Graph for GDELT\nAs previously mentioned, while the GDELT-GKG2 dataset is not actually natively in the form of a knowledge\ngraph, it is advertised and frequently cited as being one. We believe that we are making a distinct contribution\nto the research community by converting the very popular GKG2 database into a proper KG.\nGKG2 is natively a database of three related tables:\n• expert.csv captures event information;\n• GKG.csv captures article information; and\n• mentions.csv relates which articles mention which events.\nFigure 2: GDELT GKG 2.0 schema relating articles (GKG), mentions, and events (Export).\nThe database schema for these three CSV files is shown in Fig. 2 (see also [9]). The key characteristics of\nthis database relational schema should be interpreted as follows:\n• The three tables are color-coded by Events (green), Mentions (pink), and Articles (blue).\n• The single table of Events is shown in multiple green sub-tables, simply for clarity and convenience to\nlayout a long record structure.\n• Single-headed arrows represent one-to-many relationships between the tables. Specifically:\n– Each Event maps to multiple Mentions via the shared GLOBALEVENTID field.\n– Each Article maps to multiple Mentions via the DocumentIdentifer field on the Article side\nmatching to the MentionIdentifier field on the Mention side.\n• In this way, the Mentions table acts as a “pairs file” recording a many-many relation between Events\nand Articles: each event can be mentioned in multiple articles, and dually each article can men-\ntion many events. Each Article also has both a unique identifier through the GKGRECORDID or the\nDocumentIdentifer fields, since each row in the GKG data represents a single article.\n3', 'Graph Query\non DKG\nG-Retriever\non DKG\nRAG using\nVector Store\nG-Retriever\non LKG\nGraphRAG Q&A\non GRKG\nWhat is the name of\nthe Bridge that\ncollapsed and what\nriver was it on?\nThe Francis Scott Key\nBridge and it was on\nthe Patapsco River\nin Maryland.\nThe bridge is located\nin Sri Lanka.\nHowever, there is no\nexplicit mention of\nthe river’s name.\nThe Francis Scott Key\nBridge collapsed into\nthe Patapsco River.\nThe bridge that\ncollapsed spanned\nover the Patapsco\nriver.\nThe Francis Scott Key\nBridge which spans the\nthe Patapsco River.\nWhat is the name of\nthe ship that collided\nwith the baltimore\nbridge?\nThe name of the ship\nis not provided.\nHowever, the ship is a\ncontainer ship and\nSingapore-flagged.\nThere is no mention\nof the name of the\nship that collided\nwith the bridge.\nThe name of the ship\nthat collided with the\nBaltimore bridge is\nthe Dali.\nThe name of the\nship that collided\nwith the Baltimore\nbridge is Maersk.\nThe ship that collided\nwith the Baltimore\nbridge is the Dali.\nHow many articles\ndid CNN publish\nabout the Baltimore\nbridge collapse?\nCNN published 5\narticles about the\nBaltimore bridge\ncollapse.\nCNN published a\ntotal of 2 articles\nabout the Baltimore\nbridge collapse.\nCNN published three\narticles about the\nBaltimore bridge\ncollapse.\nThere is only one\narticle published by\nCNN about the\nBaltimore bridge\ncollapse.\nCNN published at\nleast two articles\nabout the Baltimore\nbridge collapse.\nOn what date did\nthe Baltimore\nBridge collapse?\nThe Baltimore Bridge\ncollapsed on\nMarch 26, 2024.\nI cannot directly\nanswer that question\nbased on the given\ndata.\nThe Baltimore Bridge\ncollapsed on\nMarch 26, 2024.\nThe Baltimore Bridge\ncollapsed at 1:20 a.m.\nThe Baltimore Bridge\ncollapsed on\nMarch 26, 2024.\nWho is\nBrandon Scott?\nBrandon Scott is a\nperson mentioned in\nseveral news articles\nrelated to the collapse\nof the Francis Scott\nKey Bridge.\nBrandon Scott is\nthe Mayor of\nBaltimore.\nBrandon Scott is\nthe mayor of\nBaltimore, Maryland.\nBrandon Scott is not\nmentioned in the\ngiven data.\nBrandon Scott is\nthe mayor of\nBaltimore, Maryland.\nWho is\nNiki Fennoy?\nNiki Fennoy is a\nperson mentioned in\nvarious news articles\nrelated to the collapse\nof the Francis Scott\nKey Bridge.\nThe article from\nthepeninsular-\n-qatar.com\nmentions Niki\nFennoy.\nI don’t know. Niki\nFennoy is not menti-\n-oned in the provided\ncontext.\nNiki Fennoy is not\npresent in the\ngiven data.\nNiki Fennoy is a\ncity police spokesman.\nWhat are the top\nthemes present in\nthe data?\nMARITIME INCIDENT\nMARITIME\nMANMADE DISASTER\nTAX FNCACT\nWB 137 WATER.\nMARITIME INCIDENT\nCRISIS\nTAX\nNEWS\nETHNICITY.\nI don’t have enough\ninformation from\nto determine specific\nthe themes present\nin the data.\nEVENTS AND THEIR\nRELATIONSHIPS,\nLOCATIONS,\nORGANIZATIONS,\nVESSELS.\nNEWS AND UPDATES\nBRIDGE COLLAPSE\nCONSTRUCTION CREW\nSEARCH AND RESCUE\nCOMMUNITY REPORT.\nTable 1: Table of example questions and answers highlighting deficiencies in each method for analyzing the\nGDELT data. Table highlight color legend: Green is a correct answer, yellow is a partially correct answer,\nred is an incorrect answer, and grey is for no answer provided.\nOur prompt was then constructed as the following: “Please answer the question given the following infor-\nmation:” with the list of edge sentences appended to the end.\nSolutions based on vector stores, GraphRAG, and direct graph queries on the DKG offer the best results\nfor question answering. With direct graph queries, we can answer high-level and other types of questions\nthat need us to aggregate information across the dataset. For example, we can easily extract information\nabout recurrent themes or about a particular news source. While GraphRAG also provides functionality\nto answer high-level questions, we found that its performance lacked in this respect. It performed well on\nfine-grained questions. A vector store performed similarly well on these fine-grained questions that can be\nanswered by a small number of excerpts from the source articles. Notably, the second column suggests that\nthe automated search functionalities provided in G-retriever are often unable to retrieve a subgraph that can\nbe used to provide an accurate answer. The problem gets worse when we use the KG created by LlamaIndex\nas our knowledge base, which is unable to suitably answer any question that we posed. These issues may\npartially be due to the out-of-box application of the G-retriever system and careful fine-tuning may improve\nperformance. Regardless, we see the retained value in directly probing our data with hand-crafted queries\nand infer that further developments are needed for these automated information extraction systems to match\nthe baseline performance on questions that require reasoning across the entire corpus.\nBy combining the results of the direct graph queries on the DKG with those of GraphRAG and standard\nRAG, we can provide suitable answers to the all of the presented questions. On one hand, we see that\nthe DKG can provide better responses to high-level or aggregate questions about our data. Conversely, the\nvector store and GRKG can be used to identify local information in the documents that might be missing\nin the DKG.\nRegarding popular subjects, direct prompting of the LLM without dealing with knowledge graphs or vector\n8', 'of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', 'stores reveals that the LLM independently recognizes Brandon Scott as the mayor of Baltimore. For all\nother questions, the language model cannot answer the posed questions by itself due to the recency of the\nbridge collapse.\nTo quantitatively evaluate the quality of the answers generated by our different question-answering methods,\nwe require a set of ground truth answers for the questions posed. Table 2 presents these manually curated\nground truth answers, representing the expected correct responses for each question used in our evalua-\ntion. These ground truth answers serve as the benchmark against which the performance of each system is\nmeasured.\nQuestion\nGround Truth\nWhat is the name of the Bridge that collapsed and\nwhat river was it on?\nThe Francis Scott Key Bridge on the Patapsco River.\nWhat is the name of the ship that collided with the\nbaltimore bridge?\nThe ship was named the Dali.\nHow many articles did CNN publish about the Bal-\ntimore bridge collapse?\nCNN published 5 articles.\nOn what date did the Baltimore Bridge collapse?\nThe collapse occurred on March 26, 2024.\nWho is Brandon Scott?\nBrandon Scott is the Mayor of Baltimore.\nWho is Niki Fennoy?\nNiki Fennoy is a city police spokesman.\nWhat are the top themes present in the data?\nThemes include maritime incidents, manmade disaster, and\nwater-related topics.\nTable 2: Ground Truth Answers for the Baltimore Bridge Collapse Questions\nTo further validate our qualitative findings, Figure 5 presents a quantitative comparison of the semantic\nsimilarity of answers generated by the five different methods when querying the GDELT dataset related\nto the Baltimore bridge collapse. We compute the quality of the result by calculating cosine similarity5, a\nmeasure of the similarity between the embeddings of the predicted answer and the ground truth, with higher\nvalues indicating greater accuracy. The box plots illustrate the distribution of these similarity scores for each\nmethod: Graph Query on DKG, G-Retriever on DKG, RAG using Vector Store, G-Retriever on LKG, and\nGraphRAG Q&A on GRKG. As our qualitative analysis suggested, methods leveraging direct graph queries\non the DKG, standard RAG with a vector store, and GraphRAG Q&A on the GRKG generally exhibit the\nhighest cosine similarity scores, providing quantitative evidence for their superior performance in generating\naccurate and relevant answers compared to the G-Retriever, especially with the LKG. This visualization\nquantitatively confirms the trends observed in the qualitative evaluation presented in Table 1.\n4\nConclusion\nThis work has taken the GDELT GKG database and introduced an ontology to create a knowledge graph\nwith rich structure. We found that while the large KG produced by the GDELT-GKG2 database has rich\ninformation for question-answering, the ad hoc techniques for graph exploration deem further investigation\nfor reliable use. That said, the information stored in the KG produced here is not without flaws, and we\nexpect the example studied here to be useful for the broader synergy between KGs and LLMs as addressed\nby others [18]. While the KGs produced using LlamaIndex captured a summary of the events surrounding\nthe Baltimore bridge collapse, the quality of the resulting structure was not suitable for question-answering.\nThose techniques incorporated into the GraphRAG package did considerably better, but there is room for\nimprovement for answering global questions, resolving duplicate entities, and incorporating ontologically-\nguided relation extraction. We believe the incorporation of the ontology into the relation extraction will\nhave the benefit of allowing tools such as GraphRAG to better answer quantitative questions that only the\nontology based KG pipeline (DKG) was able to answer (e.g., the number of articles published on a topic).\nLarge language models continue to be adapted to solve problems across domains, and the case study on the\nKG built here presents much opportunity for future development. In particular, the debate around using\n5The\nsemantic\nembeddings\nused\nto\ncalculate\nthe\ncosine\nsimilarity\nwere\ngenerated\nusing\nthe\nsentence-transformers/all-MiniLM-L6-v2 model from the Sentence Transformers library.\n9', 'we have five pipelines on how we implement an LLM for talking to GDELT. These pipelines are shown\nin Fig. 1, where in each case, we use an LLM to produce a final answer from the information obtained\nfrom each retrieval method. We note that this final processing is done with models with 7-8B parameters.\nWith the GraphRAG pipeline we use Llama-3-8B [22] for question answering, and in all other cases we use\nMistral-7B [10] in tandem with the E5-large-v2 [25] embedding model. In order, left to right:\n1. Extract knowledge using direct graph queries to probe the DKG. This method requires an analyst to\nconvert a natural language question into a suitable graph query. Consistent with other techniques, we\nthen use an LLM to interpret and repackage the retrieved information.\n2. Use G-retriever to automatically fetch a subgraph of the GDELT Knowledge Graph from a natural\nlanguage question. This subgraph retrieval algorithm requires vectorizing the nodes and edges of the\nknowledge graph using a language embedding model. Once retrieved, the subgraph is fed into an LLM\nfor interpretation.\n3. Construct a knowledge graph by parsing full-text documents (scraped from GDELT URLs) with an\nLLM and LlamaIndex’s functionality. We then proceed as in (2).\n4. Create a Vector Store using the text Corpus and ask questions in a typical RAG setting. This in-\nvolves using a language embedding model to vectorize text articles (after splitting them into 500-token\nchunks). Given a question, we use the same embedding model to vectorize it and, using the Euclidean\nmetric to identify nearby vectors, extract the most similar text snippets. The original question and its\nassociated context are then fed into an LLM to process an answer.\n5. Build a knowledge graph as in (3), using the GraphRAG ecosystem. We also use the provided question-\nanswering capabilities of the GraphRAG package.\nWe note that it is typically unnecessary to use an LLM in method (1) and the answer can often be inferred\nafter seeing the raw output of the graph query. In this case, the LLM effectively repackages the result of the\ngraph query in an expected way. As such, we view this first method as a ‘ground-truth’ on the constructed\nKG. Tautologically, if the DKG can be used to answer a question, then a suitable graph query is able to\nextract the correct answer. Conversely, if the KG cannot be used to answer a given question, then a suitable\ngraph query can prove that the answer cannot be found in the KG.\nIt is worth noting why we only employ graph queries on the DKG and not those constructed using LlamaIndex\nor GraphRAG. As noted in our empirical observations of the LLM-produced knowledge graphs, these graphs\nhave far less structure than GDELT itself. This lack of defined structure makes it difficult to form useful\nand interesting graph queries.\n3.3\nResults\nTable 1 shows a sample of questions that were passed through each of the five pipelines from Fig. 1. Exact\nqueries to the GDELT knowledge graph were generated by searching for keywords in the edge triples com-\nprising the knowledge graph. Specifically, we searched for keywords in these triples by converting each triple\nto a sentence (stored as a string) and searching therein. We then used the edge induced subgraph from the\nedge sentences where keywords were found. The following keywords were used for each question:\n• What is the name of the Bridge that collapsed and what river was it on?: Bridge, Collapse, River\n• What is the name of the ship that collided with the baltimore bridge?: Ship, Collide, Baltimore, Bridge\n• How many articles did CNN published about the baltimore bridge collapse?: CNN, Baltimore, Bridge,\nCollapse\n• On what date did the Baltimore Bridge collapse?: Date, Baltimore, Bridge, Collapse\n• Who is Brandon Scott?: Brandon Scott\n• Who is Niki Fennoy?: Niki Fennoy\n• What are the top themes present in the data?: Has Theme\n7', 'Figure 3: GDELT GKG 2.0 ontology relating articles and events..\nMethods to automatically determine the graphical form of a relational database are widely known [21]. Most\nnaturally, consider a table T with m rows T[j], 1 ≤j ≤m and n columns T.i, 1 ≤i ≤n. Then each of the\nm rows T[j] is represented as a node in one meta-class labeled by the primary keys. This node then has n\noutgoing edges, each connecting to a node in another meta-class representing the field value T[j].i, and labeled\nby the column name. The resulting “star” bipartite graphs are then linked over shared values, including\nacross multiple tables. This method straightforwardly produces a graph schema consistent with a given\nRDB, which may or may not be of sufficient complexity to warrant the lofty description of “ontology”. In\nour case, such a straightforward approach is mostly warranted, although as we will see additional constraints\nin the event table will argue for a somewhat more specific and idosyncratic graph structure.\nAfter understanding the GDELT database schema, we developed a capability to convert (portions of) the\nGDELT database to a KG using an ontology as a graph typing schema, derived from the above relational\nschema. This is shown in Fig. 3, to be interpreted as follows:\n• Nodes in the ontology indicate the types of nodes possible in the KG.\n• Nodes are color-coded to indicate their source relational table.\n• Fields in ⟨angled brackets⟩indicate the field name in the schema.\n4']","JSON is not the native data format for the GDELT Global Knowledge Graph (GKG) data; instead, the GKG is provided in a tab-delimited CSV format optimized for fast scanning and parallelized streaming. The GKG format is designed to handle extremely large and complex datasets efficiently, which is why encoding it in JSON, XML, RDF, or similar formats is avoided due to the significant increase in on-disk footprint and complexity that would result.

However, JSON is related to the GKG data format in the sense that users who require the GKG data in JSON (or other structured formats like XML or RDF) can convert the native CSV format into JSON using scripting languages such as Python or PERL. This conversion is not provided out-of-the-box but is feasible through custom preprocessing scripts.

### Key considerations for data scientists working with GKG data and JSON:

1. **Native Format and Conversion**:  
   - The GKG is natively distributed as tab-delimited CSV files, not JSON.  
   - Converting to JSON requires additional preprocessing and scripting skills (e.g., Python or PERL).  
   - Such conversion may increase file size and processing time due to the verbose nature of JSON compared to CSV.

2. **Complexity and Size**:  
   - The GKG dataset is very large and complex, containing multiple linked tables (Events, Mentions, Articles) with many fields.  
   - JSON’s verbosity can make handling and storing the data more resource-intensive.

3. **Data Structure and Relationships**:  
   - The GKG data represents a relational database schema with one-to-many and many-to-many relationships (e.g., Events linked to Mentions, Mentions linked to Articles).  
   - When converting to JSON, careful structuring is needed to preserve these relationships, possibly requiring nested objects or arrays.

4. **Preprocessing Requirements**:  
   - Users typically need advanced text processing and scripting skills to parse, extract, and transform the raw GKG CSV data into formats suitable for their analysis tools.  
   - Direct import into statistical packages is less straightforward than with the primary GDELT event stream.

5. **Use Case Flexibility**:  
   - The raw CSV format is designed to be a flexible base that can be transformed into various refined formats, including JSON, depending on the user’s analytic needs.  
   - This flexibility allows users to tailor the data structure to their specific software or analysis pipelines.

6. **Performance Considerations**:  
   - The tab-delimited CSV format supports highly optimized, fully parallelized streamed parsing, which is beneficial for processing large-scale data efficiently.  
   - JSON parsing might be slower and more memory-intensive, which is a critical consideration for large datasets like GKG.

### Summary

- **JSON is not the native format of GDELT GKG data; the data is provided as tab-delimited CSV files for efficiency.**  
- **Data scientists must preprocess and convert the CSV data to JSON if needed, using scripting languages.**  
- **Conversion to JSON increases data size and complexity, so careful consideration of performance and data structure is necessary.**  
- **Advanced scripting and text processing skills are essential to work effectively with GKG data, especially when transforming it into JSON or other formats.**","The GDELT Global Knowledge Graph (GKG) is primarily available in a tab-delimited CSV format rather than JSON due to the complexity and size of encoding it in JSON, XML, RDF, or other file formats, which significantly increases the on-disk footprint. However, users who require the GKG data in JSON or other formats can write scripts in PERL, Python, or similar languages to translate the CSV format into JSON. Working with the GKG data requires advanced text processing and scripting skills to preprocess and reformat the raw output for statistical packages and complex analytic needs."
Wht is GDELT Translingual?,"['adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening \nentirely new analytic opportunities.  Some of the most significant changes: \n \n\uf0b7 \nRealtime Measurement of 2,300 Emotions and Themes.  The GDELT Global Content Analysis \nMeasures (GCAM) module represents what we believe is the largest deployment of sentiment \nanalysis in the world: bringing together 24 emotional measurement packages that together \nassess more than 2,300 emotions and themes from every article in realtime, multilingual \ndimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, \nFrench, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and \nUrdu).  GCAM is designed to enable unparalleled assessment of the emotional undercurrents \nand reaction at a planetary scale by bringing together an incredible array of dimensions, from \nLIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”. \n\uf0b7 \nRealtime Translation of 65 Languages.  GDELT 2.0 brings with it the public debut of GDELT \nTranslingual, representing what we believe is the largest realtime streaming news machine \ntranslation deployment in the world: all global news that GDELT monitors in 65 languages, \nrepresenting 98.4% of its daily non-English monitoring volume, is translated in realtime into \nEnglish for processing through the entire GDELT Event and GKG/GCAM pipelines.  GDELT \nTranslingual is designed to allow GDELT to monitor the entire planet at full volume, creating the \nvery first glimpses of a world without language barriers.  The GKG system now processes every \nnews report monitored by GDELT across these 65 languages, making it possible to trace people, \norganizations, locations, themes, and emotions across languages and media systems. \n\uf0b7 \nRelevant Imagery, Videos, and Social Embeds.  A large fraction of the world’s news outlets now \nspecify a hand-selected image for each article to appear when it is shared via social media that \nrepresents the core focus of the article.  GDELT identifies this imagery in a wide array of formats \nincluding Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats.  In addition, \nGDELT also uses a set of highly specialized algorithms to analyze the article content itself to \nidentify inline imagery of high likely relevance to the story, along with videos and embedded \nsocial media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is \ncompiled.  This makes it possible to gain a unique ground-level view into emerging situations \nanywhere in the world, even in those areas with very little social media penetration, and to act \nas a kind of curated list of social posts in those areas with strong social use. \n\uf0b7 \nQuotes, Names, and Amounts.  The world’s news contains a wealth of information on food \nprices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable \nitem.  GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to \noffer numeric context to global events.  In parallel, a new Names engine augments the existing \nPerson and Organization names engines by identifying an array of other kinds of proper names, \nsuch as named events (Orange Revolution / Umbrella Movement), occurrences like the World \nCup, named dates like Holocaust Remembrance Day, on through named legislation like Iran \nNuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative.  Finally, \nGDELT also identifies attributable quotes from each article, making it possible to see the \nevolving language used by political leadership across the world. \n\uf0b7 \nDate Mentions.  We’ve heard from many of you the desire to encode the list of date references \nfound in news articles and documents in order to identify repeating mentions of specific dates \nas possible “anniversary violence” indicators.  All day, month, and year dates are now extracted \nfrom each document. \n\uf0b7 \nProximity Context.  Perhaps the greatest change to the overall format from version 1.0 is the \nintroduction of the new Proximity Context capability.  The GKG records an enormously rich array', 'THE GDELT EVENT DATABASE \nDATA FORMAT CODEBOOK V2.0 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook provides a quick overview of the fields in the GDELT Event file format and their \ndescriptions.  GDELT Event records are stored in an expanded version of the dyadic CAMEO format, \ncapturing two actors and the action performed by Actor1 upon Actor2.  A wide array of variables break \nout the raw CAMEO actor codes into their respective fields to make it easier to interact with the data, \nthe Action codes are broken out into their hierarchy, the Goldstein ranking score is provided, a unique \narray of georeferencing fields offer estimated landmark-centroid-level geographic positioning of both \nactors and the location of the action, and a new “Mentions” table records the network trajectory of the \nstory of each event “in flight” through the global media system. \n \nAt present, only records from February 19, 2015 onwards are available in the GDELT 2.0 file format, \nhowever in late Spring 2015 the entire historical backfile back to 1979 will be released in the GDELT 2.0 \nformat.  The   Records are stored one per line, separated by a newline (\\n) and are tab-delimited (note \nthat files have a “.csv” extension, but are actually tab-delimited).   \n \nWith the release of GDELT 2.0, the daily GDELT 1.0 Event files will still be generated each morning at \nleast through the end of Spring 2015 to enable existing applications to continue to function without \nmodification.  Please note that at present, since GDELT 2.0 files are only available for events beginning \nFebruary 19, 2015, you will need to use GDELT 1.0 to examine longitudinal patterns (since it stretches \nback to January 1, 1979) and use GDELT 2.0 moving forward for realtime events. \n  \nThere are now two data tables created every 15 minutes for the GDELT Event dataset.  The first is the \ntraditional Event table.  This table is largely identical to the GDELT 1.0 format, but does have several \nchanges as noted below.  In addition to the Event table there is now a new Mentions table that records \nall mentions of each event.  As an event is mentioned across multiple news reports, each of those \nmentions is recorded in the Mentions table, along with several key indicators about that mention, \nincluding the location within the article where the mention appeared (in the lead paragraph versus \nbeing buried at the bottom) and the “confidence” of the algorithms in their identification of the event \nfrom that specific news report.  The Confidence measure is a new feature in GDELT 2.0 that makes it \npossible to adjust the sensitivity of GDELT towards specific use cases.  Those wishing to find the earliest \nglimmers of breaking events or reports of very small-bore events that tend to only appear as part of \nperiod “round up” reports, can use the entire event stream, while those wishing to find only the largest \nevents with strongly detailed descriptions, can filter the Event stream to find only those events with the \nhighest Confidence measures.  This allows the GDELT Event stream to be dynamically filtered for each \nindividual use case (learn more about the Confidence measure below).  It also makes it possible to \nidentify the “best” news report to return for a given event (filtering all mentions of an event for those \nwith the highest Confidence scores, most prominent positioning within the article, and/or in a specific \nsource language – such as Arabic coverage of a protest versus English coverage of that protest).', 'offsets of approximately where in the document they were found.  Its primary role is to allow \nfor rapid numeric assessment of evolving situations (such as mentions of everything from the \nnumber of affected households to the estimated dollar amount of damage to the number of \nrelief trucks and troops being sent into the area, to the price of food and medicine in the \naffected zone) and general assessment of geographies and topics.  Both textual and numeric \nformats are supported (“twenty-five trucks”, “two million displaced civilians”, “hundreds of \nmillions of dollars”, “$1.25 billion was spent”, “75 trucks were dispatched”, “1,345 houses were \naffected”, “we spent $25m on it”, etc).  At this time, percentages are not supported due to the \nlarge amount of additional document context required for meaningful deciphering (“reduced by \n45%” is meaningless without understanding what was reduced and whether the reduction was \ngood or bad, often requiring looking across the entire enclosing paragraph for context).  This \nfield is designed to be maximally inclusive and in cases of ambiguity, to err on the side of \ninclusion of an amount even if the object of the amount is more difficult to decipher. \no Amount.  This is the precise numeric value of the amount.  Embedded commas are \nremoved (“1,345,123” becomes 1345123), but decimal numbers are left as is (thus this \nfield can range from a floating point number to a “long long” integer).  Numbers in \ntextual or mixed numeric-textual format (“such as “2m” or “two million” or “tens of \nmillions”) are converted to numeric digit representation. \no Object.  This is the object that the amount is of or refers to.  Thus, “20,000 combat \nsoldiers” will result in “20000” in the Amount field and “combat soldiers” in this field. \no Offset.  This is the character offset of the quoted statement within the document, \nindicating approximately where it was found in the body.  This can be used to associate \nthe date with the entries from other “V2ENHANCED” fields that appeared in closest \nproximity to it. \n\uf0b7 \nV2.1TRANSLATIONINFO.  (semicolon-delimited fields) This field is used to record provenance \ninformation for machine translated documents indicating the original source language and the \ncitation of the translation system used to translate the document for processing.  It will be blank \nfor documents originally in English.  At this time the field will also be blank for documents \ntranslated by a human translator and provided to GDELT in English (such as BBC Monitoring \nmaterials) – in future this field may be expanded to include information on human translation \npipelines, but at present it only captures information on machine translated materials.  An \nexample of the contents of this field might be “srclc:fra; eng:Moses 2.1.1 / MosesCore Europarl \nfr-en / GT-FRA 1.0”. \no SRCLC. This is the Source Language Code, representing the three-letter ISO639-2 code of \nthe language of the original source material.   \no ENG.  This is a textual citation string that indicates the engine(s) and model(s) used to \ntranslate the text.  The format of this field will vary across engines and over time and no \nexpectations should be made on the ordering or formatting of this field.  In the example \nabove, the string “Moses 2.1.1 / MosesCore Europarl fr-en / GT-FRA 1.0” indicates that \nthe document was translated using version 2.1.1 of the Moses 9 SMT platform, using the \n“MosesCore Europarl fr-en” translation and language models, with the final translation \nenhanced via GDELT Translingual’s own version 1.0 French translation and language \nmodels.  A value of “GT-ARA 1.0” indicates that GDELT Translingual’s version 1.0 Arabic \ntranslation and language models were the sole resources used for translation.  \nAdditional language systems used in the translation pipeline such as word segmentation \nsystems are also captured in this field such that a value of “GT-ZHO 1.0 / Stanford PKU” \n                                                          \n9 http://www.statmt.org/moses/', 'the MentionIdentifier field above to merge the Mentions table with the GKG table to access the \ncomplete set of 2,300 emotions and themes from the GCAM system.    \n\uf0b7 \nMentionDocTranslationInfo.  (string)  This field is internally delimited by semicolons and is used \nto record provenance information for machine translated documents indicating the original \nsource language and the citation of the translation system used to translate the document for \nprocessing.  It will be blank for documents originally in English.  At this time the field will also be \nblank for documents translated by a human translator and provided to GDELT in English (such as \nBBC Monitoring materials) – in future this field may be expanded to include information on \nhuman translation pipelines, but at present it only captures information on machine translated \nmaterials.  An example of the contents of this field might be “srclc:fra; eng:Moses 2.1.1 / \nMosesCore Europarl fr-en / GT-FRA 1.0”.  NOTE:  Machine translation is often not as accurate as \nhuman translation and users requiring the highest possible confidence levels may wish to \nexclude events whose only mentions are in translated reports, while those needing the highest-\npossible coverage of the non-Western world will find that these events often offer the earliest \nglimmers of breaking events or smaller-bore events of less interest to Western media.   \no SRCLC. This is the Source Language Code, representing the three-letter ISO639-2 code of \nthe language of the original source material.   \no ENG.  This is a textual citation string that indicates the engine(s) and model(s) used to \ntranslate the text.  The format of this field will vary across engines and over time and no \nexpectations should be made on the ordering or formatting of this field.  In the example \nabove, the string “Moses 2.1.1 / MosesCore Europarl fr-en / GT-FRA 1.0” indicates that \nthe document was translated using version 2.1.1 of the Moses 7 SMT platform, using the \n“MosesCore Europarl fr-en” translation and language models, with the final translation \nenhanced via GDELT Translingual’s own version 1.0 French translation and language \nmodels.  A value of “GT-ARA 1.0” indicates that GDELT Translingual’s version 1.0 Arabic \ntranslation and language models were the sole resources used for translation.  \nAdditional language systems used in the translation pipeline such as word segmentation \nsystems are also captured in this field such that a value of “GT-ZHO 1.0 / Stanford PKU” \nindicates that the Stanford Chinese Word Segmenter 8 was used to segment the text \ninto individual words and sentences, which were then translated by GDELT \nTranslingual’s own version 1.0 Chinese (Traditional or Simplified) translation and \nlanguage models. \n\uf0b7 \nExtras.  (string)  This field is currently blank, but is reserved for future use to encode special \nadditional measurements for selected material. \n \n \n \n \n \n                                                          \n7 http://www.statmt.org/moses/ \n \n8 http://nlp.stanford.edu/software/segmenter.shtml', '[23, 28].\nThroughout this work we use the GDELT dataset as a case study.\nGDELT is a massive collection of\nnews reports that provide a real-time computational record of global events that is published every 15\nminutes. It aggregates information from various news sources, blogs, and social media platforms to construct\na large collection of data including information on people, organizations, locations, themes, and emotions.\nEssentially, GDELT offers a snapshot of the world’s collective events, enabling researchers and analysts to\nexplore complex patterns and relationships within global society. By analyzing this data, it’s possible to\nidentify emerging trends, assess risks, understand public sentiment, and track the evolution of various issues\nover time. The applications of GDELT are diverse and far-reaching. Some of the most common use cases\nincluding event monitoring [16, 17, 29], risk assessment and prediction [6, 19, 20, 24, 26, 30], and social\nscience research [2, 3, 4, 12].\nGDELT describes its structure as a Global Knowledge Graph (GKG, specifically, we use the the Global\nKnowledge Graph edition 2 (GKG2) of GDELT). But in fact GDELT-GKG2 is implemented as multiple\nlinked tables recording information about the relationship between articles and events, and thus effectively\nhas the structure of a relational database. Another important contribution of this paper is to actually realize\nGKG2 properly in the mathematical form of a KG, effectively a graph database, derived from and consistent\nwith its native relational database form. To facilitate this effort, we have identified a lightweight ontology\nfor GDELT in the form of its graph schema, realizing its relational database schema in a KG form.\nUsing the KG that we construct from the GDELT-GKG2 dataset, we provide a case study to explore the\nutility of LLM-based tools to extract information and confirm that the KG can be used for question-answering\nin cases where traditional RAG fails. As part of our analysis, we compare to KGs produced from processing\nvarious news articles with an LLM, prompting it to try and adhere to a reduced version of the same ontology.\nThe current state of neurosymbolic work is noted for the plethora of experimental architectures available.\nWhile details are explicated below in Section 3.2, we preview ours in Figure 1, including the five method-\nological pathways which are quantitatively compared: 1) graph queries on the KG (called the DKG) derived\n“directly” from GKG2; 2) use of G-Retriever2 [7] against the same DKG; 3) RAG against a vector store\nrepresentation of GKG2; 4) G-Retriever against a second KG (called the LKG) derived from using Llamain-\ndex3 [1] against the GDELT source articles; and 5) GraphRAG4 Q&A deployed against a third KG (called\nGRKG) using Microsoft’s open-source GraphRAG package with default configuration parameters.\nFigure 1: Pipeline of different experiments ran to analyze the GDELT database using an LLM.\n2https://github.com/XiaoxinHe/G-Retriever\n3https://www.llamaindex.ai/\n4https://microsoft.github.io/graphrag/\n2', 'Finally, a set of fields at the end of the record provide additional data management information for the \nevent record.   \n \n\uf0b7 \nDATEADDED. (integer) This field stores the date the event was added to the master database \nin YYYYMMDDHHMMSS format in the UTC timezone.  For those needing to access events at 15 \nminute resolution, this is the field that should be used in queries. \n\uf0b7 \nSOURCEURL.  (string) This field records the URL or citation of the first news report it found this \nevent in.  In most cases this is the first report it saw the article in, but due to the timing and \nflow of news reports through the processing pipeline, this may not always be the very first \nreport, but is at least in the first few reports. \n \n \n \nMENTIONS TABLE \n \nThe Mentions table is a new addition to GDELT 2.0 and records each mention of the events in the Event \ntable, making it possible to track the trajectory and network structure of a story as it flows through the \nglobal media system.  Each mention of an event receives its own entry in the Mentions table – thus an \nevent which is mentioned in 100 articles will be listed 100 times in the Mentions table.  Mentions are \nrecorded irrespective of the date of the original event, meaning that a mention today of an event from a \nyear ago will still be recorded, making it possible to trace discussion of “anniversary events” or historical \nevents being recontextualized into present actions.  If a news report mentions multiple events, each \nmention is recorded separately in this table.  For translated documents, all measures below are based \non its English translation. \n \nSeveral of the new measures recorded in the Mentions table make it possible to better filter events \nbased on how confident GDELT was in its extraction of that event.  When trying to understand news \nmedia spanning the entire globe, one finds that journalism is rife with ambiguities, assumed background \nknowledge, and complex linguistic structures.  Not every event mention will take the form of “American \nPresident Barack Obama met with Russian President Vladimir Putin yesterday at a trade summit in Paris, \nFrance.”  Instead, an event mention might more commonly appear as “Obama and Putin were in Paris \nyesterday for a trade summit.  The two leaders met backstage where he discussed his policy on \nUkraine.”  To which of the two leader(s) do “he” and “his” refer?  Is Obama discussing Obama’s policy on \nUkraine, or is Obama discussing Putin’s policy on Ukraine, or is it Putin discussing Putin’s policy or \nperhaps Putin discussing Obama’s policy?  While additional cues may be available in the surrounding \ntext, ambiguous event mentions like this are exceptionally common across the world’s media.  Similarly, \nit would be difficult indeed to maintain an exhaustive list of every single political figure in the entire \nworld and thus context is often critical for disambiguating the geographic affiliation of an actor.  Even in \nthe case of more senior political leadership, a reference to “Renauld’s press conference this afternoon in \nPort-au-Prince” most likely refers to Lener Renauld, the Minister of Defense of Haiti, but this \ndisambiguation still carries with it some degree of ambiguity.  GDELT makes use of an array of natural \nlanguage processing algorithms like coreference and deep parsing using whole-of-document context.  \nWhile these enormously increase GDELT’s ability to understand and extract ambiguous and linguistically \ncomplex events, such extractions also come with a higher potential for error.  Under GDELT 1.0, the \nNumMentions field as designed as a composite score of the absolute number of unique documents \nmentioning an event and the number of revisions to the text required by these various algorithms, up to \nsix revision passes.  Under GDELT 2.0, the Mentions table now separates these, with each record in the \nMentions table recording an individual mention of an event in an article, while the new Confidence field', 'of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', '• Solid edges indicate a field in a relational table and are labeled with the type of semantic relation.\n• Dashed and bold edges indicate the structural, one-to-many relations in the relational schema.\nThe naming convention also captures the unique identifier for these csv files, so that ⟨GLOBALEVENTID⟩\nidentifies unique Events, the pair (⟨GLOBALEVENTID⟩, ⟨MentionIdentifier⟩) identifies unique Mentions, as\ndoes ⟨DocumentIdentifier⟩for Articles. We again note that the document and mention identifiers are the\nsame field, but have different field names (e.g., a URL is typically used for the document identifier and the\nsame URL is used for the mention identifier).\n3\nCase Study - Baltimore Bridge Collapse\nHere we will provide an analysis of data collected over a recent and short period of time to do question-\nanswering based analysis. The point of collecting recent data is that the LLMs used have not yet been\ntrained on these events (at the time of this study) and thus the knowledge systems are needed to supply\nthe LLM with relevant information. Specifically, this analysis uses a subset of the GDELT data collected\non March 26th of 2024 from 12:00 AM to 10:00 AM during and after the collapse of the Francis Scott Key\nBridge in Baltimore, Maryland, which occurred at approximately 1:29 AM. This 10 hour window of time\ncaptures the media response to this disaster. We filtered down the collected mentions data to only include\nrows in any of the related data if it included any of the keywords “Baltimore”, “bridge”, “collapse”, or\n“ship”. We then used all GLOBALEVENTIDs and MentionIdentifiers in this reduced mentions file to collect\nthe relevant events and articles. This filtration resulted in using approximately 1.33% of the available data\nwith 371 events, 2047 mentions, and 209 articles.\n3.1\nGDELT Knowledge Graphs\nUsing the GDELT data directly and the scraped text we can construct a total of three KGs:\nDirect KG (DKG): The first KG was simply a direct conversion of the subset of the original GDELT data\ninto an equivalent KG as specified by our ontology in Fig. 3. This KG is shown in Fig. 4a.\nLlamaIndex KG (LKG): The second KG was generated by an LLM deployed against a text corpus con-\nsisting of the source articles collected by scraping URLs of the 209 articles included in our GDELT\nsubset, and enriched with knowledge of the ontology. This KG is shown in Fig. 4b.\nGraphRAG KG (GRKG): The final KG was generated using the same articles as the LKG, using Mi-\ncrosoft’s open-source GraphRAG package with default configuration parameters. This KG is shown in\nFig. 4c.\nThe example KG constructed using our ontology (DKG) is shown in a reduced form in Fig. 4a. The nodes\nare color coded based on their source. Note that node and edge labels are not shown in order to facilitate\nclarity. This KG is one component and has 3,469 nodes and 18,052 edges.\nTo construct a KG directly from the corpus of source document text (LKG) shown in Fig. 4b, we used\nMixtral-8x7B [11] as our base model, following the procedure outlined by the LlamaIndex package developers\n[1]. The LLM is prompted to extract triples from the news articles according to a prompt provided in the\nparameter kg triplet prompt. Using the default prompt, the ontology does not get incorporated and the\nresulting KG is a star-shaped graph with a single central node and all other nodes connected to this center,\nthere being no other edges. When we change the prompt to consider the entire ontology, we again get a\nstar-shaped graph. Nontrivial graph structure arose when we prompted the language model with a reduced\nversion of the ontology with adaptation for unstructured text. In particular, our prompt asked for:\n• Vertices of one of the following types: “Event”, “Article”, “Mention”, “Person”, “Quotation”, “Orga-\nnization”, “Location”, and “Other”, with the last type serving as a catch-all.\n5']","GDELT Translingual is a component of the GDELT 2.0 system that provides realtime machine translation of global news content. Specifically, it translates news monitored by GDELT in 65 different languages (covering 98.4% of its daily non-English monitoring volume) into English in realtime. This enables the entire GDELT Event and Global Knowledge Graph (GKG/GCAM) pipelines to process news from around the world without language barriers.

Key features of GDELT Translingual include:

- It represents one of the largest realtime streaming news machine translation deployments globally.
- It allows GDELT to monitor global news at full volume across multiple languages.
- It facilitates tracing people, organizations, locations, themes, and emotions across languages and media systems.
- The translation provenance is recorded in fields such as MentionDocTranslationInfo, which includes the original source language and the translation engine/model used.
- The system uses a combination of translation engines and language models, including versions of Moses SMT platform and GDELT Translingual’s own translation models for various languages.

In summary, GDELT Translingual is the realtime multilingual machine translation system within GDELT 2.0 that translates news from 65 languages into English to enable comprehensive global event monitoring and analysis without language barriers.","GDELT Translingual is the largest realtime streaming news machine translation deployment in the world, translating all global news monitored by GDELT in 65 languages into English in realtime. It enables GDELT to monitor the entire planet at full volume, allowing tracing of people, organizations, locations, themes, and emotions across languages and media systems."
what is date mentions in news articles?,"['Finally, a set of fields at the end of the record provide additional data management information for the \nevent record.   \n \n\uf0b7 \nDATEADDED. (integer) This field stores the date the event was added to the master database \nin YYYYMMDDHHMMSS format in the UTC timezone.  For those needing to access events at 15 \nminute resolution, this is the field that should be used in queries. \n\uf0b7 \nSOURCEURL.  (string) This field records the URL or citation of the first news report it found this \nevent in.  In most cases this is the first report it saw the article in, but due to the timing and \nflow of news reports through the processing pipeline, this may not always be the very first \nreport, but is at least in the first few reports. \n \n \n \nMENTIONS TABLE \n \nThe Mentions table is a new addition to GDELT 2.0 and records each mention of the events in the Event \ntable, making it possible to track the trajectory and network structure of a story as it flows through the \nglobal media system.  Each mention of an event receives its own entry in the Mentions table – thus an \nevent which is mentioned in 100 articles will be listed 100 times in the Mentions table.  Mentions are \nrecorded irrespective of the date of the original event, meaning that a mention today of an event from a \nyear ago will still be recorded, making it possible to trace discussion of “anniversary events” or historical \nevents being recontextualized into present actions.  If a news report mentions multiple events, each \nmention is recorded separately in this table.  For translated documents, all measures below are based \non its English translation. \n \nSeveral of the new measures recorded in the Mentions table make it possible to better filter events \nbased on how confident GDELT was in its extraction of that event.  When trying to understand news \nmedia spanning the entire globe, one finds that journalism is rife with ambiguities, assumed background \nknowledge, and complex linguistic structures.  Not every event mention will take the form of “American \nPresident Barack Obama met with Russian President Vladimir Putin yesterday at a trade summit in Paris, \nFrance.”  Instead, an event mention might more commonly appear as “Obama and Putin were in Paris \nyesterday for a trade summit.  The two leaders met backstage where he discussed his policy on \nUkraine.”  To which of the two leader(s) do “he” and “his” refer?  Is Obama discussing Obama’s policy on \nUkraine, or is Obama discussing Putin’s policy on Ukraine, or is it Putin discussing Putin’s policy or \nperhaps Putin discussing Obama’s policy?  While additional cues may be available in the surrounding \ntext, ambiguous event mentions like this are exceptionally common across the world’s media.  Similarly, \nit would be difficult indeed to maintain an exhaustive list of every single political figure in the entire \nworld and thus context is often critical for disambiguating the geographic affiliation of an actor.  Even in \nthe case of more senior political leadership, a reference to “Renauld’s press conference this afternoon in \nPort-au-Prince” most likely refers to Lener Renauld, the Minister of Defense of Haiti, but this \ndisambiguation still carries with it some degree of ambiguity.  GDELT makes use of an array of natural \nlanguage processing algorithms like coreference and deep parsing using whole-of-document context.  \nWhile these enormously increase GDELT’s ability to understand and extract ambiguous and linguistically \ncomplex events, such extractions also come with a higher potential for error.  Under GDELT 1.0, the \nNumMentions field as designed as a composite score of the absolute number of unique documents \nmentioning an event and the number of revisions to the text required by these various algorithms, up to \nsix revision passes.  Under GDELT 2.0, the Mentions table now separates these, with each record in the \nMentions table recording an individual mention of an event in an article, while the new Confidence field', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.', 'records GDELT’s confidence in its extraction of that event from that particular article.  This field is a \npercent, ranging from 10 to 100% and indicates how aggressively GDELT had to perform tasks like \ncoreference or grammatical restructuring to extract the event from that article.  Sorting all mentions of \nan event by this field makes it possible to identify articles featuring the strongest and most \nunambiguous discussion of an event. \n \n\uf0b7 \nGlobalEventID.  (integer)  This is the ID of the event that was mentioned in the article. \n\uf0b7 \nEventTimeDate.  (integer)  This is the 15-minute timestamp (YYYYMMDDHHMMSS) when the \nevent being mentioned was first recorded by GDELT (the DATEADDED field of the original event \nrecord).  This field can be compared against the next one to identify events being mentioned for \nthe first time (their first mentions) or to identify events of a particular vintage being mentioned \nnow (such as filtering for mentions of events at least one week old). \n\uf0b7 \nMentionTimeDate.  (integer)  This is the 15-minute timestamp (YYYYMMDDHHMMSS) of the \ncurrent update.  This is identical for all entries in the update file but is included to make it easier \nto load the Mentions table into a database.   \n\uf0b7 \nMentionType.  (integer)  This is a numeric identifier that refers to the source collection the \ndocument came from and is used to interpret the MentionIdentifier in the next column.  In \nessence, it specifies how to interpret the MentionIdentifier to locate the actual document.  At \npresent, it can hold one of the following values: \no 1 = WEB (The document originates from the open web and the MentionIdentifier is a \nfully-qualified URL that can be used to access the document on the web). \no 2 = CITATIONONLY (The document originates from a broadcast, print, or other offline \nsource in which only a textual citation is available for the document.  In this case the \nMentionIdentifier contains the textual citation for the document). \no 3 = CORE (The document originates from the CORE archive and the MentionIdentifier \ncontains its DOI, suitable for accessing the original document through the CORE \nwebsite). \no 4 = DTIC (The document originates from the DTIC archive and the MentionIdentifier \ncontains its DOI, suitable for accessing the original document through the DTIC website). \no 5 = JSTOR (The document originates from the JSTOR archive and the MentionIdentifier \ncontains its DOI, suitable for accessing the original document through your JSTOR \nsubscription if your institution subscribes to it). \no 6 = NONTEXTUALSOURCE (The document originates from a textual proxy (such as closed \ncaptioning) of a non-textual information source (such as a video) available via a URL and \nthe MentionIdentifier provides the URL of the non-textual original source.  At present, \nthis Collection Identifier is used for processing of the closed captioning streams of the \nInternet Archive Television News Archive in which each broadcast is available via a URL, \nbut the URL offers access only to the video of the broadcast and does not provide any \naccess to the textual closed captioning used to generate the metadata.  This code is \nused in order to draw a distinction between URL-based textual material (Collection \nIdentifier 1 (WEB) and URL-based non-textual material like the Television News Archive). \n\uf0b7 \nMentionSourceName.  (integer)  This is a human-friendly identifier of the source of the \ndocument.  For material originating from the open web with a URL this field will contain the top-\nlevel domain the page was from.  For BBC Monitoring material it will contain “BBC Monitoring” \nand for JSTOR material it will contain “JSTOR.”  This field is intended for human display of major \nsources as well as for network analysis of information flows by source, obviating the \nrequirement to perform domain or other parsing of the MentionIdentifier field.', 'adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening \nentirely new analytic opportunities.  Some of the most significant changes: \n \n\uf0b7 \nRealtime Measurement of 2,300 Emotions and Themes.  The GDELT Global Content Analysis \nMeasures (GCAM) module represents what we believe is the largest deployment of sentiment \nanalysis in the world: bringing together 24 emotional measurement packages that together \nassess more than 2,300 emotions and themes from every article in realtime, multilingual \ndimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, \nFrench, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and \nUrdu).  GCAM is designed to enable unparalleled assessment of the emotional undercurrents \nand reaction at a planetary scale by bringing together an incredible array of dimensions, from \nLIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”. \n\uf0b7 \nRealtime Translation of 65 Languages.  GDELT 2.0 brings with it the public debut of GDELT \nTranslingual, representing what we believe is the largest realtime streaming news machine \ntranslation deployment in the world: all global news that GDELT monitors in 65 languages, \nrepresenting 98.4% of its daily non-English monitoring volume, is translated in realtime into \nEnglish for processing through the entire GDELT Event and GKG/GCAM pipelines.  GDELT \nTranslingual is designed to allow GDELT to monitor the entire planet at full volume, creating the \nvery first glimpses of a world without language barriers.  The GKG system now processes every \nnews report monitored by GDELT across these 65 languages, making it possible to trace people, \norganizations, locations, themes, and emotions across languages and media systems. \n\uf0b7 \nRelevant Imagery, Videos, and Social Embeds.  A large fraction of the world’s news outlets now \nspecify a hand-selected image for each article to appear when it is shared via social media that \nrepresents the core focus of the article.  GDELT identifies this imagery in a wide array of formats \nincluding Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats.  In addition, \nGDELT also uses a set of highly specialized algorithms to analyze the article content itself to \nidentify inline imagery of high likely relevance to the story, along with videos and embedded \nsocial media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is \ncompiled.  This makes it possible to gain a unique ground-level view into emerging situations \nanywhere in the world, even in those areas with very little social media penetration, and to act \nas a kind of curated list of social posts in those areas with strong social use. \n\uf0b7 \nQuotes, Names, and Amounts.  The world’s news contains a wealth of information on food \nprices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable \nitem.  GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to \noffer numeric context to global events.  In parallel, a new Names engine augments the existing \nPerson and Organization names engines by identifying an array of other kinds of proper names, \nsuch as named events (Orange Revolution / Umbrella Movement), occurrences like the World \nCup, named dates like Holocaust Remembrance Day, on through named legislation like Iran \nNuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative.  Finally, \nGDELT also identifies attributable quotes from each article, making it possible to see the \nevolving language used by political leadership across the world. \n\uf0b7 \nDate Mentions.  We’ve heard from many of you the desire to encode the list of date references \nfound in news articles and documents in order to identify repeating mentions of specific dates \nas possible “anniversary violence” indicators.  All day, month, and year dates are now extracted \nfrom each document. \n\uf0b7 \nProximity Context.  Perhaps the greatest change to the overall format from version 1.0 is the \nintroduction of the new Proximity Context capability.  The GKG records an enormously rich array', 'Graph Query\non DKG\nG-Retriever\non DKG\nRAG using\nVector Store\nG-Retriever\non LKG\nGraphRAG Q&A\non GRKG\nWhat is the name of\nthe Bridge that\ncollapsed and what\nriver was it on?\nThe Francis Scott Key\nBridge and it was on\nthe Patapsco River\nin Maryland.\nThe bridge is located\nin Sri Lanka.\nHowever, there is no\nexplicit mention of\nthe river’s name.\nThe Francis Scott Key\nBridge collapsed into\nthe Patapsco River.\nThe bridge that\ncollapsed spanned\nover the Patapsco\nriver.\nThe Francis Scott Key\nBridge which spans the\nthe Patapsco River.\nWhat is the name of\nthe ship that collided\nwith the baltimore\nbridge?\nThe name of the ship\nis not provided.\nHowever, the ship is a\ncontainer ship and\nSingapore-flagged.\nThere is no mention\nof the name of the\nship that collided\nwith the bridge.\nThe name of the ship\nthat collided with the\nBaltimore bridge is\nthe Dali.\nThe name of the\nship that collided\nwith the Baltimore\nbridge is Maersk.\nThe ship that collided\nwith the Baltimore\nbridge is the Dali.\nHow many articles\ndid CNN publish\nabout the Baltimore\nbridge collapse?\nCNN published 5\narticles about the\nBaltimore bridge\ncollapse.\nCNN published a\ntotal of 2 articles\nabout the Baltimore\nbridge collapse.\nCNN published three\narticles about the\nBaltimore bridge\ncollapse.\nThere is only one\narticle published by\nCNN about the\nBaltimore bridge\ncollapse.\nCNN published at\nleast two articles\nabout the Baltimore\nbridge collapse.\nOn what date did\nthe Baltimore\nBridge collapse?\nThe Baltimore Bridge\ncollapsed on\nMarch 26, 2024.\nI cannot directly\nanswer that question\nbased on the given\ndata.\nThe Baltimore Bridge\ncollapsed on\nMarch 26, 2024.\nThe Baltimore Bridge\ncollapsed at 1:20 a.m.\nThe Baltimore Bridge\ncollapsed on\nMarch 26, 2024.\nWho is\nBrandon Scott?\nBrandon Scott is a\nperson mentioned in\nseveral news articles\nrelated to the collapse\nof the Francis Scott\nKey Bridge.\nBrandon Scott is\nthe Mayor of\nBaltimore.\nBrandon Scott is\nthe mayor of\nBaltimore, Maryland.\nBrandon Scott is not\nmentioned in the\ngiven data.\nBrandon Scott is\nthe mayor of\nBaltimore, Maryland.\nWho is\nNiki Fennoy?\nNiki Fennoy is a\nperson mentioned in\nvarious news articles\nrelated to the collapse\nof the Francis Scott\nKey Bridge.\nThe article from\nthepeninsular-\n-qatar.com\nmentions Niki\nFennoy.\nI don’t know. Niki\nFennoy is not menti-\n-oned in the provided\ncontext.\nNiki Fennoy is not\npresent in the\ngiven data.\nNiki Fennoy is a\ncity police spokesman.\nWhat are the top\nthemes present in\nthe data?\nMARITIME INCIDENT\nMARITIME\nMANMADE DISASTER\nTAX FNCACT\nWB 137 WATER.\nMARITIME INCIDENT\nCRISIS\nTAX\nNEWS\nETHNICITY.\nI don’t have enough\ninformation from\nto determine specific\nthe themes present\nin the data.\nEVENTS AND THEIR\nRELATIONSHIPS,\nLOCATIONS,\nORGANIZATIONS,\nVESSELS.\nNEWS AND UPDATES\nBRIDGE COLLAPSE\nCONSTRUCTION CREW\nSEARCH AND RESCUE\nCOMMUNITY REPORT.\nTable 1: Table of example questions and answers highlighting deficiencies in each method for analyzing the\nGDELT data. Table highlight color legend: Green is a correct answer, yellow is a partially correct answer,\nred is an incorrect answer, and grey is for no answer provided.\nOur prompt was then constructed as the following: “Please answer the question given the following infor-\nmation:” with the list of edge sentences appended to the end.\nSolutions based on vector stores, GraphRAG, and direct graph queries on the DKG offer the best results\nfor question answering. With direct graph queries, we can answer high-level and other types of questions\nthat need us to aggregate information across the dataset. For example, we can easily extract information\nabout recurrent themes or about a particular news source. While GraphRAG also provides functionality\nto answer high-level questions, we found that its performance lacked in this respect. It performed well on\nfine-grained questions. A vector store performed similarly well on these fine-grained questions that can be\nanswered by a small number of excerpts from the source articles. Notably, the second column suggests that\nthe automated search functionalities provided in G-retriever are often unable to retrieve a subgraph that can\nbe used to provide an accurate answer. The problem gets worse when we use the KG created by LlamaIndex\nas our knowledge base, which is unable to suitably answer any question that we posed. These issues may\npartially be due to the out-of-box application of the G-retriever system and careful fine-tuning may improve\nperformance. Regardless, we see the retained value in directly probing our data with hand-crafted queries\nand infer that further developments are needed for these automated information extraction systems to match\nthe baseline performance on questions that require reasoning across the entire corpus.\nBy combining the results of the direct graph queries on the DKG with those of GraphRAG and standard\nRAG, we can provide suitable answers to the all of the presented questions. On one hand, we see that\nthe DKG can provide better responses to high-level or aggregate questions about our data. Conversely, the\nvector store and GRKG can be used to identify local information in the documents that might be missing\nin the DKG.\nRegarding popular subjects, direct prompting of the LLM without dealing with knowledge graphs or vector\n8', '\uf0b7 \nMentionIdentifier.  (integer)  This is the unique external identifier for the source document.  It \ncan be used to uniquely identify the document and access it if you have the necessary \nsubscriptions or authorizations and/or the document is public access.  This field can contain a \nrange of values, from URLs of open web resources to textual citations of print or broadcast \nmaterial to DOI identifiers for various document repositories.  For example, if MentionType is \nequal to 1, this field will contain a fully-qualified URL suitable for direct access.  If MentionType \nis equal to 2, this field will contain a textual citation akin to what would appear in an academic \njournal article referencing that document (NOTE that the actual citation format will vary (usually \nbetween APA, Chicago, Harvard, or MLA) depending on a number of factors and no assumptions \nshould be made on its precise format at this time due to the way in which this data is currently \nprovided to GDELT – future efforts will focus on normalization of this field to a standard citation \nformat).  If MentionType is 3, the field will contain a numeric or alpha-numeric DOI that can be \ntyped into JSTOR’s search engine to access the document if your institution has a JSTOR \nsubscription. \n\uf0b7 \nSentenceID.  (integer)  The sentence within the article where the event was mentioned (starting \nwith the first sentence as 1, the second sentence as 2, the third sentence as 3, and so on).  This \ncan be used similarly to the CharOffset fields below, but reports the event’s location in the \narticle in terms of sentences instead of characters, which is more amenable to certain measures \nof the “importance” of an event’s positioning within an article. \n\uf0b7 \nActor1CharOffset.  (integer)  The location within the article (in terms of English characters) \nwhere Actor1 was found.  This can be used in combination with the GKG or other analysis to \nidentify further characteristics and attributes of the actor.  NOTE: due to processing performed \non each article, this may be slightly offset from the position seen when the article is rendered in \na web browser. \n\uf0b7 \nActor2CharOffset.  (integer)  The location within the article (in terms of English characters) \nwhere Actor2 was found.  This can be used in combination with the GKG or other analysis to \nidentify further characteristics and attributes of the actor.  NOTE: due to processing performed \non each article, this may be slightly offset from the position seen when the article is rendered in \na web browser. \n\uf0b7 \nActionCharOffset.  (integer)  The location within the article (in terms of English characters) \nwhere the core Action description was found.  This can be used in combination with the GKG or \nother analysis to identify further characteristics and attributes of the actor.  NOTE: due to \nprocessing performed on each article, this may be slightly offset from the position seen when \nthe article is rendered in a web browser. \n\uf0b7 \nInRawText.  (integer)  This records whether the event was found in the original unaltered raw \narticle text (a value of 1) or whether advanced natural language processing algorithms were \nrequired to synthesize and rewrite the article text to identify the event (a value of 0).  See the \ndiscussion on the Confidence field below for more details.  Mentions with a value of “1” in this \nfield likely represent strong detail-rich references to an event. \n\uf0b7 \nConfidence.  (integer)  Percent confidence in the extraction of this event from this article.  See \nthe discussion above. \n\uf0b7 \nMentionDocLen.  (integer)  The length in English characters of the source document (making it \npossible to filter for short articles focusing on a particular event versus long summary articles \nthat casually mention an event in passing). \n\uf0b7 \nMentionDocTone.  (integer)  The same contents as the AvgTone field in the Events table, but \ncomputed for this particular article.  NOTE: users interested in emotional measures should use', 'significance, credibly, and/or interest to their audiences.  Only image-based embedded posts are \nincluded in this field – videos are identified in the following field. \n\uf0b7 \nV2.1SOCIALVIDEOEMBEDS.    (semicolon-delimited list of URLs).  News websites are increasingly \nembedding videos inline in their articles to illustrate them with realtime reaction or citizen \nreporting from the ground.  Some news outlets that also have television properties may cross-\nlink their television reporting into their web-based presentation.  GDELT currently recognizes \nYouTube, DailyMotion, Vimeo, and Vine videos embedded in articles and records their URLs in \nthis field.  Similarly to the field above, this allows for a form of social media “curation” of the \nvideos deemed by the mainstream media to be of greatest relevance, significance, credibly, \nand/or interest to their audiences.   \n\uf0b7 \nV2.1QUOTATIONS.  (pound-delimited (“#”) blocks, with pipe-delimited (“|”) fields).  News \ncoverage frequently features excerpted statements from participants in an event and/or those \naffected by it and these quotations can offer critical insights into differing perspectives and \nemotions surrounding that event.  GDELT identifies and extracts all quoted statements from \neach article and additionally attempts to identify the verb introducing the quote to help lend \nadditional context, separating “John retorted…” from “John agreed…” to show whether the \nspeaker was agreeing with or rejecting the statement being made.  Each quoted statement is \nseparated by a “#” character, and within each block the following fields appear, separated by \npipe (“|”) symbols: \no Offset.  This is the character offset of the quoted statement within the document, \nindicating approximately where it was found in the body.  This can be used to associate \nthe date with the entries from other “V2ENHANCED” fields that appeared in closest \nproximity to it. \no Length.  This is the length of the quoted statement in characters. \no Verb.  This is the verb used to introduce the quote, allowing for separation of \nagreement versus disagreement quotes.  May not be present for all quotes and not all \nverbs are recognized for this field. \no Quote.  The actual quotation itself. \n\uf0b7 \nV2.1ALLNAMES.  (semicolon-delimited blocks, with comma-delimited fields)  This field contains \na list of all proper names referenced in the document, along with the character offsets of \napproximately where in the document they were found.  Unlike the V2ENHANCEDPERSONS and \nV2ENHANCEDORGANIZATIONS fields, which are restricted to person and organization names, \nrespectively, this field records ALL proper names referenced in the article, ranging from named \nevents like the Orange Revolution, Umbrella Movement, and Arab Spring, to movements like the \nCivil Rights Movement, to festivals and occurrences like the Cannes Film Festival and World Cup, \nto named wars like World War I, to named dates like Martin Luther King Day and Holocaust \nRemembrance Day, to named legislation like Iran Nuclear Weapon Free Act, Affordable Care Act \nand Rouge National Urban Park Initiative.  This field goes beyond people and organizations to \ncapturing a much broader view of the named events, objects, initiatives, laws, and other types \nof names in each article.  Each name reference is separated by a semicolon, and within each \nreference, the name is specified first, followed by a comma, and then the approximate character \noffset of the reference of that name in the document, allowing it to be associated with other \nentries from other “V2ENHANCED” fields that appear in closest proximity to it.  If a name is \nmentioned multiple times in a document, each mention will appear separately in this field.  This \nfield is designed to be maximally inclusive and in cases of ambiguity, to err on the side of \ninclusion of a name. \n\uf0b7 \nV2.1AMOUNTS.  (semicolon-delimited blocks, with comma-delimited fields)  This field contains \na list of all precise numeric amounts referenced in the document, along with the character', 'Conflict.  This field specifies this primary classification for the event type, allowing analysis at the \nhighest level of aggregation.  The numeric codes in this field map to the Quad Classes as follows: \n1=Verbal Cooperation, 2=Material Cooperation, 3=Verbal Conflict, 4=Material Conflict. \n\uf0b7 \nGoldsteinScale.  (floating point) Each CAMEO event code is assigned a numeric score from -10 to \n+10, capturing the theoretical potential impact that type of event will have on the stability of a \ncountry.  This is known as the Goldstein Scale.  This field specifies the Goldstein score for each \nevent type.  NOTE: this score is based on the type of event, not the specifics of the actual event \nrecord being recorded – thus two riots, one with 10 people and one with 10,000, will both \nreceive the same Goldstein score.  This can be aggregated to various levels of time resolution to \nyield an approximation of the stability of a location over time. \n\uf0b7 \nNumMentions.  (integer) This is the total number of mentions of this event across all source \ndocuments during the 15 minute update in which it was first seen.  Multiple references to an \nevent within a single document also contribute to this count.  This can be used as a method of \nassessing the “importance” of an event: the more discussion of that event, the more likely it is \nto be significant.  The total universe of source documents and the density of events within them \nvary over time, so it is recommended that this field be normalized by the average or other \nmeasure of the universe of events during the time period of interest.  This field is actually a \ncomposite score of the total number of raw mentions and the number of mentions extracted \nfrom reprocessed versions of each article (see the discussion for the Mentions table).   NOTE: \nthis field refers only to the first news report to mention an event and is not updated if the event \nis found in a different context in other news reports.  It is included for legacy purposes – for \nmore precise information on the positioning of an event, see the Mentions table.  \n\uf0b7 \nNumSources.  (integer) This is the total number of information sources containing one or more \nmentions of this event during the 15 minute update in which it was first seen.  This can be used \nas a method of assessing the “importance” of an event: the more discussion of that event, the \nmore likely it is to be significant.  The total universe of sources varies over time, so it is \nrecommended that this field be normalized by the average or other measure of the universe of \nevents during the time period of interest.  NOTE: this field refers only to the first news report to \nmention an event and is not updated if the event is found in a different context in other news \nreports.  It is included for legacy purposes – for more precise information on the positioning of \nan event, see the Mentions table. \n\uf0b7 \nNumArticles.  (integer) This is the total number of source documents containing one or more \nmentions of this event during the 15 minute update in which it was first seen.  This can be used \nas a method of assessing the “importance” of an event: the more discussion of that event, the \nmore likely it is to be significant.  The total universe of source documents varies over time, so it \nis recommended that this field be normalized by the average or other measure of the universe \nof events during the time period of interest.  NOTE: this field refers only to the first news report \nto mention an event and is not updated if the event is found in a different context in other news \nreports.  It is included for legacy purposes – for more precise information on the positioning of \nan event, see the Mentions table. \n\uf0b7 \nAvgTone.  (numeric) This is the average “tone” of all documents containing one or more \nmentions of this event during the 15 minute update in which it was first seen.  The score \nranges from -100 (extremely negative) to +100 (extremely positive).  Common values range \nbetween -10 and +10, with 0 indicating neutral.  This can be used as a method of filtering the \n“context” of events as a subtle measure of the importance of an event and as a proxy for the \n“impact” of that event.  For example, a riot event with a slightly negative average tone is likely \nto have been a minor occurrence, whereas if it had an extremely negative average tone, it \nsuggests a far more serious occurrence.  A riot with a positive score likely suggests a very minor']","The ""date mentions"" in news articles, as described in the provided context, refer to all day, month, and year dates that are extracted from each news document or article. This extraction is done to identify and encode the list of date references found within the text of news articles and documents. The purpose of extracting these date mentions is to enable the identification of repeating mentions of specific dates, which can serve as indicators of events such as ""anniversary violence"" or other significant recurring dates.

In summary:

- Date mentions are all references to dates (day, month, year) found within the text of news articles.
- These are extracted from each document to track mentions of specific dates.
- This allows analysis of how often particular dates are referenced, which can be useful for identifying anniversaries or historical events being discussed in current news.

This feature is part of the enhancements in GDELT 2.0 and later versions, aimed at providing richer temporal context and enabling new analytic opportunities related to the timing and recurrence of events in the media.","Date Mentions refer to the list of date references found in news articles and documents, which are extracted to identify repeating mentions of specific dates as possible “anniversary violence” indicators. All day, month, and year dates are now extracted from each document."
how GKG 2.1 help to know Russia with people and roles in news articles when before it was hard to connect them all together in one place?,"['of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', '\uf0b7 \nSingle Data File.  Previously there were two separate GKG data files, one containing Counts only \nand one containing the full GKG file.  The original rationale for having two separate files was that \nusers interested only in counts could download a much smaller daily file, but in practice nearly \nall applications use the full GKG file in order to make use of its thematic and other data fields to \ncontextualize those counts and to tie them into the GDELT Event Database.  Thus, we are \neliminating the separate counts-only file to simplify the GKG data environment. \n\uf0b7 \nProduction Status.  The GKG has now moved out of Alpha Experimental Release status and into \nproduction status.  This means that the file format is now stabilized and will not change. \n \nDIFFERENCES FROM GKG 2.0 \n \nThe GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were \nreleased in that format.  With the debut of the GKG 2.1 format in February 2015, the format has \nremained largely the same, but with the addition of several new fields to accommodate a number of \nsignificant enhancements to the GKG system.  While it was originally intended to release these new \nfeatures in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these \nfields, the desire to more closely align some of them with the format used for the Events dataset, and \nthe need to enable structural mapping of several of the fields to a forthcoming new hierarchical \nrepresentation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to \naccommodate these goals.  Users will find that code designed for the GKG 2.0 format can be adapted to \nthe GKG 2.1 format with minimal modification.  Since the GKG 2.0 format was only used for a handful of \nspecial subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 \ncompatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be \nsupported for news content.   \n \nFrom a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 \nrevolve around how entries are clustered and the minimum criteria for an article to be included in the \nGKG stream.  Under the GKG 1.0 format, a deduplication process similar to that used for the Event \nstream was applied to the daily GKG export, grouping together all articles yielding the same GKG \nmetadata.  Thus, two articles listing the same set of locations, themes, people, and organizations would \nbe grouped together in a single row with NumArticles holding a value of 2.  With the introduction of the \nnew GCAM system that assess more than 2,300 emotions and themes for each article, it became clear \nthat the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, \nthemes, people, and organizations might use very different language to discuss them, yielding very \ndifferent GCAM scores.  In addition, the introduction of realtime translation into the GDELT architecture \nnecessitated the ability to identify the provenance of metadata at the document level.  Thus, GKG 2.1 no \nlonger clusters documents together based on shared metadata – if 20 articles all contain the same list of \nextracted locations, themes, people, and organizations, they will appear as 20 separate entries in the \nGKG stream.  The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering.  \nIn addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article \nto appear in the GKG.  Under GKG 1.0 and 2.0, an article was required to have at least one successfully \nidentified and geocoded geographic location before it would be included in the GKG output.  However, \nmany topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy \ndiscussions, often do not have strong geographic centering, with many articles not mentioning even a \nsingle location.  This was excluding a considerable amount of content from the GKG system that is of \nhigh relevance to many GDELT user communities.  Thus, beginning with GKG 2.1, an article is included in \nthe GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional \nscores.  An article that contains no recognizable geographic mentions, but lists several political leaders,', 'adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening \nentirely new analytic opportunities.  Some of the most significant changes: \n \n\uf0b7 \nRealtime Measurement of 2,300 Emotions and Themes.  The GDELT Global Content Analysis \nMeasures (GCAM) module represents what we believe is the largest deployment of sentiment \nanalysis in the world: bringing together 24 emotional measurement packages that together \nassess more than 2,300 emotions and themes from every article in realtime, multilingual \ndimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, \nFrench, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and \nUrdu).  GCAM is designed to enable unparalleled assessment of the emotional undercurrents \nand reaction at a planetary scale by bringing together an incredible array of dimensions, from \nLIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”. \n\uf0b7 \nRealtime Translation of 65 Languages.  GDELT 2.0 brings with it the public debut of GDELT \nTranslingual, representing what we believe is the largest realtime streaming news machine \ntranslation deployment in the world: all global news that GDELT monitors in 65 languages, \nrepresenting 98.4% of its daily non-English monitoring volume, is translated in realtime into \nEnglish for processing through the entire GDELT Event and GKG/GCAM pipelines.  GDELT \nTranslingual is designed to allow GDELT to monitor the entire planet at full volume, creating the \nvery first glimpses of a world without language barriers.  The GKG system now processes every \nnews report monitored by GDELT across these 65 languages, making it possible to trace people, \norganizations, locations, themes, and emotions across languages and media systems. \n\uf0b7 \nRelevant Imagery, Videos, and Social Embeds.  A large fraction of the world’s news outlets now \nspecify a hand-selected image for each article to appear when it is shared via social media that \nrepresents the core focus of the article.  GDELT identifies this imagery in a wide array of formats \nincluding Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats.  In addition, \nGDELT also uses a set of highly specialized algorithms to analyze the article content itself to \nidentify inline imagery of high likely relevance to the story, along with videos and embedded \nsocial media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is \ncompiled.  This makes it possible to gain a unique ground-level view into emerging situations \nanywhere in the world, even in those areas with very little social media penetration, and to act \nas a kind of curated list of social posts in those areas with strong social use. \n\uf0b7 \nQuotes, Names, and Amounts.  The world’s news contains a wealth of information on food \nprices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable \nitem.  GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to \noffer numeric context to global events.  In parallel, a new Names engine augments the existing \nPerson and Organization names engines by identifying an array of other kinds of proper names, \nsuch as named events (Orange Revolution / Umbrella Movement), occurrences like the World \nCup, named dates like Holocaust Remembrance Day, on through named legislation like Iran \nNuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative.  Finally, \nGDELT also identifies attributable quotes from each article, making it possible to see the \nevolving language used by political leadership across the world. \n\uf0b7 \nDate Mentions.  We’ve heard from many of you the desire to encode the list of date references \nfound in news articles and documents in order to identify repeating mentions of specific dates \nas possible “anniversary violence” indicators.  All day, month, and year dates are now extracted \nfrom each document. \n\uf0b7 \nProximity Context.  Perhaps the greatest change to the overall format from version 1.0 is the \nintroduction of the new Proximity Context capability.  The GKG records an enormously rich array', 'significance, credibly, and/or interest to their audiences.  Only image-based embedded posts are \nincluded in this field – videos are identified in the following field. \n\uf0b7 \nV2.1SOCIALVIDEOEMBEDS.    (semicolon-delimited list of URLs).  News websites are increasingly \nembedding videos inline in their articles to illustrate them with realtime reaction or citizen \nreporting from the ground.  Some news outlets that also have television properties may cross-\nlink their television reporting into their web-based presentation.  GDELT currently recognizes \nYouTube, DailyMotion, Vimeo, and Vine videos embedded in articles and records their URLs in \nthis field.  Similarly to the field above, this allows for a form of social media “curation” of the \nvideos deemed by the mainstream media to be of greatest relevance, significance, credibly, \nand/or interest to their audiences.   \n\uf0b7 \nV2.1QUOTATIONS.  (pound-delimited (“#”) blocks, with pipe-delimited (“|”) fields).  News \ncoverage frequently features excerpted statements from participants in an event and/or those \naffected by it and these quotations can offer critical insights into differing perspectives and \nemotions surrounding that event.  GDELT identifies and extracts all quoted statements from \neach article and additionally attempts to identify the verb introducing the quote to help lend \nadditional context, separating “John retorted…” from “John agreed…” to show whether the \nspeaker was agreeing with or rejecting the statement being made.  Each quoted statement is \nseparated by a “#” character, and within each block the following fields appear, separated by \npipe (“|”) symbols: \no Offset.  This is the character offset of the quoted statement within the document, \nindicating approximately where it was found in the body.  This can be used to associate \nthe date with the entries from other “V2ENHANCED” fields that appeared in closest \nproximity to it. \no Length.  This is the length of the quoted statement in characters. \no Verb.  This is the verb used to introduce the quote, allowing for separation of \nagreement versus disagreement quotes.  May not be present for all quotes and not all \nverbs are recognized for this field. \no Quote.  The actual quotation itself. \n\uf0b7 \nV2.1ALLNAMES.  (semicolon-delimited blocks, with comma-delimited fields)  This field contains \na list of all proper names referenced in the document, along with the character offsets of \napproximately where in the document they were found.  Unlike the V2ENHANCEDPERSONS and \nV2ENHANCEDORGANIZATIONS fields, which are restricted to person and organization names, \nrespectively, this field records ALL proper names referenced in the article, ranging from named \nevents like the Orange Revolution, Umbrella Movement, and Arab Spring, to movements like the \nCivil Rights Movement, to festivals and occurrences like the Cannes Film Festival and World Cup, \nto named wars like World War I, to named dates like Martin Luther King Day and Holocaust \nRemembrance Day, to named legislation like Iran Nuclear Weapon Free Act, Affordable Care Act \nand Rouge National Urban Park Initiative.  This field goes beyond people and organizations to \ncapturing a much broader view of the named events, objects, initiatives, laws, and other types \nof names in each article.  Each name reference is separated by a semicolon, and within each \nreference, the name is specified first, followed by a comma, and then the approximate character \noffset of the reference of that name in the document, allowing it to be associated with other \nentries from other “V2ENHANCED” fields that appear in closest proximity to it.  If a name is \nmentioned multiple times in a document, each mention will appear separately in this field.  This \nfield is designed to be maximally inclusive and in cases of ambiguity, to err on the side of \ninclusion of a name. \n\uf0b7 \nV2.1AMOUNTS.  (semicolon-delimited blocks, with comma-delimited fields)  This field contains \na list of all precise numeric amounts referenced in the document, along with the character', '2\nConstructing a Knowledge Graph for GDELT\nAs previously mentioned, while the GDELT-GKG2 dataset is not actually natively in the form of a knowledge\ngraph, it is advertised and frequently cited as being one. We believe that we are making a distinct contribution\nto the research community by converting the very popular GKG2 database into a proper KG.\nGKG2 is natively a database of three related tables:\n• expert.csv captures event information;\n• GKG.csv captures article information; and\n• mentions.csv relates which articles mention which events.\nFigure 2: GDELT GKG 2.0 schema relating articles (GKG), mentions, and events (Export).\nThe database schema for these three CSV files is shown in Fig. 2 (see also [9]). The key characteristics of\nthis database relational schema should be interpreted as follows:\n• The three tables are color-coded by Events (green), Mentions (pink), and Articles (blue).\n• The single table of Events is shown in multiple green sub-tables, simply for clarity and convenience to\nlayout a long record structure.\n• Single-headed arrows represent one-to-many relationships between the tables. Specifically:\n– Each Event maps to multiple Mentions via the shared GLOBALEVENTID field.\n– Each Article maps to multiple Mentions via the DocumentIdentifer field on the Article side\nmatching to the MentionIdentifier field on the Mention side.\n• In this way, the Mentions table acts as a “pairs file” recording a many-many relation between Events\nand Articles: each event can be mentioned in multiple articles, and dually each article can men-\ntion many events. Each Article also has both a unique identifier through the GKGRECORDID or the\nDocumentIdentifer fields, since each row in the GKG data represents a single article.\n3', 'the score of any word-count field to convert to a percentage density score.  As an example, \nassume a document with 125 words.  The General Inquirer dictionary has been assigned the \nDictionaryID of 2 and its “Bodypt” dimension has a DimensionID of 21.  SentiWordNet has a \nDictionaryID of 10 and its “Positive” dimension has a DimensionID of 1.  Thus, the V2GCAM field \nfor a document might look like “wc:125,c2.21:4,c10.1:40,v10.1:3.21111111” indicating that the \ndocument had 125 words, that 4 of those words were found the General Inquirer “Bodypt” \nlexicon, that 40 of those words were found in the SentiWordNet lexicon, and that the average \nnumeric score of all of the words found in the SentiWordNet lexicon was 3.21111111.  For a \ncomplete list of the available dimensions, along with their assigned DictionaryID and \nDimensionID codes, their assigned key, and their human name and full citation to cite that \ndimension, please see the GCAM Master Codebook. 8  NOTE: the scores for all dimensions, both \nEnglish and non-English dimensions, will be listed together in this field – please see the \ncodebooks to determine the source language of a specific dimension.  NOTE: if non-English \ndictionaries are available for a given language and generated at least one match for that \ndocument, an additional “nwc” entry will be added which reflects the word count in the native \nlanguage, since languages may have differing word counts in their native and translated forms.  \nThis count will be absent if no native dictionaries yielded a match for the document. \n\uf0b7 \nV2.1SHARINGIMAGE.  (textual URL)  Many news websites specify a so-called “sharing image” for \neach article in which the news outlet manually specifies a particular image to be displayed when \nthat article is shared via social media or other formats.  Not all news outlets specify a sharing \nimage and some sites simply use their logo, but for those that do use this field, it represents the \noutlet’s selection of the single image that best captures the overall focus and contents of the \nstory.  GDELT currently recognizes a variety of formats for specifying this image, including Open \nGraph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats, among others.  \n\uf0b7 \nV2.1RELATEDIMAGES.  (semicolon-delimited list of URLs).  News articles frequently include \nphotographs, figures, and other imagery to illustrate the story, ranging from a single illustrative \nphotograph at top, to lengthy photo essays interspersed through the entirety of an article.  Such \nimagery lends a rich visual tapestry to a news report, helping to clarify, for example, whether an \narticle about a “protest blocking a highway” involves hundreds of activists along its length, or \njust a handful of people in one location, or whether a gas explosion leveled a building or merely \nshattered its windows.  GDELT uses a suite of highly sophisticated algorithms to actually “read” \nthrough each article in the way a human would, evaluating each image on to determine its \nrelevance, based on positioning, captioning, referencing, and context, and compiles a list of the \nURLs of the images it deems to be most relevant to the article.  Thus, unrelated inset boxes, \nadvertisements, and other imagery are ignored and this field contains only a list of images most \nillustrative of the core of the story.  This feature is in alpha release and involves a number of \nhighly complex algorithms working together in concert and thus may make mistakes.  We will be \nimproving this algorithm over time and would appreciate any feedback you may have on the \nkinds of images it incorrectly includes and those that it misses. \n\uf0b7 \nV2.1SOCIALIMAGEEMBEDS.  (semicolon-delimited list of URLs).  News websites are increasingly \nembedding image-based social media posts inline in their articles to illustrate them with \nrealtime reaction or citizen reporting from the ground.  GDELT currently recognizes embedded \nimage-based Twitter and Instagram posts and records their URLs in this field.  Only those posts \ncontaining imagery are included in this field.  This acts as a form of social media “curation” in \nwhich news outlets are wading through the deluge of social media reaction or reporting about a \nspecific situation and hand-selecting key image posts deemed of greatest relevance, \n                                                          \n8 http://data.gdeltproject.org/documentation/GCAM-MASTERCODEBOOK.xlsx', 'THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.']","GKG 2.1 helps to better understand Russia with its people and their roles in news articles by addressing a key limitation of the previous GKG system: the difficulty in associating people, locations, and functional roles together within the same article.

Previously, an article might list multiple people (e.g., Vladimir Putin, Barack Obama), locations (e.g., Russia, United States), and roles (e.g., President, Secretary of State), but there was no way to link each person to their specific location or role. For example, it was unclear which person was associated with which country or role.

GKG 2.1 solves this by providing the approximate character offset of each reference to an object (person, organization, location, role) within the original article text. This allows for proximity-based contextualization: by examining which mentions occur close to each other in the text, one can infer associations. For instance, mentions of ""Russia"" are likely to be closer to ""Vladimir Putin"" than to ""Barack Obama,"" and the role ""President"" is likely to be mentioned near ""Vladimir Putin,"" while ""Secretary of State"" is closer to ""John Kerry.""

This proximity information enables users to explore critical connections between people, their roles, and geographic or thematic contexts in a way that was not possible before. Pilot tests have shown that these proximity indicators are effective at recovering functional, thematic, and geographic affiliations.

In summary, GKG 2.1 enhances the ability to connect Russia-related people and their roles in news articles by:

- Providing character offsets for each mention, enabling proximity-based linking of people to their roles and locations.
- Allowing exploration of role, geographic, and thematic associations within articles.
- Including all extracted information even if geographic mentions are absent, broadening the scope of articles included.
  
This makes it much easier to analyze and understand the network of people and roles related to Russia in news coverage, all consolidated in one place.","GKG 2.1 helps by providing the approximate character offset of each reference to an object in the original article, which allows for simple proximity-based contextualization. This means that while it does not allow for deeper semantic association, it can show that mentions of Russia likely occur closer to certain people like Vladimir Putin, and roles like President or Secretary of State occur closer to the relevant individuals. This proximity information helps recover functional, thematic, and geographic affiliations involving Russia and people mentioned in the news, which was difficult with the previous GKG system that only recorded co-occurrence without associating each person with locations and roles."
"How does the GDELT Global Knowledge Graph (GKG) Version 2.1 enable the realtime measurement of emotions and themes across multiple languages, and what new analytic opportunities does this capability introduce according to the codebook?","['adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening \nentirely new analytic opportunities.  Some of the most significant changes: \n \n\uf0b7 \nRealtime Measurement of 2,300 Emotions and Themes.  The GDELT Global Content Analysis \nMeasures (GCAM) module represents what we believe is the largest deployment of sentiment \nanalysis in the world: bringing together 24 emotional measurement packages that together \nassess more than 2,300 emotions and themes from every article in realtime, multilingual \ndimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, \nFrench, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and \nUrdu).  GCAM is designed to enable unparalleled assessment of the emotional undercurrents \nand reaction at a planetary scale by bringing together an incredible array of dimensions, from \nLIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”. \n\uf0b7 \nRealtime Translation of 65 Languages.  GDELT 2.0 brings with it the public debut of GDELT \nTranslingual, representing what we believe is the largest realtime streaming news machine \ntranslation deployment in the world: all global news that GDELT monitors in 65 languages, \nrepresenting 98.4% of its daily non-English monitoring volume, is translated in realtime into \nEnglish for processing through the entire GDELT Event and GKG/GCAM pipelines.  GDELT \nTranslingual is designed to allow GDELT to monitor the entire planet at full volume, creating the \nvery first glimpses of a world without language barriers.  The GKG system now processes every \nnews report monitored by GDELT across these 65 languages, making it possible to trace people, \norganizations, locations, themes, and emotions across languages and media systems. \n\uf0b7 \nRelevant Imagery, Videos, and Social Embeds.  A large fraction of the world’s news outlets now \nspecify a hand-selected image for each article to appear when it is shared via social media that \nrepresents the core focus of the article.  GDELT identifies this imagery in a wide array of formats \nincluding Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats.  In addition, \nGDELT also uses a set of highly specialized algorithms to analyze the article content itself to \nidentify inline imagery of high likely relevance to the story, along with videos and embedded \nsocial media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is \ncompiled.  This makes it possible to gain a unique ground-level view into emerging situations \nanywhere in the world, even in those areas with very little social media penetration, and to act \nas a kind of curated list of social posts in those areas with strong social use. \n\uf0b7 \nQuotes, Names, and Amounts.  The world’s news contains a wealth of information on food \nprices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable \nitem.  GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to \noffer numeric context to global events.  In parallel, a new Names engine augments the existing \nPerson and Organization names engines by identifying an array of other kinds of proper names, \nsuch as named events (Orange Revolution / Umbrella Movement), occurrences like the World \nCup, named dates like Holocaust Remembrance Day, on through named legislation like Iran \nNuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative.  Finally, \nGDELT also identifies attributable quotes from each article, making it possible to see the \nevolving language used by political leadership across the world. \n\uf0b7 \nDate Mentions.  We’ve heard from many of you the desire to encode the list of date references \nfound in news articles and documents in order to identify repeating mentions of specific dates \nas possible “anniversary violence” indicators.  All day, month, and year dates are now extracted \nfrom each document. \n\uf0b7 \nProximity Context.  Perhaps the greatest change to the overall format from version 1.0 is the \nintroduction of the new Proximity Context capability.  The GKG records an enormously rich array', 'THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', 'of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.', '2\nConstructing a Knowledge Graph for GDELT\nAs previously mentioned, while the GDELT-GKG2 dataset is not actually natively in the form of a knowledge\ngraph, it is advertised and frequently cited as being one. We believe that we are making a distinct contribution\nto the research community by converting the very popular GKG2 database into a proper KG.\nGKG2 is natively a database of three related tables:\n• expert.csv captures event information;\n• GKG.csv captures article information; and\n• mentions.csv relates which articles mention which events.\nFigure 2: GDELT GKG 2.0 schema relating articles (GKG), mentions, and events (Export).\nThe database schema for these three CSV files is shown in Fig. 2 (see also [9]). The key characteristics of\nthis database relational schema should be interpreted as follows:\n• The three tables are color-coded by Events (green), Mentions (pink), and Articles (blue).\n• The single table of Events is shown in multiple green sub-tables, simply for clarity and convenience to\nlayout a long record structure.\n• Single-headed arrows represent one-to-many relationships between the tables. Specifically:\n– Each Event maps to multiple Mentions via the shared GLOBALEVENTID field.\n– Each Article maps to multiple Mentions via the DocumentIdentifer field on the Article side\nmatching to the MentionIdentifier field on the Mention side.\n• In this way, the Mentions table acts as a “pairs file” recording a many-many relation between Events\nand Articles: each event can be mentioned in multiple articles, and dually each article can men-\ntion many events. Each Article also has both a unique identifier through the GKGRECORDID or the\nDocumentIdentifer fields, since each row in the GKG data represents a single article.\n3', '\uf0b7 \nSingle Data File.  Previously there were two separate GKG data files, one containing Counts only \nand one containing the full GKG file.  The original rationale for having two separate files was that \nusers interested only in counts could download a much smaller daily file, but in practice nearly \nall applications use the full GKG file in order to make use of its thematic and other data fields to \ncontextualize those counts and to tie them into the GDELT Event Database.  Thus, we are \neliminating the separate counts-only file to simplify the GKG data environment. \n\uf0b7 \nProduction Status.  The GKG has now moved out of Alpha Experimental Release status and into \nproduction status.  This means that the file format is now stabilized and will not change. \n \nDIFFERENCES FROM GKG 2.0 \n \nThe GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were \nreleased in that format.  With the debut of the GKG 2.1 format in February 2015, the format has \nremained largely the same, but with the addition of several new fields to accommodate a number of \nsignificant enhancements to the GKG system.  While it was originally intended to release these new \nfeatures in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these \nfields, the desire to more closely align some of them with the format used for the Events dataset, and \nthe need to enable structural mapping of several of the fields to a forthcoming new hierarchical \nrepresentation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to \naccommodate these goals.  Users will find that code designed for the GKG 2.0 format can be adapted to \nthe GKG 2.1 format with minimal modification.  Since the GKG 2.0 format was only used for a handful of \nspecial subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 \ncompatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be \nsupported for news content.   \n \nFrom a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 \nrevolve around how entries are clustered and the minimum criteria for an article to be included in the \nGKG stream.  Under the GKG 1.0 format, a deduplication process similar to that used for the Event \nstream was applied to the daily GKG export, grouping together all articles yielding the same GKG \nmetadata.  Thus, two articles listing the same set of locations, themes, people, and organizations would \nbe grouped together in a single row with NumArticles holding a value of 2.  With the introduction of the \nnew GCAM system that assess more than 2,300 emotions and themes for each article, it became clear \nthat the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, \nthemes, people, and organizations might use very different language to discuss them, yielding very \ndifferent GCAM scores.  In addition, the introduction of realtime translation into the GDELT architecture \nnecessitated the ability to identify the provenance of metadata at the document level.  Thus, GKG 2.1 no \nlonger clusters documents together based on shared metadata – if 20 articles all contain the same list of \nextracted locations, themes, people, and organizations, they will appear as 20 separate entries in the \nGKG stream.  The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering.  \nIn addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article \nto appear in the GKG.  Under GKG 1.0 and 2.0, an article was required to have at least one successfully \nidentified and geocoded geographic location before it would be included in the GKG output.  However, \nmany topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy \ndiscussions, often do not have strong geographic centering, with many articles not mentioning even a \nsingle location.  This was excluding a considerable amount of content from the GKG system that is of \nhigh relevance to many GDELT user communities.  Thus, beginning with GKG 2.1, an article is included in \nthe GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional \nscores.  An article that contains no recognizable geographic mentions, but lists several political leaders,', '[23, 28].\nThroughout this work we use the GDELT dataset as a case study.\nGDELT is a massive collection of\nnews reports that provide a real-time computational record of global events that is published every 15\nminutes. It aggregates information from various news sources, blogs, and social media platforms to construct\na large collection of data including information on people, organizations, locations, themes, and emotions.\nEssentially, GDELT offers a snapshot of the world’s collective events, enabling researchers and analysts to\nexplore complex patterns and relationships within global society. By analyzing this data, it’s possible to\nidentify emerging trends, assess risks, understand public sentiment, and track the evolution of various issues\nover time. The applications of GDELT are diverse and far-reaching. Some of the most common use cases\nincluding event monitoring [16, 17, 29], risk assessment and prediction [6, 19, 20, 24, 26, 30], and social\nscience research [2, 3, 4, 12].\nGDELT describes its structure as a Global Knowledge Graph (GKG, specifically, we use the the Global\nKnowledge Graph edition 2 (GKG2) of GDELT). But in fact GDELT-GKG2 is implemented as multiple\nlinked tables recording information about the relationship between articles and events, and thus effectively\nhas the structure of a relational database. Another important contribution of this paper is to actually realize\nGKG2 properly in the mathematical form of a KG, effectively a graph database, derived from and consistent\nwith its native relational database form. To facilitate this effort, we have identified a lightweight ontology\nfor GDELT in the form of its graph schema, realizing its relational database schema in a KG form.\nUsing the KG that we construct from the GDELT-GKG2 dataset, we provide a case study to explore the\nutility of LLM-based tools to extract information and confirm that the KG can be used for question-answering\nin cases where traditional RAG fails. As part of our analysis, we compare to KGs produced from processing\nvarious news articles with an LLM, prompting it to try and adhere to a reduced version of the same ontology.\nThe current state of neurosymbolic work is noted for the plethora of experimental architectures available.\nWhile details are explicated below in Section 3.2, we preview ours in Figure 1, including the five method-\nological pathways which are quantitatively compared: 1) graph queries on the KG (called the DKG) derived\n“directly” from GKG2; 2) use of G-Retriever2 [7] against the same DKG; 3) RAG against a vector store\nrepresentation of GKG2; 4) G-Retriever against a second KG (called the LKG) derived from using Llamain-\ndex3 [1] against the GDELT source articles; and 5) GraphRAG4 Q&A deployed against a third KG (called\nGRKG) using Microsoft’s open-source GraphRAG package with default configuration parameters.\nFigure 1: Pipeline of different experiments ran to analyze the GDELT database using an LLM.\n2https://github.com/XiaoxinHe/G-Retriever\n3https://www.llamaindex.ai/\n4https://microsoft.github.io/graphrag/\n2', 'THE GDELT EVENT DATABASE \nDATA FORMAT CODEBOOK V2.0 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook provides a quick overview of the fields in the GDELT Event file format and their \ndescriptions.  GDELT Event records are stored in an expanded version of the dyadic CAMEO format, \ncapturing two actors and the action performed by Actor1 upon Actor2.  A wide array of variables break \nout the raw CAMEO actor codes into their respective fields to make it easier to interact with the data, \nthe Action codes are broken out into their hierarchy, the Goldstein ranking score is provided, a unique \narray of georeferencing fields offer estimated landmark-centroid-level geographic positioning of both \nactors and the location of the action, and a new “Mentions” table records the network trajectory of the \nstory of each event “in flight” through the global media system. \n \nAt present, only records from February 19, 2015 onwards are available in the GDELT 2.0 file format, \nhowever in late Spring 2015 the entire historical backfile back to 1979 will be released in the GDELT 2.0 \nformat.  The   Records are stored one per line, separated by a newline (\\n) and are tab-delimited (note \nthat files have a “.csv” extension, but are actually tab-delimited).   \n \nWith the release of GDELT 2.0, the daily GDELT 1.0 Event files will still be generated each morning at \nleast through the end of Spring 2015 to enable existing applications to continue to function without \nmodification.  Please note that at present, since GDELT 2.0 files are only available for events beginning \nFebruary 19, 2015, you will need to use GDELT 1.0 to examine longitudinal patterns (since it stretches \nback to January 1, 1979) and use GDELT 2.0 moving forward for realtime events. \n  \nThere are now two data tables created every 15 minutes for the GDELT Event dataset.  The first is the \ntraditional Event table.  This table is largely identical to the GDELT 1.0 format, but does have several \nchanges as noted below.  In addition to the Event table there is now a new Mentions table that records \nall mentions of each event.  As an event is mentioned across multiple news reports, each of those \nmentions is recorded in the Mentions table, along with several key indicators about that mention, \nincluding the location within the article where the mention appeared (in the lead paragraph versus \nbeing buried at the bottom) and the “confidence” of the algorithms in their identification of the event \nfrom that specific news report.  The Confidence measure is a new feature in GDELT 2.0 that makes it \npossible to adjust the sensitivity of GDELT towards specific use cases.  Those wishing to find the earliest \nglimmers of breaking events or reports of very small-bore events that tend to only appear as part of \nperiod “round up” reports, can use the entire event stream, while those wishing to find only the largest \nevents with strongly detailed descriptions, can filter the Event stream to find only those events with the \nhighest Confidence measures.  This allows the GDELT Event stream to be dynamically filtered for each \nindividual use case (learn more about the Confidence measure below).  It also makes it possible to \nidentify the “best” news report to return for a given event (filtering all mentions of an event for those \nwith the highest Confidence scores, most prominent positioning within the article, and/or in a specific \nsource language – such as Arabic coverage of a protest versus English coverage of that protest).']","The GDELT Global Knowledge Graph (GKG) Version 2.1 enables the realtime measurement of emotions and themes across multiple languages primarily through the integration of the GDELT Global Content Analysis Measures (GCAM) module and the GDELT Translingual system. According to the codebook, this capability is realized as follows:

### How GKG 2.1 Enables Realtime Multilingual Emotion and Theme Measurement

1. **GCAM Module for Emotions and Themes:**
   - GCAM represents one of the largest deployments of sentiment analysis globally.
   - It combines 24 different emotional measurement packages to assess over 2,300 distinct emotions and themes.
   - This assessment is done in realtime for every article processed.
   - GCAM natively supports 15 languages, including Arabic, Basque, Catalan, Chinese, French, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and Urdu.
   - The emotional dimensions covered are diverse, ranging from LIWC’s “Anxiety” to Lexicoder’s “Positivity,” WordNet Affect’s “Smugness,” and RID’s “Passivity,” enabling a rich and nuanced understanding of emotional undercurrents.

2. **Realtime Translation via GDELT Translingual:**
   - GDELT 2.0 introduced GDELT Translingual, which performs realtime machine translation of news content from 65 languages into English.
   - This covers 98.4% of the daily non-English news volume monitored by GDELT.
   - The translated content is then processed through the entire GDELT Event and GKG/GCAM pipelines.
   - This system effectively removes language barriers, allowing the GKG to monitor global news at full volume.
   - It enables tracing of people, organizations, locations, themes, and emotions across languages and media systems.

### New Analytic Opportunities Introduced

- **Planetary-Scale Emotional Assessment:**
  - By combining multilingual native emotional assessment with realtime translation, GKG 2.1 allows for unparalleled, large-scale measurement of emotional reactions and thematic content worldwide.
  - This enables researchers and analysts to capture the emotional undercurrents and societal reactions on a global scale as events unfold.

- **Cross-Language and Cross-Media Tracking:**
  - The ability to process and translate news from 65 languages and assess emotions in 15 languages natively allows for comprehensive tracking of themes and sentiments across different linguistic and media ecosystems.
  - This facilitates comparative studies, trend analysis, and monitoring of global narratives without being limited by language.

- **Enhanced Contextualization of Global Events:**
  - The rich emotional and thematic metadata can be combined with other GKG data such as people, organizations, locations, and events to provide deeper insights into the context and impact of news stories.
  - This supports advanced applications in social science research, risk assessment, event monitoring, and more.

- **Inclusion of Non-Geographically Centered Topics:**
  - Unlike previous versions, GKG 2.1 includes articles even if they lack geographic mentions, as long as they contain any extracted information such as GCAM emotional scores.
  - This broadens the scope of analysis to include important global discussions like cybersecurity, constitutional discourse, and policy debates that may not be geographically anchored.

### Summary

GKG Version 2.1 leverages a combination of native multilingual emotional analysis (GCAM) and extensive realtime machine translation (GDELT Translingual) to measure over 2,300 emotions and themes across a wide array of languages in realtime. This capability opens new analytic opportunities by enabling comprehensive, cross-lingual, and cross-media tracking of emotional and thematic content at a planetary scale, enhancing the ability to understand global societal dynamics as they happen.","The GDELT Global Knowledge Graph (GKG) Version 2.1 enhances the ability to measure emotions and themes in realtime by integrating the GDELT Global Content Analysis Measures (GCAM) module, which deploys 24 emotional measurement packages assessing more than 2,300 emotions and themes from every article. This system natively analyzes emotions in 15 languages, including Arabic, Chinese, French, Hindi, Russian, and Spanish, among others. Additionally, GDELT 2.0 introduces GDELT Translingual, a realtime streaming news machine translation system that translates news from 65 languages into English, covering 98.4% of non-English monitoring volume. This allows the GKG to process news reports globally across languages, tracing people, organizations, locations, themes, and emotions seamlessly. These capabilities open entirely new analytic opportunities by enabling unparalleled assessment of emotional undercurrents and reactions at a planetary scale, supporting sophisticated sentiment analysis and cross-lingual event tracking that were not possible before."
"How does the introduction of Unique Record Identifiers in the GKG 2.1 system address the Limitations of previous GKG system in associating contextual details such as people, locations, and functional roles within news articles?","['of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', '\uf0b7 \nSingle Data File.  Previously there were two separate GKG data files, one containing Counts only \nand one containing the full GKG file.  The original rationale for having two separate files was that \nusers interested only in counts could download a much smaller daily file, but in practice nearly \nall applications use the full GKG file in order to make use of its thematic and other data fields to \ncontextualize those counts and to tie them into the GDELT Event Database.  Thus, we are \neliminating the separate counts-only file to simplify the GKG data environment. \n\uf0b7 \nProduction Status.  The GKG has now moved out of Alpha Experimental Release status and into \nproduction status.  This means that the file format is now stabilized and will not change. \n \nDIFFERENCES FROM GKG 2.0 \n \nThe GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were \nreleased in that format.  With the debut of the GKG 2.1 format in February 2015, the format has \nremained largely the same, but with the addition of several new fields to accommodate a number of \nsignificant enhancements to the GKG system.  While it was originally intended to release these new \nfeatures in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these \nfields, the desire to more closely align some of them with the format used for the Events dataset, and \nthe need to enable structural mapping of several of the fields to a forthcoming new hierarchical \nrepresentation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to \naccommodate these goals.  Users will find that code designed for the GKG 2.0 format can be adapted to \nthe GKG 2.1 format with minimal modification.  Since the GKG 2.0 format was only used for a handful of \nspecial subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 \ncompatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be \nsupported for news content.   \n \nFrom a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 \nrevolve around how entries are clustered and the minimum criteria for an article to be included in the \nGKG stream.  Under the GKG 1.0 format, a deduplication process similar to that used for the Event \nstream was applied to the daily GKG export, grouping together all articles yielding the same GKG \nmetadata.  Thus, two articles listing the same set of locations, themes, people, and organizations would \nbe grouped together in a single row with NumArticles holding a value of 2.  With the introduction of the \nnew GCAM system that assess more than 2,300 emotions and themes for each article, it became clear \nthat the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, \nthemes, people, and organizations might use very different language to discuss them, yielding very \ndifferent GCAM scores.  In addition, the introduction of realtime translation into the GDELT architecture \nnecessitated the ability to identify the provenance of metadata at the document level.  Thus, GKG 2.1 no \nlonger clusters documents together based on shared metadata – if 20 articles all contain the same list of \nextracted locations, themes, people, and organizations, they will appear as 20 separate entries in the \nGKG stream.  The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering.  \nIn addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article \nto appear in the GKG.  Under GKG 1.0 and 2.0, an article was required to have at least one successfully \nidentified and geocoded geographic location before it would be included in the GKG output.  However, \nmany topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy \ndiscussions, often do not have strong geographic centering, with many articles not mentioning even a \nsingle location.  This was excluding a considerable amount of content from the GKG system that is of \nhigh relevance to many GDELT user communities.  Thus, beginning with GKG 2.1, an article is included in \nthe GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional \nscores.  An article that contains no recognizable geographic mentions, but lists several political leaders,', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.', 'THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', '2\nConstructing a Knowledge Graph for GDELT\nAs previously mentioned, while the GDELT-GKG2 dataset is not actually natively in the form of a knowledge\ngraph, it is advertised and frequently cited as being one. We believe that we are making a distinct contribution\nto the research community by converting the very popular GKG2 database into a proper KG.\nGKG2 is natively a database of three related tables:\n• expert.csv captures event information;\n• GKG.csv captures article information; and\n• mentions.csv relates which articles mention which events.\nFigure 2: GDELT GKG 2.0 schema relating articles (GKG), mentions, and events (Export).\nThe database schema for these three CSV files is shown in Fig. 2 (see also [9]). The key characteristics of\nthis database relational schema should be interpreted as follows:\n• The three tables are color-coded by Events (green), Mentions (pink), and Articles (blue).\n• The single table of Events is shown in multiple green sub-tables, simply for clarity and convenience to\nlayout a long record structure.\n• Single-headed arrows represent one-to-many relationships between the tables. Specifically:\n– Each Event maps to multiple Mentions via the shared GLOBALEVENTID field.\n– Each Article maps to multiple Mentions via the DocumentIdentifer field on the Article side\nmatching to the MentionIdentifier field on the Mention side.\n• In this way, the Mentions table acts as a “pairs file” recording a many-many relation between Events\nand Articles: each event can be mentioned in multiple articles, and dually each article can men-\ntion many events. Each Article also has both a unique identifier through the GKGRECORDID or the\nDocumentIdentifer fields, since each row in the GKG data represents a single article.\n3', 'adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening \nentirely new analytic opportunities.  Some of the most significant changes: \n \n\uf0b7 \nRealtime Measurement of 2,300 Emotions and Themes.  The GDELT Global Content Analysis \nMeasures (GCAM) module represents what we believe is the largest deployment of sentiment \nanalysis in the world: bringing together 24 emotional measurement packages that together \nassess more than 2,300 emotions and themes from every article in realtime, multilingual \ndimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, \nFrench, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and \nUrdu).  GCAM is designed to enable unparalleled assessment of the emotional undercurrents \nand reaction at a planetary scale by bringing together an incredible array of dimensions, from \nLIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”. \n\uf0b7 \nRealtime Translation of 65 Languages.  GDELT 2.0 brings with it the public debut of GDELT \nTranslingual, representing what we believe is the largest realtime streaming news machine \ntranslation deployment in the world: all global news that GDELT monitors in 65 languages, \nrepresenting 98.4% of its daily non-English monitoring volume, is translated in realtime into \nEnglish for processing through the entire GDELT Event and GKG/GCAM pipelines.  GDELT \nTranslingual is designed to allow GDELT to monitor the entire planet at full volume, creating the \nvery first glimpses of a world without language barriers.  The GKG system now processes every \nnews report monitored by GDELT across these 65 languages, making it possible to trace people, \norganizations, locations, themes, and emotions across languages and media systems. \n\uf0b7 \nRelevant Imagery, Videos, and Social Embeds.  A large fraction of the world’s news outlets now \nspecify a hand-selected image for each article to appear when it is shared via social media that \nrepresents the core focus of the article.  GDELT identifies this imagery in a wide array of formats \nincluding Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats.  In addition, \nGDELT also uses a set of highly specialized algorithms to analyze the article content itself to \nidentify inline imagery of high likely relevance to the story, along with videos and embedded \nsocial media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is \ncompiled.  This makes it possible to gain a unique ground-level view into emerging situations \nanywhere in the world, even in those areas with very little social media penetration, and to act \nas a kind of curated list of social posts in those areas with strong social use. \n\uf0b7 \nQuotes, Names, and Amounts.  The world’s news contains a wealth of information on food \nprices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable \nitem.  GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to \noffer numeric context to global events.  In parallel, a new Names engine augments the existing \nPerson and Organization names engines by identifying an array of other kinds of proper names, \nsuch as named events (Orange Revolution / Umbrella Movement), occurrences like the World \nCup, named dates like Holocaust Remembrance Day, on through named legislation like Iran \nNuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative.  Finally, \nGDELT also identifies attributable quotes from each article, making it possible to see the \nevolving language used by political leadership across the world. \n\uf0b7 \nDate Mentions.  We’ve heard from many of you the desire to encode the list of date references \nfound in news articles and documents in order to identify repeating mentions of specific dates \nas possible “anniversary violence” indicators.  All day, month, and year dates are now extracted \nfrom each document. \n\uf0b7 \nProximity Context.  Perhaps the greatest change to the overall format from version 1.0 is the \nintroduction of the new Proximity Context capability.  The GKG records an enormously rich array']","The introduction of Unique Record Identifiers in the GKG 2.1 system addresses the limitations of the previous GKG system in associating contextual details within news articles by enabling precise, document-level identification and improved contextual association through proximity indicators.

**Background Limitation in Previous GKG System:**
- The earlier GKG system could extract various data points such as people, organizations, locations, and functional roles mentioned in an article.
- However, it was difficult to associate these data points together within the article. For example, while Barack Obama, John Kerry, Vladimir Putin, the United States, Russia, and roles like President and Secretary of State might all be mentioned in the same article, the system could not link each person to their corresponding location or role.
- This lack of association meant that the contextual relationships between entities (e.g., which person held which role or was associated with which location) were not captured.

**How GKG 2.1 Addresses This:**
- **Unique Record Identifiers (GKGRECORDID):** Each GKG record (representing a single article) is assigned a globally unique identifier. This allows users to uniquely refer to and analyze individual articles without ambiguity.
- **Proximity Context via Character Offsets:** GKG 2.1 provides the approximate character offset of each reference to an object (person, location, role, etc.) within the original article text. Although this does not enable deep semantic understanding, it allows for simple proximity-based contextualization.
  - For example, in the article mentioning Obama, Kerry, Putin, the United States, Russia, President, and Secretary of State, the proximity data can show that mentions of the United States occur closer to Obama and Kerry than to Putin, and that ""Secretary of State"" is mentioned closer to Kerry than to others.
  - This proximity information enables exploration of functional, thematic, and geographic associations by analyzing which entities appear near each other in the text.
- **No Clustering of Articles:** Unlike previous versions that clustered multiple articles with identical metadata into a single record, GKG 2.1 treats each article as a separate record with its own unique identifier. This preserves the distinct contextual nuances of each article, including differences in language and thematic content.

**Summary:**
By assigning a unique identifier to each article and providing character offset data for each entity mention, GKG 2.1 allows users to associate people, locations, and functional roles more effectively within the context of individual news articles. This proximity-based approach overcomes the previous system’s inability to link entities and their roles or locations, enabling richer and more accurate contextual analysis of news content.","The previous GKG system had limitations in associating various data points together, such as linking people like Barack Obama, John Kerry, and Vladimir Putin with their corresponding locations and functional roles within the same article. Although GKG 2.1 improved this by providing approximate character offsets to enable proximity-based contextualization, it still lacked deeper semantic association. To further enhance data management and referencing, GKG 2.1 introduced Unique Record Identifiers, which assign a unique identifier to every GKG record. These identifiers do not indicate sequence but uniquely identify each record across the entire collection, making it easier to refer to and manage specific records. This addition complements the proximity-based improvements by enabling precise and unambiguous referencing of individual records, thereby addressing some of the previous system's limitations in handling complex contextual details."
"How does the introduction of unique record identifiers in GKG 2.1 address the limitations of the previous GKG system in associating contextual details such as people, locations, and functional roles within news articles?","['of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', '\uf0b7 \nSingle Data File.  Previously there were two separate GKG data files, one containing Counts only \nand one containing the full GKG file.  The original rationale for having two separate files was that \nusers interested only in counts could download a much smaller daily file, but in practice nearly \nall applications use the full GKG file in order to make use of its thematic and other data fields to \ncontextualize those counts and to tie them into the GDELT Event Database.  Thus, we are \neliminating the separate counts-only file to simplify the GKG data environment. \n\uf0b7 \nProduction Status.  The GKG has now moved out of Alpha Experimental Release status and into \nproduction status.  This means that the file format is now stabilized and will not change. \n \nDIFFERENCES FROM GKG 2.0 \n \nThe GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were \nreleased in that format.  With the debut of the GKG 2.1 format in February 2015, the format has \nremained largely the same, but with the addition of several new fields to accommodate a number of \nsignificant enhancements to the GKG system.  While it was originally intended to release these new \nfeatures in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these \nfields, the desire to more closely align some of them with the format used for the Events dataset, and \nthe need to enable structural mapping of several of the fields to a forthcoming new hierarchical \nrepresentation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to \naccommodate these goals.  Users will find that code designed for the GKG 2.0 format can be adapted to \nthe GKG 2.1 format with minimal modification.  Since the GKG 2.0 format was only used for a handful of \nspecial subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 \ncompatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be \nsupported for news content.   \n \nFrom a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 \nrevolve around how entries are clustered and the minimum criteria for an article to be included in the \nGKG stream.  Under the GKG 1.0 format, a deduplication process similar to that used for the Event \nstream was applied to the daily GKG export, grouping together all articles yielding the same GKG \nmetadata.  Thus, two articles listing the same set of locations, themes, people, and organizations would \nbe grouped together in a single row with NumArticles holding a value of 2.  With the introduction of the \nnew GCAM system that assess more than 2,300 emotions and themes for each article, it became clear \nthat the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, \nthemes, people, and organizations might use very different language to discuss them, yielding very \ndifferent GCAM scores.  In addition, the introduction of realtime translation into the GDELT architecture \nnecessitated the ability to identify the provenance of metadata at the document level.  Thus, GKG 2.1 no \nlonger clusters documents together based on shared metadata – if 20 articles all contain the same list of \nextracted locations, themes, people, and organizations, they will appear as 20 separate entries in the \nGKG stream.  The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering.  \nIn addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article \nto appear in the GKG.  Under GKG 1.0 and 2.0, an article was required to have at least one successfully \nidentified and geocoded geographic location before it would be included in the GKG output.  However, \nmany topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy \ndiscussions, often do not have strong geographic centering, with many articles not mentioning even a \nsingle location.  This was excluding a considerable amount of content from the GKG system that is of \nhigh relevance to many GDELT user communities.  Thus, beginning with GKG 2.1, an article is included in \nthe GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional \nscores.  An article that contains no recognizable geographic mentions, but lists several political leaders,', 'THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.', '2\nConstructing a Knowledge Graph for GDELT\nAs previously mentioned, while the GDELT-GKG2 dataset is not actually natively in the form of a knowledge\ngraph, it is advertised and frequently cited as being one. We believe that we are making a distinct contribution\nto the research community by converting the very popular GKG2 database into a proper KG.\nGKG2 is natively a database of three related tables:\n• expert.csv captures event information;\n• GKG.csv captures article information; and\n• mentions.csv relates which articles mention which events.\nFigure 2: GDELT GKG 2.0 schema relating articles (GKG), mentions, and events (Export).\nThe database schema for these three CSV files is shown in Fig. 2 (see also [9]). The key characteristics of\nthis database relational schema should be interpreted as follows:\n• The three tables are color-coded by Events (green), Mentions (pink), and Articles (blue).\n• The single table of Events is shown in multiple green sub-tables, simply for clarity and convenience to\nlayout a long record structure.\n• Single-headed arrows represent one-to-many relationships between the tables. Specifically:\n– Each Event maps to multiple Mentions via the shared GLOBALEVENTID field.\n– Each Article maps to multiple Mentions via the DocumentIdentifer field on the Article side\nmatching to the MentionIdentifier field on the Mention side.\n• In this way, the Mentions table acts as a “pairs file” recording a many-many relation between Events\nand Articles: each event can be mentioned in multiple articles, and dually each article can men-\ntion many events. Each Article also has both a unique identifier through the GKGRECORDID or the\nDocumentIdentifer fields, since each row in the GKG data represents a single article.\n3', '[23, 28].\nThroughout this work we use the GDELT dataset as a case study.\nGDELT is a massive collection of\nnews reports that provide a real-time computational record of global events that is published every 15\nminutes. It aggregates information from various news sources, blogs, and social media platforms to construct\na large collection of data including information on people, organizations, locations, themes, and emotions.\nEssentially, GDELT offers a snapshot of the world’s collective events, enabling researchers and analysts to\nexplore complex patterns and relationships within global society. By analyzing this data, it’s possible to\nidentify emerging trends, assess risks, understand public sentiment, and track the evolution of various issues\nover time. The applications of GDELT are diverse and far-reaching. Some of the most common use cases\nincluding event monitoring [16, 17, 29], risk assessment and prediction [6, 19, 20, 24, 26, 30], and social\nscience research [2, 3, 4, 12].\nGDELT describes its structure as a Global Knowledge Graph (GKG, specifically, we use the the Global\nKnowledge Graph edition 2 (GKG2) of GDELT). But in fact GDELT-GKG2 is implemented as multiple\nlinked tables recording information about the relationship between articles and events, and thus effectively\nhas the structure of a relational database. Another important contribution of this paper is to actually realize\nGKG2 properly in the mathematical form of a KG, effectively a graph database, derived from and consistent\nwith its native relational database form. To facilitate this effort, we have identified a lightweight ontology\nfor GDELT in the form of its graph schema, realizing its relational database schema in a KG form.\nUsing the KG that we construct from the GDELT-GKG2 dataset, we provide a case study to explore the\nutility of LLM-based tools to extract information and confirm that the KG can be used for question-answering\nin cases where traditional RAG fails. As part of our analysis, we compare to KGs produced from processing\nvarious news articles with an LLM, prompting it to try and adhere to a reduced version of the same ontology.\nThe current state of neurosymbolic work is noted for the plethora of experimental architectures available.\nWhile details are explicated below in Section 3.2, we preview ours in Figure 1, including the five method-\nological pathways which are quantitatively compared: 1) graph queries on the KG (called the DKG) derived\n“directly” from GKG2; 2) use of G-Retriever2 [7] against the same DKG; 3) RAG against a vector store\nrepresentation of GKG2; 4) G-Retriever against a second KG (called the LKG) derived from using Llamain-\ndex3 [1] against the GDELT source articles; and 5) GraphRAG4 Q&A deployed against a third KG (called\nGRKG) using Microsoft’s open-source GraphRAG package with default configuration parameters.\nFigure 1: Pipeline of different experiments ran to analyze the GDELT database using an LLM.\n2https://github.com/XiaoxinHe/G-Retriever\n3https://www.llamaindex.ai/\n4https://microsoft.github.io/graphrag/\n2']","The introduction of unique record identifiers in GKG 2.1 addresses the limitations of the previous GKG system by enabling precise and unambiguous referencing of individual records (i.e., articles) within the dataset. Previously, the GKG system aggregated or clustered multiple articles with identical metadata into a single record, which made it difficult to associate specific contextual details—such as people, locations, and functional roles—within individual news articles. For example, while the earlier system could indicate that Barack Obama, John Kerry, and Vladimir Putin all appeared in an article along with mentions of the United States, Russia, and roles like President and Secretary of State, it could not link each person to their corresponding location or role within that article.

GKG 2.1 overcomes this by assigning a globally unique identifier (GKGRECORDID) to each record, representing a single document or article. This change means that each article is represented as a separate entry rather than being clustered with others sharing the same metadata. Additionally, GKG 2.1 provides approximate character offsets for each reference to an object within the original article text. Although this does not enable deep semantic linking, it allows for proximity-based contextualization—meaning that mentions of people, locations, and roles that appear close together in the text can be associated more reliably. For instance, the mention of the United States is likely to be closer to Barack Obama and John Kerry than to Vladimir Putin, and the role of Secretary of State is likely closer to John Kerry than to the others. This proximity information facilitates exploration of functional, thematic, and geographic affiliations within individual articles.

In summary, unique record identifiers in GKG 2.1 enable:

- Distinct representation of each article, avoiding clustering that obscured individual contextual associations.
- Easier and precise referencing of specific records.
- Use of character offset data to associate people, locations, and roles based on their proximity in the text.
- Improved ability to explore and recover functional, thematic, and geographic relationships within news articles.

This represents a significant improvement over the previous system, which lacked the means to link contextual details within articles effectively.","The previous GKG system struggled to associate various data points such as people, organizations, locations, and functional roles within news articles, making it difficult to link each person with the corresponding location and role. GKG 2.1 addresses these limitations by providing the approximate character offset of each reference in the original article, enabling proximity-based contextualization that helps recover functional, thematic, and geographic affiliations. Additionally, GKG 2.1 introduces unique record identifiers for every GKG record, which uniquely identify each record across the entire collection. This addition facilitates easier and unambiguous referencing of particular GKG records, thereby improving the management and association of contextual details that were previously difficult to connect."
How does the GKG 2.1 format improve GDELT Event Database integration and align with the Events dataset format compared to previous versions?,"['\uf0b7 \nSingle Data File.  Previously there were two separate GKG data files, one containing Counts only \nand one containing the full GKG file.  The original rationale for having two separate files was that \nusers interested only in counts could download a much smaller daily file, but in practice nearly \nall applications use the full GKG file in order to make use of its thematic and other data fields to \ncontextualize those counts and to tie them into the GDELT Event Database.  Thus, we are \neliminating the separate counts-only file to simplify the GKG data environment. \n\uf0b7 \nProduction Status.  The GKG has now moved out of Alpha Experimental Release status and into \nproduction status.  This means that the file format is now stabilized and will not change. \n \nDIFFERENCES FROM GKG 2.0 \n \nThe GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were \nreleased in that format.  With the debut of the GKG 2.1 format in February 2015, the format has \nremained largely the same, but with the addition of several new fields to accommodate a number of \nsignificant enhancements to the GKG system.  While it was originally intended to release these new \nfeatures in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these \nfields, the desire to more closely align some of them with the format used for the Events dataset, and \nthe need to enable structural mapping of several of the fields to a forthcoming new hierarchical \nrepresentation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to \naccommodate these goals.  Users will find that code designed for the GKG 2.0 format can be adapted to \nthe GKG 2.1 format with minimal modification.  Since the GKG 2.0 format was only used for a handful of \nspecial subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 \ncompatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be \nsupported for news content.   \n \nFrom a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 \nrevolve around how entries are clustered and the minimum criteria for an article to be included in the \nGKG stream.  Under the GKG 1.0 format, a deduplication process similar to that used for the Event \nstream was applied to the daily GKG export, grouping together all articles yielding the same GKG \nmetadata.  Thus, two articles listing the same set of locations, themes, people, and organizations would \nbe grouped together in a single row with NumArticles holding a value of 2.  With the introduction of the \nnew GCAM system that assess more than 2,300 emotions and themes for each article, it became clear \nthat the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, \nthemes, people, and organizations might use very different language to discuss them, yielding very \ndifferent GCAM scores.  In addition, the introduction of realtime translation into the GDELT architecture \nnecessitated the ability to identify the provenance of metadata at the document level.  Thus, GKG 2.1 no \nlonger clusters documents together based on shared metadata – if 20 articles all contain the same list of \nextracted locations, themes, people, and organizations, they will appear as 20 separate entries in the \nGKG stream.  The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering.  \nIn addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article \nto appear in the GKG.  Under GKG 1.0 and 2.0, an article was required to have at least one successfully \nidentified and geocoded geographic location before it would be included in the GKG output.  However, \nmany topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy \ndiscussions, often do not have strong geographic centering, with many articles not mentioning even a \nsingle location.  This was excluding a considerable amount of content from the GKG system that is of \nhigh relevance to many GDELT user communities.  Thus, beginning with GKG 2.1, an article is included in \nthe GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional \nscores.  An article that contains no recognizable geographic mentions, but lists several political leaders,', '2\nConstructing a Knowledge Graph for GDELT\nAs previously mentioned, while the GDELT-GKG2 dataset is not actually natively in the form of a knowledge\ngraph, it is advertised and frequently cited as being one. We believe that we are making a distinct contribution\nto the research community by converting the very popular GKG2 database into a proper KG.\nGKG2 is natively a database of three related tables:\n• expert.csv captures event information;\n• GKG.csv captures article information; and\n• mentions.csv relates which articles mention which events.\nFigure 2: GDELT GKG 2.0 schema relating articles (GKG), mentions, and events (Export).\nThe database schema for these three CSV files is shown in Fig. 2 (see also [9]). The key characteristics of\nthis database relational schema should be interpreted as follows:\n• The three tables are color-coded by Events (green), Mentions (pink), and Articles (blue).\n• The single table of Events is shown in multiple green sub-tables, simply for clarity and convenience to\nlayout a long record structure.\n• Single-headed arrows represent one-to-many relationships between the tables. Specifically:\n– Each Event maps to multiple Mentions via the shared GLOBALEVENTID field.\n– Each Article maps to multiple Mentions via the DocumentIdentifer field on the Article side\nmatching to the MentionIdentifier field on the Mention side.\n• In this way, the Mentions table acts as a “pairs file” recording a many-many relation between Events\nand Articles: each event can be mentioned in multiple articles, and dually each article can men-\ntion many events. Each Article also has both a unique identifier through the GKGRECORDID or the\nDocumentIdentifer fields, since each row in the GKG data represents a single article.\n3', 'of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', 'THE GDELT EVENT DATABASE \nDATA FORMAT CODEBOOK V2.0 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook provides a quick overview of the fields in the GDELT Event file format and their \ndescriptions.  GDELT Event records are stored in an expanded version of the dyadic CAMEO format, \ncapturing two actors and the action performed by Actor1 upon Actor2.  A wide array of variables break \nout the raw CAMEO actor codes into their respective fields to make it easier to interact with the data, \nthe Action codes are broken out into their hierarchy, the Goldstein ranking score is provided, a unique \narray of georeferencing fields offer estimated landmark-centroid-level geographic positioning of both \nactors and the location of the action, and a new “Mentions” table records the network trajectory of the \nstory of each event “in flight” through the global media system. \n \nAt present, only records from February 19, 2015 onwards are available in the GDELT 2.0 file format, \nhowever in late Spring 2015 the entire historical backfile back to 1979 will be released in the GDELT 2.0 \nformat.  The   Records are stored one per line, separated by a newline (\\n) and are tab-delimited (note \nthat files have a “.csv” extension, but are actually tab-delimited).   \n \nWith the release of GDELT 2.0, the daily GDELT 1.0 Event files will still be generated each morning at \nleast through the end of Spring 2015 to enable existing applications to continue to function without \nmodification.  Please note that at present, since GDELT 2.0 files are only available for events beginning \nFebruary 19, 2015, you will need to use GDELT 1.0 to examine longitudinal patterns (since it stretches \nback to January 1, 1979) and use GDELT 2.0 moving forward for realtime events. \n  \nThere are now two data tables created every 15 minutes for the GDELT Event dataset.  The first is the \ntraditional Event table.  This table is largely identical to the GDELT 1.0 format, but does have several \nchanges as noted below.  In addition to the Event table there is now a new Mentions table that records \nall mentions of each event.  As an event is mentioned across multiple news reports, each of those \nmentions is recorded in the Mentions table, along with several key indicators about that mention, \nincluding the location within the article where the mention appeared (in the lead paragraph versus \nbeing buried at the bottom) and the “confidence” of the algorithms in their identification of the event \nfrom that specific news report.  The Confidence measure is a new feature in GDELT 2.0 that makes it \npossible to adjust the sensitivity of GDELT towards specific use cases.  Those wishing to find the earliest \nglimmers of breaking events or reports of very small-bore events that tend to only appear as part of \nperiod “round up” reports, can use the entire event stream, while those wishing to find only the largest \nevents with strongly detailed descriptions, can filter the Event stream to find only those events with the \nhighest Confidence measures.  This allows the GDELT Event stream to be dynamically filtered for each \nindividual use case (learn more about the Confidence measure below).  It also makes it possible to \nidentify the “best” news report to return for a given event (filtering all mentions of an event for those \nwith the highest Confidence scores, most prominent positioning within the article, and/or in a specific \nsource language – such as Arabic coverage of a protest versus English coverage of that protest).', 'THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.', 'stores reveals that the LLM independently recognizes Brandon Scott as the mayor of Baltimore. For all\nother questions, the language model cannot answer the posed questions by itself due to the recency of the\nbridge collapse.\nTo quantitatively evaluate the quality of the answers generated by our different question-answering methods,\nwe require a set of ground truth answers for the questions posed. Table 2 presents these manually curated\nground truth answers, representing the expected correct responses for each question used in our evalua-\ntion. These ground truth answers serve as the benchmark against which the performance of each system is\nmeasured.\nQuestion\nGround Truth\nWhat is the name of the Bridge that collapsed and\nwhat river was it on?\nThe Francis Scott Key Bridge on the Patapsco River.\nWhat is the name of the ship that collided with the\nbaltimore bridge?\nThe ship was named the Dali.\nHow many articles did CNN publish about the Bal-\ntimore bridge collapse?\nCNN published 5 articles.\nOn what date did the Baltimore Bridge collapse?\nThe collapse occurred on March 26, 2024.\nWho is Brandon Scott?\nBrandon Scott is the Mayor of Baltimore.\nWho is Niki Fennoy?\nNiki Fennoy is a city police spokesman.\nWhat are the top themes present in the data?\nThemes include maritime incidents, manmade disaster, and\nwater-related topics.\nTable 2: Ground Truth Answers for the Baltimore Bridge Collapse Questions\nTo further validate our qualitative findings, Figure 5 presents a quantitative comparison of the semantic\nsimilarity of answers generated by the five different methods when querying the GDELT dataset related\nto the Baltimore bridge collapse. We compute the quality of the result by calculating cosine similarity5, a\nmeasure of the similarity between the embeddings of the predicted answer and the ground truth, with higher\nvalues indicating greater accuracy. The box plots illustrate the distribution of these similarity scores for each\nmethod: Graph Query on DKG, G-Retriever on DKG, RAG using Vector Store, G-Retriever on LKG, and\nGraphRAG Q&A on GRKG. As our qualitative analysis suggested, methods leveraging direct graph queries\non the DKG, standard RAG with a vector store, and GraphRAG Q&A on the GRKG generally exhibit the\nhighest cosine similarity scores, providing quantitative evidence for their superior performance in generating\naccurate and relevant answers compared to the G-Retriever, especially with the LKG. This visualization\nquantitatively confirms the trends observed in the qualitative evaluation presented in Table 1.\n4\nConclusion\nThis work has taken the GDELT GKG database and introduced an ontology to create a knowledge graph\nwith rich structure. We found that while the large KG produced by the GDELT-GKG2 database has rich\ninformation for question-answering, the ad hoc techniques for graph exploration deem further investigation\nfor reliable use. That said, the information stored in the KG produced here is not without flaws, and we\nexpect the example studied here to be useful for the broader synergy between KGs and LLMs as addressed\nby others [18]. While the KGs produced using LlamaIndex captured a summary of the events surrounding\nthe Baltimore bridge collapse, the quality of the resulting structure was not suitable for question-answering.\nThose techniques incorporated into the GraphRAG package did considerably better, but there is room for\nimprovement for answering global questions, resolving duplicate entities, and incorporating ontologically-\nguided relation extraction. We believe the incorporation of the ontology into the relation extraction will\nhave the benefit of allowing tools such as GraphRAG to better answer quantitative questions that only the\nontology based KG pipeline (DKG) was able to answer (e.g., the number of articles published on a topic).\nLarge language models continue to be adapted to solve problems across domains, and the case study on the\nKG built here presents much opportunity for future development. In particular, the debate around using\n5The\nsemantic\nembeddings\nused\nto\ncalculate\nthe\ncosine\nsimilarity\nwere\ngenerated\nusing\nthe\nsentence-transformers/all-MiniLM-L6-v2 model from the Sentence Transformers library.\n9']","The GKG 2.1 format improves integration with the GDELT Event Database and aligns better with the Events dataset format compared to previous versions through several key enhancements:

1. **Single Data File Instead of Two Separate Files**  
   Previously, GKG data was split into two files: one containing only counts and another containing the full GKG data. Since most users require the full GKG data to contextualize counts and link to the Event Database, GKG 2.1 eliminates the counts-only file, simplifying the data environment and making integration more straightforward.

2. **Unique Record Identifiers for GKG Records**  
   GKG 2.1 assigns a globally unique identifier (GKGRECORDID) to each GKG record, similar to the unique identifiers used in the GDELT Event Database. This facilitates easier referencing and linking of GKG records to events, improving data integration and consistency.

3. **No Clustering of Articles Based on Shared Metadata**  
   Unlike GKG 1.0, which clustered multiple articles with identical metadata into a single record (using a NumArticles field), GKG 2.1 treats each article as a separate record even if they share the same locations, themes, people, and organizations. This change aligns better with the Event Database’s approach, which records events individually, and supports more precise document-level provenance and analysis.

4. **Broader Inclusion Criteria for Articles**  
   GKG 2.1 relaxes the previous requirement that an article must contain at least one geocoded location to be included. Now, any article with any extracted information (including GCAM emotional/thematic scores) is included. This aligns the GKG more closely with the Event Database, which captures a wide range of event-related information, including those without geographic references.

5. **Provision of Character Offsets for Mentions**  
   GKG 2.1 includes approximate character offsets for each reference to an object (person, location, organization, role) within the original article text. This allows for proximity-based contextualization of entities and roles, enabling better association of people with locations and functional roles. This structural enhancement supports more detailed linking and contextual analysis similar to the relational structure in the Event Database.

6. **Format Alignment and Structural Mapping**  
   Several new fields were added in GKG 2.1 to enable closer alignment with the Events dataset format and to support structural mapping to a forthcoming hierarchical representation. This makes it easier to integrate and cross-reference GKG data with event data.

7. **Stabilized Production Format**  
   GKG 2.1 moves the format out of alpha experimental status into production, stabilizing the format and ensuring consistent integration with the Event Database over time.

In summary, GKG 2.1 improves integration with the GDELT Event Database by unifying data files, introducing unique record IDs, treating each article as a distinct record, broadening inclusion criteria, adding character offsets for better contextual linking, and aligning the format structurally with the Events dataset. These changes facilitate more precise, consistent, and comprehensive linking of knowledge graph data with event data.","The GKG 2.1 format improves GDELT Event Database integration by eliminating the separate counts-only file and providing a single full GKG data file that includes thematic and other data fields to contextualize counts and tie them into the Event Database. Additionally, GKG 2.1 aligns more closely with the Events dataset format by introducing new fields that enable structural mapping to a forthcoming hierarchical representation. Unlike earlier versions, GKG 2.1 no longer clusters documents based on shared metadata, allowing each article to appear separately with its own GCAM emotional scores, which supports more precise provenance identification and richer metadata. Furthermore, the minimum inclusion criteria were relaxed so that articles without geocoded locations but containing any extracted information, including GCAM scores, are now included, broadening the scope of relevant content for GDELT users."
how gdelts event database use mentions table and confidence measure to filter gdelts event for best news report,"['Finally, a set of fields at the end of the record provide additional data management information for the \nevent record.   \n \n\uf0b7 \nDATEADDED. (integer) This field stores the date the event was added to the master database \nin YYYYMMDDHHMMSS format in the UTC timezone.  For those needing to access events at 15 \nminute resolution, this is the field that should be used in queries. \n\uf0b7 \nSOURCEURL.  (string) This field records the URL or citation of the first news report it found this \nevent in.  In most cases this is the first report it saw the article in, but due to the timing and \nflow of news reports through the processing pipeline, this may not always be the very first \nreport, but is at least in the first few reports. \n \n \n \nMENTIONS TABLE \n \nThe Mentions table is a new addition to GDELT 2.0 and records each mention of the events in the Event \ntable, making it possible to track the trajectory and network structure of a story as it flows through the \nglobal media system.  Each mention of an event receives its own entry in the Mentions table – thus an \nevent which is mentioned in 100 articles will be listed 100 times in the Mentions table.  Mentions are \nrecorded irrespective of the date of the original event, meaning that a mention today of an event from a \nyear ago will still be recorded, making it possible to trace discussion of “anniversary events” or historical \nevents being recontextualized into present actions.  If a news report mentions multiple events, each \nmention is recorded separately in this table.  For translated documents, all measures below are based \non its English translation. \n \nSeveral of the new measures recorded in the Mentions table make it possible to better filter events \nbased on how confident GDELT was in its extraction of that event.  When trying to understand news \nmedia spanning the entire globe, one finds that journalism is rife with ambiguities, assumed background \nknowledge, and complex linguistic structures.  Not every event mention will take the form of “American \nPresident Barack Obama met with Russian President Vladimir Putin yesterday at a trade summit in Paris, \nFrance.”  Instead, an event mention might more commonly appear as “Obama and Putin were in Paris \nyesterday for a trade summit.  The two leaders met backstage where he discussed his policy on \nUkraine.”  To which of the two leader(s) do “he” and “his” refer?  Is Obama discussing Obama’s policy on \nUkraine, or is Obama discussing Putin’s policy on Ukraine, or is it Putin discussing Putin’s policy or \nperhaps Putin discussing Obama’s policy?  While additional cues may be available in the surrounding \ntext, ambiguous event mentions like this are exceptionally common across the world’s media.  Similarly, \nit would be difficult indeed to maintain an exhaustive list of every single political figure in the entire \nworld and thus context is often critical for disambiguating the geographic affiliation of an actor.  Even in \nthe case of more senior political leadership, a reference to “Renauld’s press conference this afternoon in \nPort-au-Prince” most likely refers to Lener Renauld, the Minister of Defense of Haiti, but this \ndisambiguation still carries with it some degree of ambiguity.  GDELT makes use of an array of natural \nlanguage processing algorithms like coreference and deep parsing using whole-of-document context.  \nWhile these enormously increase GDELT’s ability to understand and extract ambiguous and linguistically \ncomplex events, such extractions also come with a higher potential for error.  Under GDELT 1.0, the \nNumMentions field as designed as a composite score of the absolute number of unique documents \nmentioning an event and the number of revisions to the text required by these various algorithms, up to \nsix revision passes.  Under GDELT 2.0, the Mentions table now separates these, with each record in the \nMentions table recording an individual mention of an event in an article, while the new Confidence field', 'THE GDELT EVENT DATABASE \nDATA FORMAT CODEBOOK V2.0 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook provides a quick overview of the fields in the GDELT Event file format and their \ndescriptions.  GDELT Event records are stored in an expanded version of the dyadic CAMEO format, \ncapturing two actors and the action performed by Actor1 upon Actor2.  A wide array of variables break \nout the raw CAMEO actor codes into their respective fields to make it easier to interact with the data, \nthe Action codes are broken out into their hierarchy, the Goldstein ranking score is provided, a unique \narray of georeferencing fields offer estimated landmark-centroid-level geographic positioning of both \nactors and the location of the action, and a new “Mentions” table records the network trajectory of the \nstory of each event “in flight” through the global media system. \n \nAt present, only records from February 19, 2015 onwards are available in the GDELT 2.0 file format, \nhowever in late Spring 2015 the entire historical backfile back to 1979 will be released in the GDELT 2.0 \nformat.  The   Records are stored one per line, separated by a newline (\\n) and are tab-delimited (note \nthat files have a “.csv” extension, but are actually tab-delimited).   \n \nWith the release of GDELT 2.0, the daily GDELT 1.0 Event files will still be generated each morning at \nleast through the end of Spring 2015 to enable existing applications to continue to function without \nmodification.  Please note that at present, since GDELT 2.0 files are only available for events beginning \nFebruary 19, 2015, you will need to use GDELT 1.0 to examine longitudinal patterns (since it stretches \nback to January 1, 1979) and use GDELT 2.0 moving forward for realtime events. \n  \nThere are now two data tables created every 15 minutes for the GDELT Event dataset.  The first is the \ntraditional Event table.  This table is largely identical to the GDELT 1.0 format, but does have several \nchanges as noted below.  In addition to the Event table there is now a new Mentions table that records \nall mentions of each event.  As an event is mentioned across multiple news reports, each of those \nmentions is recorded in the Mentions table, along with several key indicators about that mention, \nincluding the location within the article where the mention appeared (in the lead paragraph versus \nbeing buried at the bottom) and the “confidence” of the algorithms in their identification of the event \nfrom that specific news report.  The Confidence measure is a new feature in GDELT 2.0 that makes it \npossible to adjust the sensitivity of GDELT towards specific use cases.  Those wishing to find the earliest \nglimmers of breaking events or reports of very small-bore events that tend to only appear as part of \nperiod “round up” reports, can use the entire event stream, while those wishing to find only the largest \nevents with strongly detailed descriptions, can filter the Event stream to find only those events with the \nhighest Confidence measures.  This allows the GDELT Event stream to be dynamically filtered for each \nindividual use case (learn more about the Confidence measure below).  It also makes it possible to \nidentify the “best” news report to return for a given event (filtering all mentions of an event for those \nwith the highest Confidence scores, most prominent positioning within the article, and/or in a specific \nsource language – such as Arabic coverage of a protest versus English coverage of that protest).', 'records GDELT’s confidence in its extraction of that event from that particular article.  This field is a \npercent, ranging from 10 to 100% and indicates how aggressively GDELT had to perform tasks like \ncoreference or grammatical restructuring to extract the event from that article.  Sorting all mentions of \nan event by this field makes it possible to identify articles featuring the strongest and most \nunambiguous discussion of an event. \n \n\uf0b7 \nGlobalEventID.  (integer)  This is the ID of the event that was mentioned in the article. \n\uf0b7 \nEventTimeDate.  (integer)  This is the 15-minute timestamp (YYYYMMDDHHMMSS) when the \nevent being mentioned was first recorded by GDELT (the DATEADDED field of the original event \nrecord).  This field can be compared against the next one to identify events being mentioned for \nthe first time (their first mentions) or to identify events of a particular vintage being mentioned \nnow (such as filtering for mentions of events at least one week old). \n\uf0b7 \nMentionTimeDate.  (integer)  This is the 15-minute timestamp (YYYYMMDDHHMMSS) of the \ncurrent update.  This is identical for all entries in the update file but is included to make it easier \nto load the Mentions table into a database.   \n\uf0b7 \nMentionType.  (integer)  This is a numeric identifier that refers to the source collection the \ndocument came from and is used to interpret the MentionIdentifier in the next column.  In \nessence, it specifies how to interpret the MentionIdentifier to locate the actual document.  At \npresent, it can hold one of the following values: \no 1 = WEB (The document originates from the open web and the MentionIdentifier is a \nfully-qualified URL that can be used to access the document on the web). \no 2 = CITATIONONLY (The document originates from a broadcast, print, or other offline \nsource in which only a textual citation is available for the document.  In this case the \nMentionIdentifier contains the textual citation for the document). \no 3 = CORE (The document originates from the CORE archive and the MentionIdentifier \ncontains its DOI, suitable for accessing the original document through the CORE \nwebsite). \no 4 = DTIC (The document originates from the DTIC archive and the MentionIdentifier \ncontains its DOI, suitable for accessing the original document through the DTIC website). \no 5 = JSTOR (The document originates from the JSTOR archive and the MentionIdentifier \ncontains its DOI, suitable for accessing the original document through your JSTOR \nsubscription if your institution subscribes to it). \no 6 = NONTEXTUALSOURCE (The document originates from a textual proxy (such as closed \ncaptioning) of a non-textual information source (such as a video) available via a URL and \nthe MentionIdentifier provides the URL of the non-textual original source.  At present, \nthis Collection Identifier is used for processing of the closed captioning streams of the \nInternet Archive Television News Archive in which each broadcast is available via a URL, \nbut the URL offers access only to the video of the broadcast and does not provide any \naccess to the textual closed captioning used to generate the metadata.  This code is \nused in order to draw a distinction between URL-based textual material (Collection \nIdentifier 1 (WEB) and URL-based non-textual material like the Television News Archive). \n\uf0b7 \nMentionSourceName.  (integer)  This is a human-friendly identifier of the source of the \ndocument.  For material originating from the open web with a URL this field will contain the top-\nlevel domain the page was from.  For BBC Monitoring material it will contain “BBC Monitoring” \nand for JSTOR material it will contain “JSTOR.”  This field is intended for human display of major \nsources as well as for network analysis of information flows by source, obviating the \nrequirement to perform domain or other parsing of the MentionIdentifier field.', 'Conflict.  This field specifies this primary classification for the event type, allowing analysis at the \nhighest level of aggregation.  The numeric codes in this field map to the Quad Classes as follows: \n1=Verbal Cooperation, 2=Material Cooperation, 3=Verbal Conflict, 4=Material Conflict. \n\uf0b7 \nGoldsteinScale.  (floating point) Each CAMEO event code is assigned a numeric score from -10 to \n+10, capturing the theoretical potential impact that type of event will have on the stability of a \ncountry.  This is known as the Goldstein Scale.  This field specifies the Goldstein score for each \nevent type.  NOTE: this score is based on the type of event, not the specifics of the actual event \nrecord being recorded – thus two riots, one with 10 people and one with 10,000, will both \nreceive the same Goldstein score.  This can be aggregated to various levels of time resolution to \nyield an approximation of the stability of a location over time. \n\uf0b7 \nNumMentions.  (integer) This is the total number of mentions of this event across all source \ndocuments during the 15 minute update in which it was first seen.  Multiple references to an \nevent within a single document also contribute to this count.  This can be used as a method of \nassessing the “importance” of an event: the more discussion of that event, the more likely it is \nto be significant.  The total universe of source documents and the density of events within them \nvary over time, so it is recommended that this field be normalized by the average or other \nmeasure of the universe of events during the time period of interest.  This field is actually a \ncomposite score of the total number of raw mentions and the number of mentions extracted \nfrom reprocessed versions of each article (see the discussion for the Mentions table).   NOTE: \nthis field refers only to the first news report to mention an event and is not updated if the event \nis found in a different context in other news reports.  It is included for legacy purposes – for \nmore precise information on the positioning of an event, see the Mentions table.  \n\uf0b7 \nNumSources.  (integer) This is the total number of information sources containing one or more \nmentions of this event during the 15 minute update in which it was first seen.  This can be used \nas a method of assessing the “importance” of an event: the more discussion of that event, the \nmore likely it is to be significant.  The total universe of sources varies over time, so it is \nrecommended that this field be normalized by the average or other measure of the universe of \nevents during the time period of interest.  NOTE: this field refers only to the first news report to \nmention an event and is not updated if the event is found in a different context in other news \nreports.  It is included for legacy purposes – for more precise information on the positioning of \nan event, see the Mentions table. \n\uf0b7 \nNumArticles.  (integer) This is the total number of source documents containing one or more \nmentions of this event during the 15 minute update in which it was first seen.  This can be used \nas a method of assessing the “importance” of an event: the more discussion of that event, the \nmore likely it is to be significant.  The total universe of source documents varies over time, so it \nis recommended that this field be normalized by the average or other measure of the universe \nof events during the time period of interest.  NOTE: this field refers only to the first news report \nto mention an event and is not updated if the event is found in a different context in other news \nreports.  It is included for legacy purposes – for more precise information on the positioning of \nan event, see the Mentions table. \n\uf0b7 \nAvgTone.  (numeric) This is the average “tone” of all documents containing one or more \nmentions of this event during the 15 minute update in which it was first seen.  The score \nranges from -100 (extremely negative) to +100 (extremely positive).  Common values range \nbetween -10 and +10, with 0 indicating neutral.  This can be used as a method of filtering the \n“context” of events as a subtle measure of the importance of an event and as a proxy for the \n“impact” of that event.  For example, a riot event with a slightly negative average tone is likely \nto have been a minor occurrence, whereas if it had an extremely negative average tone, it \nsuggests a far more serious occurrence.  A riot with a positive score likely suggests a very minor', 'References\n[1] Knowledge\ngraph\nindex.\nhttps://docs.llamaindex.ai/en/stable/examples/index_structs/\nknowledge_graph/KnowledgeGraphDemo/. Accessed: 2024-07-22.\n[2] Rawan Alamro, Andrew McCarren, and Amal Al-Rasheed. Predicting saudi stock market index by in-\ncorporating gdelt using multivariate time series modelling. In Advances in Data Science, Cyber Security\nand IT Applications: First International Conference on Computing, ICC 2019, Riyadh, Saudi Arabia,\nDecember 10–12, 2019, Proceedings, Part I 1, pages 317–328. Springer, 2019.\n[3] Diego Bodas-Sagi and Jos´e Labeaga. Using gdelt data to evaluate the confidence on the spanish gov-\nernment energy policy. 2016.\n[4] Emina Boudemagh and Izabela Moise. News media coverage of refugees in 2016: a gdelt case study. In\nProceedings of the International AAAI Conference on Web and Social Media, volume 11, pages 743–750,\n2017.\n[5] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and\nJonathan Larson. From local to global: A graph rag approach to query-focused summarization, 2024.\n[6] Divyanshi Galla and James Burke. Predicting social unrest using gdelt. In International conference on\nmachine learning and data mining in pattern recognition, pages 103–116. Springer, 2018.\n[7] Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V Chawla, Thomas Laurent, Yann LeCun, Xavier Bresson,\nand Bryan Hooi. G-retriever: Retrieval-augmented generation for textual graph understanding and\nquestion answering. arXiv preprint arXiv:2402.07630, 2024.\n[8] Aidan Hogan, Eva Blomqvist, Michael Cochez, C D’Amato, Gerard De Melo, Claudio Gutierrez, Sabrina\nKirrane, Jos Gayo, Roberto Navigli, Sebastian Neumaier, Axel-Cyrille Ngonga Ngomo, Axel Polleres,\nSabbir M Rashid, Anisa Rula, Lukas Schmelzeisen, Juan Sequeda, Steffen Staab, and Antoine Zimmer-\nmann. Knowledge graphs. ACM Computing Surveys, 54:4:1–37, 2021.\n[9] Himarsha R Jayanetti, Erika Frydenlund, and Michele C Weigle. Exploring xenophobic events through\ngdelt data analysis. arXiv preprint arXiv:2305.01708, 2023.\n[10] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot,\nDiego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L´elio Renard\nLavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timoth´ee\nLacroix, and William El Sayed. Mistral 7b, 2023.\n[11] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford,\nDevendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel,\nGuillaume Bour, Guillaume Lample, L´elio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre\nStock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Th´eophile Gervet,\nThibaut Lavril, Thomas Wang, Timoth´ee Lacroix, and William El Sayed. Mixtral of experts, 2024.\n[12] Swetha Keertipati, Bastin Tony Roy Savarimuthu, Maryam Purvis, and Martin Purvis. Multi-level\nanalysis of peace and conflict data in gdelt. In Proceedings of the MLSDA 2014 2nd Workshop on\nMachine Learning for Sensory Data Analysis, pages 33–40, 2014.\n[13] Kalev Leetaru and Philip A Schrodt. Gdelt: Global data on events, location, and tone, 1979–2012. In\nISA annual convention, volume 2, pages 1–49. Citeseer, 2013.\n[14] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\nHeinrich K¨uttler, Mike Lewis, Wen-tau Yih, Tim Rockt¨aschel, Sebastian Riedel, and Douwe Kiela.\nRetrieval-augmented generation for knowledge-intensive nlp tasks. In Proceedings of the 34th Interna-\ntional Conference on Neural Information Processing Systems, NIPS ’20, Red Hook, NY, USA, 2020.\nCurran Associates Inc.\n11', 'occurrence described in the context of a more positive narrative (such as a report of an attack \noccurring in a discussion of improving conditions on the ground in a country and how the \nnumber of attacks per day has been greatly reduced).  NOTE: this field refers only to the first \nnews report to mention an event and is not updated if the event is found in a different context \nin other news reports.  It is included for legacy purposes – for more precise information on the \npositioning of an event, see the Mentions table.  NOTE: this provides only a basic tonal \nassessment of an article and it is recommended that users interested in emotional measures use \nthe Mentions and Global Knowledge Graph tables to merge the complete set of 2,300 emotions \nand themes from the GKG GCAM system into their analysis of event records. \n \nEVENT GEOGRAPHY \n \nThe final set of fields add a novel enhancement to the CAMEO taxonomy, georeferencing each event \nalong three primary dimensions to the landmark-centroid level.  To do this, the fulltext of the source \ndocument is processed using fulltext geocoding and automatic disambiguation to identify every \ngeographic reference.3  The closest reference to each of the two actors and to the action reference are \nthen encoded in these fields.  The georeferenced location for an actor may not always match the \nActor1_CountryCode or Actor2_CountryCode field, such as in a case where the President of Russia is \nvisiting Washington, DC in the United States, in which case the Actor1_CountryCode would contain the \ncode for Russia, while the georeferencing fields below would contain a match for Washington, DC.  It \nmay not always be possible for the system to locate a match for each actor or location, in which case \none or more of the fields may be blank.  The Action fields capture the location information closest to the \npoint in the event description that contains the actual statement of action and is the best location to use \nfor placing events on a map or in other spatial context.   \n \nTo find all events located in or relating to a specific city or geographic landmark, the Geo_FeatureID \ncolumn should be used, rather than the Geo_Fullname column.  This is because the Geo_Fullname \ncolumn captures the name of the location as expressed in the text and thus reflects differences in \ntransliteration, alternative spellings, and alternative names for the same location.  For example, Mecca \nis often spelled Makkah, while Jeddah is commonly spelled Jiddah or Jaddah.  The Geo_Fullname column \nwill reflect each of these different spellings, while the Geo_FeatureID column will resolve them all to the \nsame unique GNS or GNIS feature identification number.  For more information on the GNS and GNIS \nidentifiers, see Leetaru (2012). 4 \n \nWhen looking for events in or relating to a specific country, such as Syria, there are two possible filtering \nmethods.  The first is to use the Actor_CountryCode fields in the Actor section to look for all actors \nhaving the SYR (Syria) code.  However, conflict zones are often accompanied by high degrees of \nuncertainty in media reporting and a news article might mention only “Unidentified gunmen stormed a \nhouse and shot 12 civilians.”  In this case, the Actor_CountryCode fields for Actor1 and Actor2 would \nboth be blank, since the article did not specify the actor country affiliations, while their \nGeo_CountryCode values (and the ActorGeo_CountryCode for the event) would specify Syria.  This can \nresult in dramatic differences when examining active conflict zones.  The second method is to examine \nthe ActorGeo_CountryCode for the location of the event.  This will also capture situations such as the \nUnited States criticizing a statement by Russia regarding a specific Syrian attack. \n \n                                                          \n3 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html \n4 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html', '\uf0b7 \nMentionIdentifier.  (integer)  This is the unique external identifier for the source document.  It \ncan be used to uniquely identify the document and access it if you have the necessary \nsubscriptions or authorizations and/or the document is public access.  This field can contain a \nrange of values, from URLs of open web resources to textual citations of print or broadcast \nmaterial to DOI identifiers for various document repositories.  For example, if MentionType is \nequal to 1, this field will contain a fully-qualified URL suitable for direct access.  If MentionType \nis equal to 2, this field will contain a textual citation akin to what would appear in an academic \njournal article referencing that document (NOTE that the actual citation format will vary (usually \nbetween APA, Chicago, Harvard, or MLA) depending on a number of factors and no assumptions \nshould be made on its precise format at this time due to the way in which this data is currently \nprovided to GDELT – future efforts will focus on normalization of this field to a standard citation \nformat).  If MentionType is 3, the field will contain a numeric or alpha-numeric DOI that can be \ntyped into JSTOR’s search engine to access the document if your institution has a JSTOR \nsubscription. \n\uf0b7 \nSentenceID.  (integer)  The sentence within the article where the event was mentioned (starting \nwith the first sentence as 1, the second sentence as 2, the third sentence as 3, and so on).  This \ncan be used similarly to the CharOffset fields below, but reports the event’s location in the \narticle in terms of sentences instead of characters, which is more amenable to certain measures \nof the “importance” of an event’s positioning within an article. \n\uf0b7 \nActor1CharOffset.  (integer)  The location within the article (in terms of English characters) \nwhere Actor1 was found.  This can be used in combination with the GKG or other analysis to \nidentify further characteristics and attributes of the actor.  NOTE: due to processing performed \non each article, this may be slightly offset from the position seen when the article is rendered in \na web browser. \n\uf0b7 \nActor2CharOffset.  (integer)  The location within the article (in terms of English characters) \nwhere Actor2 was found.  This can be used in combination with the GKG or other analysis to \nidentify further characteristics and attributes of the actor.  NOTE: due to processing performed \non each article, this may be slightly offset from the position seen when the article is rendered in \na web browser. \n\uf0b7 \nActionCharOffset.  (integer)  The location within the article (in terms of English characters) \nwhere the core Action description was found.  This can be used in combination with the GKG or \nother analysis to identify further characteristics and attributes of the actor.  NOTE: due to \nprocessing performed on each article, this may be slightly offset from the position seen when \nthe article is rendered in a web browser. \n\uf0b7 \nInRawText.  (integer)  This records whether the event was found in the original unaltered raw \narticle text (a value of 1) or whether advanced natural language processing algorithms were \nrequired to synthesize and rewrite the article text to identify the event (a value of 0).  See the \ndiscussion on the Confidence field below for more details.  Mentions with a value of “1” in this \nfield likely represent strong detail-rich references to an event. \n\uf0b7 \nConfidence.  (integer)  Percent confidence in the extraction of this event from this article.  See \nthe discussion above. \n\uf0b7 \nMentionDocLen.  (integer)  The length in English characters of the source document (making it \npossible to filter for short articles focusing on a particular event versus long summary articles \nthat casually mention an event in passing). \n\uf0b7 \nMentionDocTone.  (integer)  The same contents as the AvgTone field in the Events table, but \ncomputed for this particular article.  NOTE: users interested in emotional measures should use']","The GDELT Event Database uses the **Mentions table** and the **Confidence measure** to filter and identify the best news reports for events as follows:

1. **Mentions Table Role:**
   - The Mentions table records every individual mention of an event found in news articles or other source documents.
   - Each mention corresponds to a single article or source that references the event, so an event mentioned in 100 articles will have 100 entries in the Mentions table.
   - This allows tracking the trajectory and network of a story as it spreads through global media.
   - Mentions are recorded regardless of the event's original date, enabling tracking of ongoing or historical event discussions.
   - The table includes detailed metadata about each mention, such as the source, the position of the mention within the article, and the language of the source.

2. **Confidence Measure:**
   - The Confidence field in the Mentions table is a percentage (ranging from 10% to 100%) that indicates how confidently GDELT’s natural language processing algorithms extracted the event from that specific article.
   - A higher Confidence score means the event extraction was more straightforward and less reliant on complex linguistic inference (like coreference resolution or grammatical restructuring).
   - Mentions with high Confidence scores typically represent strong, clear, and unambiguous descriptions of the event.
   - Mentions with low Confidence scores may involve more ambiguous or indirect references, increasing the chance of extraction errors.

3. **Filtering for Best News Reports:**
   - By sorting or filtering mentions of an event by their Confidence scores, users can identify the articles that provide the clearest and most detailed accounts of the event.
   - This filtering helps to isolate the ""best"" news reports—those with the strongest, most explicit descriptions and least ambiguity.
   - Additional filtering can be done based on the mention’s position in the article (e.g., lead paragraph vs. buried mention), source language, or source prominence.
   - This approach allows users to dynamically adjust the sensitivity of event detection:
     - For early detection or broad coverage, include all mentions regardless of Confidence.
     - For high-quality, detailed event reports, focus on mentions with the highest Confidence scores.

4. **Use Cases:**
   - Users interested in the earliest glimmers of breaking news might use all mentions.
   - Users seeking only the most significant or well-documented events can filter by high Confidence mentions.
   - The Mentions table also supports identifying the best source article to return for a given event by combining Confidence with other factors like source reputation and mention prominence.

**Summary:**  
GDELT’s Mentions table captures every article mention of an event, each with a Confidence score reflecting extraction reliability. Filtering event mentions by high Confidence scores enables users to select the clearest, most reliable news reports, thus improving the quality of event-based news analysis and reporting.","The GDELT Event database includes a new Mentions table in GDELT 2.0 that records all mentions of each event across multiple news reports. Each mention includes key indicators such as the location within the article where the mention appeared and a Confidence measure. The Confidence measure allows users to adjust the sensitivity of GDELT towards specific use cases, enabling filtering of the Event stream to find only the largest events with strongly detailed descriptions or to capture early or small-bore events. By filtering mentions for those with the highest Confidence scores, most prominent positioning within the article, and/or specific source languages, users can identify the ""best"" news report to return for a given event."
"How does the introduction of the GCAM system in the GKG 2.1 format enhance the granularity and scope of emotional and thematic analysis compared to the clustering approach used in GKG 1.0, and what new analytic opportunities does GCAM enable through its multilingual and realtime capabilities?","['adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening \nentirely new analytic opportunities.  Some of the most significant changes: \n \n\uf0b7 \nRealtime Measurement of 2,300 Emotions and Themes.  The GDELT Global Content Analysis \nMeasures (GCAM) module represents what we believe is the largest deployment of sentiment \nanalysis in the world: bringing together 24 emotional measurement packages that together \nassess more than 2,300 emotions and themes from every article in realtime, multilingual \ndimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, \nFrench, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and \nUrdu).  GCAM is designed to enable unparalleled assessment of the emotional undercurrents \nand reaction at a planetary scale by bringing together an incredible array of dimensions, from \nLIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”. \n\uf0b7 \nRealtime Translation of 65 Languages.  GDELT 2.0 brings with it the public debut of GDELT \nTranslingual, representing what we believe is the largest realtime streaming news machine \ntranslation deployment in the world: all global news that GDELT monitors in 65 languages, \nrepresenting 98.4% of its daily non-English monitoring volume, is translated in realtime into \nEnglish for processing through the entire GDELT Event and GKG/GCAM pipelines.  GDELT \nTranslingual is designed to allow GDELT to monitor the entire planet at full volume, creating the \nvery first glimpses of a world without language barriers.  The GKG system now processes every \nnews report monitored by GDELT across these 65 languages, making it possible to trace people, \norganizations, locations, themes, and emotions across languages and media systems. \n\uf0b7 \nRelevant Imagery, Videos, and Social Embeds.  A large fraction of the world’s news outlets now \nspecify a hand-selected image for each article to appear when it is shared via social media that \nrepresents the core focus of the article.  GDELT identifies this imagery in a wide array of formats \nincluding Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats.  In addition, \nGDELT also uses a set of highly specialized algorithms to analyze the article content itself to \nidentify inline imagery of high likely relevance to the story, along with videos and embedded \nsocial media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is \ncompiled.  This makes it possible to gain a unique ground-level view into emerging situations \nanywhere in the world, even in those areas with very little social media penetration, and to act \nas a kind of curated list of social posts in those areas with strong social use. \n\uf0b7 \nQuotes, Names, and Amounts.  The world’s news contains a wealth of information on food \nprices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable \nitem.  GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to \noffer numeric context to global events.  In parallel, a new Names engine augments the existing \nPerson and Organization names engines by identifying an array of other kinds of proper names, \nsuch as named events (Orange Revolution / Umbrella Movement), occurrences like the World \nCup, named dates like Holocaust Remembrance Day, on through named legislation like Iran \nNuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative.  Finally, \nGDELT also identifies attributable quotes from each article, making it possible to see the \nevolving language used by political leadership across the world. \n\uf0b7 \nDate Mentions.  We’ve heard from many of you the desire to encode the list of date references \nfound in news articles and documents in order to identify repeating mentions of specific dates \nas possible “anniversary violence” indicators.  All day, month, and year dates are now extracted \nfrom each document. \n\uf0b7 \nProximity Context.  Perhaps the greatest change to the overall format from version 1.0 is the \nintroduction of the new Proximity Context capability.  The GKG records an enormously rich array', '\uf0b7 \nSingle Data File.  Previously there were two separate GKG data files, one containing Counts only \nand one containing the full GKG file.  The original rationale for having two separate files was that \nusers interested only in counts could download a much smaller daily file, but in practice nearly \nall applications use the full GKG file in order to make use of its thematic and other data fields to \ncontextualize those counts and to tie them into the GDELT Event Database.  Thus, we are \neliminating the separate counts-only file to simplify the GKG data environment. \n\uf0b7 \nProduction Status.  The GKG has now moved out of Alpha Experimental Release status and into \nproduction status.  This means that the file format is now stabilized and will not change. \n \nDIFFERENCES FROM GKG 2.0 \n \nThe GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were \nreleased in that format.  With the debut of the GKG 2.1 format in February 2015, the format has \nremained largely the same, but with the addition of several new fields to accommodate a number of \nsignificant enhancements to the GKG system.  While it was originally intended to release these new \nfeatures in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these \nfields, the desire to more closely align some of them with the format used for the Events dataset, and \nthe need to enable structural mapping of several of the fields to a forthcoming new hierarchical \nrepresentation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to \naccommodate these goals.  Users will find that code designed for the GKG 2.0 format can be adapted to \nthe GKG 2.1 format with minimal modification.  Since the GKG 2.0 format was only used for a handful of \nspecial subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 \ncompatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be \nsupported for news content.   \n \nFrom a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 \nrevolve around how entries are clustered and the minimum criteria for an article to be included in the \nGKG stream.  Under the GKG 1.0 format, a deduplication process similar to that used for the Event \nstream was applied to the daily GKG export, grouping together all articles yielding the same GKG \nmetadata.  Thus, two articles listing the same set of locations, themes, people, and organizations would \nbe grouped together in a single row with NumArticles holding a value of 2.  With the introduction of the \nnew GCAM system that assess more than 2,300 emotions and themes for each article, it became clear \nthat the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, \nthemes, people, and organizations might use very different language to discuss them, yielding very \ndifferent GCAM scores.  In addition, the introduction of realtime translation into the GDELT architecture \nnecessitated the ability to identify the provenance of metadata at the document level.  Thus, GKG 2.1 no \nlonger clusters documents together based on shared metadata – if 20 articles all contain the same list of \nextracted locations, themes, people, and organizations, they will appear as 20 separate entries in the \nGKG stream.  The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering.  \nIn addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article \nto appear in the GKG.  Under GKG 1.0 and 2.0, an article was required to have at least one successfully \nidentified and geocoded geographic location before it would be included in the GKG output.  However, \nmany topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy \ndiscussions, often do not have strong geographic centering, with many articles not mentioning even a \nsingle location.  This was excluding a considerable amount of content from the GKG system that is of \nhigh relevance to many GDELT user communities.  Thus, beginning with GKG 2.1, an article is included in \nthe GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional \nscores.  An article that contains no recognizable geographic mentions, but lists several political leaders,', 'THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', 'of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.', '[23, 28].\nThroughout this work we use the GDELT dataset as a case study.\nGDELT is a massive collection of\nnews reports that provide a real-time computational record of global events that is published every 15\nminutes. It aggregates information from various news sources, blogs, and social media platforms to construct\na large collection of data including information on people, organizations, locations, themes, and emotions.\nEssentially, GDELT offers a snapshot of the world’s collective events, enabling researchers and analysts to\nexplore complex patterns and relationships within global society. By analyzing this data, it’s possible to\nidentify emerging trends, assess risks, understand public sentiment, and track the evolution of various issues\nover time. The applications of GDELT are diverse and far-reaching. Some of the most common use cases\nincluding event monitoring [16, 17, 29], risk assessment and prediction [6, 19, 20, 24, 26, 30], and social\nscience research [2, 3, 4, 12].\nGDELT describes its structure as a Global Knowledge Graph (GKG, specifically, we use the the Global\nKnowledge Graph edition 2 (GKG2) of GDELT). But in fact GDELT-GKG2 is implemented as multiple\nlinked tables recording information about the relationship between articles and events, and thus effectively\nhas the structure of a relational database. Another important contribution of this paper is to actually realize\nGKG2 properly in the mathematical form of a KG, effectively a graph database, derived from and consistent\nwith its native relational database form. To facilitate this effort, we have identified a lightweight ontology\nfor GDELT in the form of its graph schema, realizing its relational database schema in a KG form.\nUsing the KG that we construct from the GDELT-GKG2 dataset, we provide a case study to explore the\nutility of LLM-based tools to extract information and confirm that the KG can be used for question-answering\nin cases where traditional RAG fails. As part of our analysis, we compare to KGs produced from processing\nvarious news articles with an LLM, prompting it to try and adhere to a reduced version of the same ontology.\nThe current state of neurosymbolic work is noted for the plethora of experimental architectures available.\nWhile details are explicated below in Section 3.2, we preview ours in Figure 1, including the five method-\nological pathways which are quantitatively compared: 1) graph queries on the KG (called the DKG) derived\n“directly” from GKG2; 2) use of G-Retriever2 [7] against the same DKG; 3) RAG against a vector store\nrepresentation of GKG2; 4) G-Retriever against a second KG (called the LKG) derived from using Llamain-\ndex3 [1] against the GDELT source articles; and 5) GraphRAG4 Q&A deployed against a third KG (called\nGRKG) using Microsoft’s open-source GraphRAG package with default configuration parameters.\nFigure 1: Pipeline of different experiments ran to analyze the GDELT database using an LLM.\n2https://github.com/XiaoxinHe/G-Retriever\n3https://www.llamaindex.ai/\n4https://microsoft.github.io/graphrag/\n2', 'o Word Count.  (integer)  This is the total number of words in the document.  This field \nwas added in version 1.5 of the format. \n\uf0b7 \nV2.1ENHANCEDDATES.  (semicolon-delimited blocks, with comma-delimited fields)  This \ncontains a list of all date references in the document, along with the character offsets of \napproximately where in the document they were found.  If a date was mentioned multiple times \nin a document, it will appear multiple times in this field, once for each mention.  Each date \nreference is separated by a semicolon, while the fields within a date are separated by commas.  \nNOTE: this field is identical to GKG 2.0 with the sole exception of the addition of one additional \nDate Resolution type (4 = dates that include a month and day, but not a year). \no Date Resolution.  This indicates whether the date was a month-day date that did not \nspecify a year (4), a fully-resolved day-level date that included the year (3), a month-\nlevel date that included the year but not a day (2), or a year-level (1) date that did not \ninclude month or day-level information. \no Month.  This is the month of the date represented as 1-12.  For year dates this field will \ncontain a 0. \no Day. This is the day of the date represented as 1-31.  For month and year dates this field \nwill contain a 0.  \no Year.  This is the year of the date.  For Resolution=4 dates that include a month and day, \nbut not a year, this field will contain a 0. \no Offset.  This is the character offset of the date within the document, indicating \napproximately where it was found in the body.  This can be used to associate the date \nwith the entries from other “V2ENHANCED” fields that appeared in closest proximity to \nit. \n\uf0b7 \nV2GCAM.  (comma-delimited blocks, with colon-delimited key/value pairs)  The Global Content \nAnalysis Measures (GCAM) system runs an array of content analysis systems over each \ndocument and compiles their results into this field.  New content analysis systems will be \nconstantly added to the GCAM pipeline over time, meaning the set of available fields will \nconstantly grow over time.  Given that the GCAM system is debuting with over 2,300 dimensions \nand will likely grow to include several thousand more dimensions within the coming months, it \ndiffers in its approach to encoding matches from the GKG’s native thematic coding system.  \nInstead of displaying the full English name of a content analysis dictionary or dimension, it \nassigns each dictionary a unique numeric identifier (DictionaryID) and each dimension within \nthat dictionary is assigned a unique identifier from 1 to the number of dimensions in the \ndictionary (DimensionID).  Each dimension of each dictionary is assessed on a document and \nONLY those dimensions that had one or more matches onto the document are reported.  If a \ndimension did not register any matches on a document, it is not reported in order to save space.  \nThus, the absence of a dimension in this field can be interpreted as a score of 0.  Each \ndimension’s score is written to the V2GCAM field separated by a comma.  For each dimension, a \nnumeric “key” identifies it of the form “DictionaryID.DimensionID”, followed by a colon, \nfollowed by its score.  Most dictionaries are count-based, meaning they report how many words \nin the document were found in that dictionary.  Thus, a score of 18 would mean that 18 words \nfrom the document were found in that dictionary.  Count-based dimensions have a key that \nbegins with “c”.  Some dictionaries, such as SentiWordNet and SentiWords actually assign each \nword a numeric score and the output of the tool is the average of those scores for that \ndocument.  For those dictionaries, an entry will report the number of words in the document \nthat matched into that dictionary, and a separate entry, beginning with a “v” instead of a “c” will \nreport its floating-point average value.  The very first entry in the field has the special reserved \nkey of “wc” and reports the total number of words in the document – this can be used to divide']","The introduction of the GCAM (Global Content Analysis Measures) system in the GKG 2.1 format significantly enhances the granularity and scope of emotional and thematic analysis compared to the clustering approach used in GKG 1.0, and it enables new analytic opportunities through its multilingual and realtime capabilities. The key enhancements and opportunities are as follows:

### Enhanced Granularity and Scope Compared to GKG 1.0 Clustering

1. **From Clustering to Individual Document-Level Analysis:**
   - **GKG 1.0 Approach:** Articles were clustered together if they shared the same metadata (locations, themes, people, organizations), resulting in a single row representing multiple articles with a count of how many articles matched that metadata. This clustering obscured differences in language and emotional tone between articles that otherwise shared metadata.
   - **GKG 2.1 with GCAM:** Each article is treated as a separate entry in the GKG stream, even if multiple articles share the same metadata. This is necessary because GCAM assesses over 2,300 emotions and themes per article, and articles with identical metadata can have very different emotional and thematic profiles. This shift allows for much finer granularity in emotional and thematic analysis at the individual document level.

2. **Massive Expansion of Emotional and Thematic Dimensions:**
   - GCAM integrates 24 emotional measurement packages, collectively assessing more than 2,300 emotions and themes per article. This is a substantial increase in the depth and breadth of emotional and thematic coding compared to previous versions.
   - The system includes a wide array of emotional dimensions, from LIWC’s “Anxiety” to Lexicoder’s “Positivity,” WordNet Affect’s “Smugness,” and RID’s “Passivity,” enabling nuanced and multifaceted emotional analysis.

3. **Inclusion of Articles Without Geographic Metadata:**
   - Unlike GKG 1.0, which required at least one geocoded location for an article to be included, GKG 2.1 includes articles based on any successfully extracted information, including GCAM emotional scores. This broadens the scope of the dataset to include articles on topics without geographic references (e.g., cybersecurity, constitutional discourse), increasing thematic coverage.

### New Analytic Opportunities Enabled by GCAM’s Multilingual and Realtime Capabilities

1. **Realtime Measurement:**
   - GCAM processes every article in realtime, enabling immediate assessment of emotional and thematic content as news is published. This allows analysts to track emotional undercurrents and thematic trends on a planetary scale with minimal delay.

2. **Multilingual Native Assessment:**
   - GCAM natively assesses emotions and themes in 15 languages (including Arabic, Chinese, French, Hindi, Russian, Spanish, and others), allowing direct emotional and thematic analysis without relying solely on translation.
   - This native multilingual capability preserves linguistic nuances and cultural context in emotional expression, improving the accuracy and richness of analysis.

3. **Realtime Translation of 65 Languages:**
   - GDELT Translingual translates news from 65 languages in realtime into English, covering 98.4% of non-English news volume monitored by GDELT.
   - This enables GCAM and the broader GKG system to process and analyze global news content across virtually all major languages, breaking down language barriers and allowing cross-lingual comparison and aggregation of emotional and thematic data.

4. **Document-Level Provenance and Unique Identifiers:**
   - Each GKG 2.1 record has a unique identifier, including a marker for whether the document was translated, enabling precise tracking and filtering of multilingual content.
   - This supports detailed provenance analysis and the ability to distinguish between original and translated content in analyses.

5. **Proximity Context and Rich Metadata:**
   - GKG 2.1 introduces proximity context fields that provide approximate character offsets of references within articles, allowing analysts to associate emotions and themes with specific people, places, or events mentioned in close textual proximity.
   - This enhances the ability to perform contextualized emotional and thematic analysis within documents.

### Summary

- **Compared to GKG 1.0’s clustering approach, GCAM in GKG 2.1 enables much finer-grained, article-level emotional and thematic analysis, capturing subtle differences in language and sentiment that clustering obscured.**
- **The system’s assessment of over 2,300 emotions and themes vastly expands the scope of analysis.**
- **Inclusion of articles without geographic metadata broadens thematic coverage.**
- **Realtime and multilingual native processing, combined with realtime translation of 65 languages, open new opportunities for global-scale, cross-lingual emotional and thematic monitoring and analysis.**
- **Unique record identifiers and proximity context fields further enhance analytic precision and contextual understanding.**

These enhancements collectively enable researchers and analysts to conduct more detailed, timely, and globally comprehensive studies of emotional and thematic trends in the world’s news media.","The introduction of the GCAM system in the GKG 2.1 format fundamentally changes how articles are represented by no longer clustering documents based on shared metadata, as was done in GKG 1.0. Under GKG 1.0, articles with identical locations, themes, people, and organizations were grouped together, which was insufficient for GCAM because multiple articles with the same metadata could express very different emotions and themes, resulting in distinct GCAM scores. GCAM assesses more than 2,300 emotions and themes for each article in realtime, across 15 languages natively, enabling a highly granular and nuanced emotional and thematic analysis at a planetary scale. This shift allows GKG 2.1 to include articles even without geographic mentions, broadening the scope of content captured. Furthermore, GCAM’s realtime multilingual sentiment analysis, combined with GDELT’s realtime translation of 65 languages, opens entirely new analytic opportunities by enabling the tracing of emotional undercurrents and reactions globally without language barriers. This includes the ability to analyze a vast array of emotional dimensions from multiple established measurement packages, providing unparalleled insight into global news content and its emotional context."
How do the Actor1Geo and Location fields utilize FIPS10-4 codes to specify geographic locations at different administrative levels in the dataset?,"['\uf0b7 \nActor1Geo_Type.  (integer) This field specifies the geographic resolution of the match type and \nholds one of the following values:  1=COUNTRY (match was at the country level), 2=USSTATE \n(match was to a US state), 3=USCITY (match was to a US city or landmark), 4=WORLDCITY \n(match was to a city or landmark outside the US), 5=WORLDSTATE (match was to an \nAdministrative Division 1 outside the US – roughly equivalent to a US state).  This can be used to \nfilter events by geographic specificity, for example, extracting only those events with a \nlandmark-level geographic resolution for mapping.  Note that matches with codes 1 (COUNTRY), \n2 (USSTATE), and 5 (WORLDSTATE) will still provide a latitude/longitude pair, which will be the \ncentroid of that country or state, but the FeatureID field below will be blank. \n\uf0b7 \nActor1Geo_Fullname.  (string) This is the full human-readable name of the matched location.  In \nthe case of a country it is simply the country name.  For US and World states it is in the format of \n“State, Country Name”, while for all other matches it is in the format of “City/Landmark, State, \nCountry”.  This can be used to label locations when placing events on a map.  NOTE: this field \nreflects the precise name used to refer to the location in the text itself, meaning it may contain \nmultiple spellings of the same location – use the FeatureID column to determine whether two \nlocation names refer to the same place. \n\uf0b7 \nActor1Geo_CountryCode.  (string) This is the 2-character FIPS10-4 country code for the location. \n\uf0b7 \nActor1Geo_ADM1Code.  (string). This is the 2-character FIPS10-4 country code followed by the \n2-character FIPS10-4 administrative division 1 (ADM1) code for the administrative division \nhousing the landmark.  In the case of the United States, this is the 2-character shortform of the \nstate’s name (such as “TX” for Texas). \n\uf0b7 \nActor1Geo_ADM2Code.  (string).  For international locations this is the numeric Global \nAdministrative Unit Layers (GAUL) administrative division 2 (ADM2) code assigned to each global \nlocation, while for US locations this is the two-character shortform of the state’s name (such as \n“TX” for Texas) followed by the 3-digit numeric county code (following the INCITS 31:200x \nstandard used in GNIS).  For more detail on the contents and computation of this field, please \nsee the following footnoted URL. 5  NOTE:  This field may be blank/null in cases where no ADM2 \ninformation was available, for some ADM1-level matches, and for all country-level matches.  \nNOTE: this field may still contain a value for ADM1-level matches depending on how they are \ncodified in GNS. \n\uf0b7 \nActor1Geo_Lat.  (floating point) This is the centroid latitude of the landmark for mapping. \n\uf0b7 \nActor1Geo_Long.  (floating point) This is the centroid longitude of the landmark for mapping. \n\uf0b7 \nActor1Geo_FeatureID.  (string). This is the GNS or GNIS FeatureID for this location.  More \ninformation on these values can be found in Leetaru (2012).6  NOTE: When Actor1Geo_Type has \na value of 3 or 4 this field will contain a signed numeric value, while it will contain a textual \nFeatureID in the case of other match resolutions (usually the country code or country code and \nADM1 code).  A small percentage of small cities and towns may have a blank value in this field \neven for Actor1Geo_Type values of 3 or 4: this will be corrected in the 2.0 release of GDELT.  \nNOTE: This field can contain both positive and negative numbers, see Leetaru (2012) for more \ninformation on this. \n \nThese codes are repeated for Actor2 and Action, using those prefixes. \n \nDATA MANAGEMENT FIELDS \n \n                                                          \n5 http://blog.gdeltproject.org/global-second-order-administrative-divisions-now-available-from-gaul/ \n6 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html', 'proximity to it.  If a theme is mentioned multiple times in a document, each mention will appear \nseparately in this field. \n\uf0b7 \nV1LOCATIONS.  (semicolon-delimited blocks, with pound symbol (“#”) delimited fields)  This is a \nlist of all locations found in the text, extracted through the Leetaru (2012) algorithm. 2  The \nalgorithm is run in a more aggressive stance here than ordinary in order to extract every \npossible locative referent, so may have a slightly elevated level of false positives.  NOTE: some \nlocations have multiple accepted formal or informal names and this field is collapsed on name, \nrather than feature (since in some applications the understanding of a geographic feature differs \nbased on which name was used to reference it).  In cases where it is necessary to collapse by \nfeature, the Geo_FeatureID column should be used, rather than the Geo_Fullname column.  This \nis because the Geo_Fullname column captures the name of the location as expressed in the text \nand thus reflects differences in transliteration, alternative spellings, and alternative names for \nthe same location.  For example, Mecca is often spelled Makkah, while Jeddah is commonly \nspelled Jiddah or Jaddah.  The Geo_Fullname column will reflect each of these different \nspellings, while the Geo_FeatureID column will resolve them all to the same unique GNS or GNIS \nfeature identification number.  For more information on the GNS and GNIS identifiers, see \nLeetaru (2012). 3  This field is identical in format and population as the corresponding field in the \nGKG 1.0  format.  NOTE: there was an error in this field from 2/19/2015 through midday \n3/1/2015 that caused the CountryCode field to list the wrong country code in some cases. \no Location Type.  (integer) This field specifies the geographic resolution of the match type \nand holds one of the following values:  1=COUNTRY (match was at the country level), \n2=USSTATE (match was to a US state), 3=USCITY (match was to a US city or landmark), \n4=WORLDCITY (match was to a city or landmark outside the US), 5=WORLDSTATE \n(match was to an Administrative Division 1 outside the US – roughly equivalent to a US \nstate).  This can be used to filter counts by geographic specificity, for example, \nextracting only those counts with a landmark-level geographic resolution for mapping.  \nNote that matches with codes 1 (COUNTRY), 2 (USSTATE), and 5 (WORLDSTATE) will still \nprovide a latitude/longitude pair, which will be the centroid of that country or state, but \nthe FeatureID field below will contain its textual country or ADM1 code instead of a \nnumeric featureid. \no Location FullName.  (text) This is the full human-readable name of the matched \nlocation.  In the case of a country it is simply the country name.  For US and World states \nit is in the format of “State, Country Name”, while for all other matches it is in the \nformat of “City/Landmark, State, Country”.  This can be used to label locations when \nplacing counts on a map.  Note: this field reflects the precise name used to refer to the \nlocation in the text itself, meaning it may contain multiple spellings of the same location \n– use the FeatureID column to determine whether two location names refer to the same \nplace. \no Location CountryCode.  (text) This is the 2-character FIPS10-4 country code for the \nlocation.  Note: GDELT continues to use the FIPS10-4 codes under USG guidance while \nGNS continues its formal transition to the successor Geopolitical Entities, Names, and \nCodes (GENC) Standard (the US Government profile of ISO 3166). \no Location ADM1Code.  (text) This is the 2-character FIPS10-4 country code followed by \nthe 2-character FIPS10-4 administrative division 1 (ADM1) code for the administrative \ndivision housing the landmark.  In the case of the United States, this is the 2-character \n                                                          \n2 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html \n3 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html', 'shortform of the state’s name (such as “TX” for Texas).  Note: see the notice above for \nCountryCode regarding the FIPS10-4 / GENC transition.  Note: to obtain ADM2 (district-\nlevel) assignments for locations, you can either perform a spatial join against a ShapeFile \ntemplate in any GIS software, or cross-walk the FeatureID to the GNIS/GNS databases – \nthis will provide additional fields such as ADM2 codes and MGRS grid references for \nGNS. \no Location Latitude.  (floating point number) This is the centroid latitude of the landmark \nfor mapping.  In the case of a country or administrative division this will reflect the \ncentroid of that entire country/division. \no Location Longitude.  (floating point number) This is the centroid longitude of the \nlandmark for mapping.  In the case of a country or administrative division this will reflect \nthe centroid of that entire country/division. \no Location FeatureID.  (text OR signed integer) This is the numeric GNS or GNIS FeatureID \nfor this location OR a textual country or ADM1 code.  More information on these values \ncan be found in Leetaru (2012).4  Note: This field will be blank or contain a textual ADM1 \ncode for country or ADM1-level matches – see above.  Note: For numeric GNS or GNIS \nFeatureIDs, this field can contain both positive and negative numbers, see Leetaru \n(2012) for more information on this. \n\uf0b7 \nV2ENHANCEDLOCATIONS.  (semicolon-delimited blocks, with pound symbol (“#”) delimited \nfields)  This field is identical to the V1LOCATIONS field with the primary exception of an extra \nfield appended to the end of each location block after its FeatureID that lists the approximate \ncharacter offset of the reference to that location in the text.  In addition, if a location appears \nmultiple times in the article, it will be listed multiple times in this field.  The only other \nmodification from V1LOCATIONS is the addition of a single new field “Location ADM2Code” in \nbetween “Location ADM1Code” and “Location Latitude”. 5  NOTE: there was an error in this field \nfrom 2/19/2015 through midday 3/1/2015 that caused the CountryCode field to list the wrong \ncountry code in some cases. \n\uf0b7 \nV1PERSONS.  (semicolon-delimited)  This is the list of all person names found in the text, \nextracted through the Leetaru (2012) algorithm. 6  This name recognition algorithm is unique in \nthat it is specially designed to recognize the African, Asian, and Middle Eastern names that yield \nsignificantly reduced accuracy with most name recognition engines.  This field is identical in \nformat and population as the corresponding field in the GKG 1.0  format. \n\uf0b7 \nV2ENHANCEDPERSONS.  (semicolon-delimited blocks, with comma-delimited fields)  This \ncontains a list of all person names referenced in the document, along with the character offsets \nof approximately where in the document they were found.  Each person reference is separated \nby a semicolon, and within each reference, the person name is specified first, followed by a \ncomma, and then the approximate character offset of the reference of that person in the \ndocument, allowing it to be associated with other entries from other “V2ENHANCED” fields that \nappear in closest proximity to it.  If a person is mentioned multiple times in a document, each \nmention will appear separately in this field. \n\uf0b7 \nV1ORGANIZATIONS.  (semicolon-delimited)  This is the list of all company and organization \nnames found in the text, extracted through the Leetaru (2012) algorithm. 7  This is a \ncombination of corporations, IGOs, NGOs, and any other local organizations such as a local fair \n                                                          \n4 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html \n5 http://blog.gdeltproject.org/global-second-order-administrative-divisions-now-available-from-gaul/ \n6 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html \n7 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html', 'organizational classes like Non-Governmental Movement.  Special codes such as Moderate and \nRadical may refer to the operational strategy of a group. \n\uf0b7 \nActor1Type2Code.  (string) If multiple type/role codes are specified for Actor1, this returns the \nsecond code. \n\uf0b7 \nActor1Type3Code.  (string) If multiple type/role codes are specified for Actor1, this returns the \nthird code. \n \nThe fields above are repeated for Actor2.  The set of fields above are repeated, but each is prefaced with \n“Actor2” instead of “Actor1”.  The definitions and values of each field are the same as above. \n \n \nEVENT ACTION ATTRIBUTES \n \nThe following fields break out various attributes of the event “action” (what Actor1 did to Actor2) and \noffer several mechanisms for assessing the “importance” or immediate-term “impact” of an event.  \nNOTE: the various fields in this section recording the amount of coverage an event has received are \nincluded solely for legacy purposes – the new Mentions table should be used instead in most cases. \n \n\uf0b7 \nIsRootEvent.  (integer) The system codes every event found in an entire document, using an \narray of techniques to deference and link information together.  A number of previous projects \nsuch as the ICEWS initiative have found that events occurring in the lead paragraph of a \ndocument tend to be the most “important.”  This flag can therefore be used as a proxy for the \nrough importance of an event to create subsets of the event stream.  NOTE: this field refers only \nto the first news report to mention an event and is not updated if the event is found in a \ndifferent context in other news reports.  It is included for legacy purposes – for more precise \ninformation on the positioning of an event, see the Mentions table. \n\uf0b7 \nEventCode.  (string) This is the raw CAMEO action code describing the action that Actor1 \nperformed upon Actor2.  NOTE: it is strongly recommended that this field be stored as a string \ninstead of an integer, since the CAMEO taxonomy can include zero-leaded event codes that can \nmake distinguishing between certain event types more difficult when stored as an integer. \n\uf0b7 \nEventBaseCode.  (string) CAMEO event codes are defined in a three-level taxonomy.  For events \nat level three in the taxonomy, this yields its level two leaf root node.  For example, code “0251” \n(“Appeal for easing of administrative sanctions”) would yield an EventBaseCode of “025” \n(“Appeal to yield”).  This makes it possible to aggregate events at various resolutions of \nspecificity.  For events at levels two or one, this field will be set to EventCode.  NOTE: it is \nstrongly recommended that this field be stored as a string instead of an integer, since the \nCAMEO taxonomy can include zero-leaded event codes that can make distinguishing between \ncertain event types more difficult when stored as an integer. \n\uf0b7 \nEventRootCode.  (string) Similar to EventBaseCode, this defines the root-level category the \nevent code falls under.  For example, code “0251” (“Appeal for easing of administrative \nsanctions”) has a root code of “02” (“Appeal”).  This makes it possible to aggregate events at \nvarious resolutions of specificity.  For events at levels two or one, this field will be set to \nEventCode.  NOTE: it is strongly recommended that this field be stored as a string instead of an \ninteger, since the CAMEO taxonomy can include zero-leaded event codes that can make \ndistinguishing between certain event types more difficult when stored as an integer. \n\uf0b7 \nQuadClass.  (integer) The entire CAMEO event taxonomy is ultimately organized under four \nprimary classifications: Verbal Cooperation, Material Cooperation, Verbal Conflict, and Material', 'occurrence described in the context of a more positive narrative (such as a report of an attack \noccurring in a discussion of improving conditions on the ground in a country and how the \nnumber of attacks per day has been greatly reduced).  NOTE: this field refers only to the first \nnews report to mention an event and is not updated if the event is found in a different context \nin other news reports.  It is included for legacy purposes – for more precise information on the \npositioning of an event, see the Mentions table.  NOTE: this provides only a basic tonal \nassessment of an article and it is recommended that users interested in emotional measures use \nthe Mentions and Global Knowledge Graph tables to merge the complete set of 2,300 emotions \nand themes from the GKG GCAM system into their analysis of event records. \n \nEVENT GEOGRAPHY \n \nThe final set of fields add a novel enhancement to the CAMEO taxonomy, georeferencing each event \nalong three primary dimensions to the landmark-centroid level.  To do this, the fulltext of the source \ndocument is processed using fulltext geocoding and automatic disambiguation to identify every \ngeographic reference.3  The closest reference to each of the two actors and to the action reference are \nthen encoded in these fields.  The georeferenced location for an actor may not always match the \nActor1_CountryCode or Actor2_CountryCode field, such as in a case where the President of Russia is \nvisiting Washington, DC in the United States, in which case the Actor1_CountryCode would contain the \ncode for Russia, while the georeferencing fields below would contain a match for Washington, DC.  It \nmay not always be possible for the system to locate a match for each actor or location, in which case \none or more of the fields may be blank.  The Action fields capture the location information closest to the \npoint in the event description that contains the actual statement of action and is the best location to use \nfor placing events on a map or in other spatial context.   \n \nTo find all events located in or relating to a specific city or geographic landmark, the Geo_FeatureID \ncolumn should be used, rather than the Geo_Fullname column.  This is because the Geo_Fullname \ncolumn captures the name of the location as expressed in the text and thus reflects differences in \ntransliteration, alternative spellings, and alternative names for the same location.  For example, Mecca \nis often spelled Makkah, while Jeddah is commonly spelled Jiddah or Jaddah.  The Geo_Fullname column \nwill reflect each of these different spellings, while the Geo_FeatureID column will resolve them all to the \nsame unique GNS or GNIS feature identification number.  For more information on the GNS and GNIS \nidentifiers, see Leetaru (2012). 4 \n \nWhen looking for events in or relating to a specific country, such as Syria, there are two possible filtering \nmethods.  The first is to use the Actor_CountryCode fields in the Actor section to look for all actors \nhaving the SYR (Syria) code.  However, conflict zones are often accompanied by high degrees of \nuncertainty in media reporting and a news article might mention only “Unidentified gunmen stormed a \nhouse and shot 12 civilians.”  In this case, the Actor_CountryCode fields for Actor1 and Actor2 would \nboth be blank, since the article did not specify the actor country affiliations, while their \nGeo_CountryCode values (and the ActorGeo_CountryCode for the event) would specify Syria.  This can \nresult in dramatic differences when examining active conflict zones.  The second method is to examine \nthe ActorGeo_CountryCode for the location of the event.  This will also capture situations such as the \nUnited States criticizing a statement by Russia regarding a specific Syrian attack. \n \n                                                          \n3 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html \n4 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html', 'terrorists,” but the TABARI ACTORS dictionary labels that group as “Insurgents,” the latter label will be \nused. Use the GDELT Global Knowledge Graph to enrich actors with additional information from the rest \nof the article.  NOTE: the CountryCode field reflects a combination of information from the TABARI \nACTORS dictionary and text, with the ACTORS dictionary taking precedence, and thus if the text refers to \n“French Assistant Minister Smith was in Moscow,” the CountryCode field will list France in the \nCountryCode field, while the geographic fields discussed at the end of this manual may list Moscow as \nhis/her location.  NOTE: One of the two actor fields may be blank in complex or single-actor situations or \nmay contain only minimal detail for actors such as “Unidentified gunmen.” \n \nGDELT currently uses the CAMEO version 1.1b3 taxonomy.  For more information on what each specific \ncode in the fields below stands for and the complete available taxonomy of the various fields below, \nplease see the CAMEO User Manual 1 or the GDELT website for crosswalk files.2 \n \n\uf0b7 \nActor1Code.  (string) The complete raw CAMEO code for Actor1 (includes geographic, class, \nethnic, religious, and type classes).  May be blank if the system was unable to identify an Actor1. \n\uf0b7 \nActor1Name.  (string) The actual name of the Actor1.  In the case of a political leader or \norganization, this will be the leader’s formal name (GEORGE W BUSH, UNITED NATIONS), for a \ngeographic match it will be either the country or capital/major city name (UNITED STATES / \nPARIS), and for ethnic, religious, and type matches it will reflect the root match class (KURD, \nCATHOLIC, POLICE OFFICER, etc).  May be blank if the system was unable to identify an Actor1. \n\uf0b7 \nActor1CountryCode.  (string) The 3-character CAMEO code for the country affiliation of Actor1.  \nMay be blank if the system was unable to identify an Actor1 or determine its country affiliation \n(such as “UNIDENTIFIED GUNMEN”). \n\uf0b7 \nActor1KnownGroupCode. (string) If Actor1 is a known IGO/NGO/rebel organization (United \nNations, World Bank, al-Qaeda, etc) with its own CAMEO code, this field will contain that code. \n\uf0b7 \nActor1EthnicCode.  (string) If the source document specifies the ethnic affiliation of Actor1 and \nthat ethnic group has a CAMEO entry, the CAMEO code is entered here.  NOTE: a few special \ngroups like ARAB may also have entries in the type column due to legacy CAMEO behavior.  \nNOTE: this behavior is highly experimental and may not capture all affiliations properly – for \nmore comprehensive and sophisticated identification of ethnic affiliation, it is recommended \nthat users use the GDELT Global Knowledge Graph’s ethnic, religious, and social group \ntaxonomies and post-enrich actors from the GKG. \n\uf0b7 \nActor1Religion1Code. (string) If the source document specifies the religious affiliation of Actor1 \nand that religious group has a CAMEO entry, the CAMEO code is entered here.  NOTE: a few \nspecial groups like JEW may also have entries in the geographic or type columns due to legacy \nCAMEO behavior.  NOTE: this behavior is highly experimental and may not capture all affiliations \nproperly – for more comprehensive and sophisticated identification of ethnic affiliation, it is \nrecommended that users use the GDELT Global Knowledge Graph’s ethnic, religious, and social \ngroup taxonomies and post-enrich actors from the GKG. \n\uf0b7 \nActor1Religion2Code.  (string) If multiple religious codes are specified for Actor1, this contains \nthe secondary code.  Some religion entries automatically use two codes, such as Catholic, which \ninvokes Christianity as Code1 and Catholicism as Code2. \n\uf0b7 \nActor1Type1Code.  (string) The 3-character CAMEO code of the CAMEO “type” or “role” of \nActor1, if specified.  This can be a specific role such as Police Forces, Government, Military, \nPolitical Opposition, Rebels, etc, a broad role class such as Education, Elites, Media, Refugees, or \n                                                          \n1 http://gdeltproject.org/data/documentation/CAMEO.Manual.1.1b3.pdf  \n2 http://gdeltproject.org/', 'EVENT TABLE \n \nEVENTID AND DATE ATTRIBUTES \n \nThe first few fields of an event record capture its globally unique identifier number, the date the event \ntook place on, and several alternatively formatted versions of the date designed to make it easier to \nwork with the event records in different analytical software programs that may have specific date \nformat requirements.  The parenthetical after each variable name gives the datatype of that field. \n \nNote that even though GDELT 2.0 operates at a 15 minute resolution, the date fields in this section still \nrecord the date at the daily level, since this is the resolution that event analysis has historically been \nperformed at.  To examine events at the 15 minute resolution, use the DATEADDED field (the second \nfrom the last field in this table at the end).  \n \n\uf0b7 \nGlobalEventID.  (integer) Globally unique identifier assigned to each event record that uniquely \nidentifies it in the master dataset.  NOTE: While these will often be sequential with date, this is \nNOT always the case and this field should NOT be used to sort events by date: the date fields \nshould be used for this.  NOTE: There is a large gap in the sequence between February 18, 2015 \nand February 19, 2015 with the switchover to GDELT 2.0 – these are not missing events, the ID \nsequence was simply reset at a higher number so that it is possible to easily distinguish events \ncreated after the switchover to GDELT 2.0 from those created using the older GDELT 1.0 system. \n\uf0b7 \nDay.  (integer) Date the event took place in YYYYMMDD format.  See DATEADDED field for \nYYYYMMDDHHMMSS date. \n\uf0b7 \nMonthYear.  (integer) Alternative formatting of the event date, in YYYYMM format. \n\uf0b7 \nYear.  (integer) Alternative formatting of the event date, in YYYY format. \n\uf0b7 \nFractionDate.  (floating point) Alternative formatting of the event date, computed as YYYY.FFFF, \nwhere FFFF is the percentage of the year completed by that day.  This collapses the month and \nday into a fractional range from 0 to 0.9999, capturing the 365 days of the year.  The fractional \ncomponent (FFFF) is computed as (MONTH * 30 + DAY) / 365.  This is an approximation and does \nnot correctly take into account the differing numbers of days in each month or leap years, but \noffers a simple single-number sorting mechanism for applications that wish to estimate the \nrough temporal distance between dates. \n \n \nACTOR ATTRIBUTES \n \nThe next fields describe attributes and characteristics of the two actors involved in the event.  This \nincludes the complete raw CAMEO code for each actor, its proper name, and associated attributes.  The \nraw CAMEO code for each actor contains an array of coded attributes indicating geographic, ethnic, and \nreligious affiliation and the actor’s role in the environment (political elite, military officer, rebel, etc).  \nThese 3-character codes may be combined in any order and are concatenated together to form the final \nraw actor CAMEO code.  To make it easier to utilize this information in analysis, this section breaks these \ncodes out into a set of individual fields that can be separately queried.  NOTE: all attributes in this \nsection other than CountryCode are derived from the TABARI ACTORS dictionary and are NOT \nsupplemented from information in the text.  Thus, if the text refers to a group as “Radicalized']","The **Actor1Geo** and **Location** fields in the dataset utilize **FIPS10-4 codes** to specify geographic locations at different administrative levels by encoding hierarchical geographic information in a structured manner. Here is how they do so:

### Geographic Resolution and Types
- Both **Actor1Geo_Type** and **Location Type** fields specify the geographic resolution of the location match using integer codes:
  - 1 = COUNTRY (country-level)
  - 2 = USSTATE (US state-level)
  - 3 = USCITY (US city or landmark)
  - 4 = WORLDCITY (city or landmark outside the US)
  - 5 = WORLDSTATE (Administrative Division 1 outside the US, roughly equivalent to a US state)

This allows filtering and distinguishing events by geographic specificity.

### Use of FIPS10-4 Codes in Fields

1. **Country Level (FIPS10-4 Country Code)**
   - **Actor1Geo_CountryCode** and **Location CountryCode** fields contain the 2-character FIPS10-4 country code for the location.
   - This code identifies the country uniquely according to the FIPS10-4 standard.
   - Example: For Syria, the country code would be the 2-character FIPS10-4 code assigned to Syria.

2. **Administrative Division 1 (ADM1) Level**
   - **Actor1Geo_ADM1Code** and **Location ADM1Code** fields contain a concatenation of:
     - The 2-character FIPS10-4 country code
     - Followed by the 2-character FIPS10-4 administrative division 1 (ADM1) code.
   - For the United States, the ADM1 code is the 2-character shortform of the state’s name (e.g., ""TX"" for Texas).
   - For other countries, the ADM1 code corresponds to the first-level administrative division as defined by FIPS10-4.
   - This allows specifying the state or province within a country.

3. **Administrative Division 2 (ADM2) Level**
   - **Actor1Geo_ADM2Code** and **Location ADM2Code** provide further granularity:
     - For international locations, this is the numeric GAUL ADM2 code.
     - For US locations, it is the 2-character state shortform plus a 3-digit county code (per INCITS 31:200x standard).
   - This field may be blank if ADM2 information is unavailable or if the match is at a higher geographic level (country or ADM1).

### Additional Geographic Fields
- **Actor1Geo_Fullname** and **Location FullName** provide human-readable names formatted according to the geographic level:
  - Country: just the country name.
  - US and World states: “State, Country Name”.
  - Cities/landmarks: “City/Landmark, State, Country”.
- **Actor1Geo_Lat** and **Actor1Geo_Long** (and corresponding Location Latitude/Longitude) provide centroid coordinates of the matched geographic entity.
- **Actor1Geo_FeatureID** and **Location FeatureID** contain unique GNS or GNIS feature identifiers or textual country/ADM1 codes depending on the geographic resolution.

### Summary
- The **Actor1Geo** and **Location** fields use the **FIPS10-4 country codes** to identify countries.
- They extend this by appending **FIPS10-4 ADM1 codes** to specify first-level administrative divisions (states/provinces).
- For finer granularity, ADM2 codes (GAUL numeric codes internationally, or state+county codes in the US) are used.
- This hierarchical coding system allows the dataset to specify geographic locations at multiple administrative levels consistently and enables filtering and mapping at country, state, and city/landmark levels.

Thus, the dataset leverages the FIPS10-4 coding scheme to encode geographic locations from broad country-level down to detailed administrative divisions, facilitating precise geographic referencing and analysis.","Both the Actor1Geo and Location fields use the 2-character FIPS10-4 country codes to specify geographic locations. Actor1Geo_CountryCode and Location CountryCode represent the country using these codes. For more detailed geographic resolution, Actor1Geo_ADM1Code and Location ADM1Code combine the 2-character FIPS10-4 country code with a 2-character FIPS10-4 administrative division 1 (ADM1) code to identify subdivisions such as US states or equivalent administrative divisions outside the US. This allows the dataset to specify locations at country and ADM1 levels consistently using FIPS10-4 codes."
"What are the key enhancements introduced in the GKG 2.1 format released in February 2015, and how does the availability of GDELT 2.0 event records starting February 19, 2015, relate to these changes?","['THE GDELT EVENT DATABASE \nDATA FORMAT CODEBOOK V2.0 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook provides a quick overview of the fields in the GDELT Event file format and their \ndescriptions.  GDELT Event records are stored in an expanded version of the dyadic CAMEO format, \ncapturing two actors and the action performed by Actor1 upon Actor2.  A wide array of variables break \nout the raw CAMEO actor codes into their respective fields to make it easier to interact with the data, \nthe Action codes are broken out into their hierarchy, the Goldstein ranking score is provided, a unique \narray of georeferencing fields offer estimated landmark-centroid-level geographic positioning of both \nactors and the location of the action, and a new “Mentions” table records the network trajectory of the \nstory of each event “in flight” through the global media system. \n \nAt present, only records from February 19, 2015 onwards are available in the GDELT 2.0 file format, \nhowever in late Spring 2015 the entire historical backfile back to 1979 will be released in the GDELT 2.0 \nformat.  The   Records are stored one per line, separated by a newline (\\n) and are tab-delimited (note \nthat files have a “.csv” extension, but are actually tab-delimited).   \n \nWith the release of GDELT 2.0, the daily GDELT 1.0 Event files will still be generated each morning at \nleast through the end of Spring 2015 to enable existing applications to continue to function without \nmodification.  Please note that at present, since GDELT 2.0 files are only available for events beginning \nFebruary 19, 2015, you will need to use GDELT 1.0 to examine longitudinal patterns (since it stretches \nback to January 1, 1979) and use GDELT 2.0 moving forward for realtime events. \n  \nThere are now two data tables created every 15 minutes for the GDELT Event dataset.  The first is the \ntraditional Event table.  This table is largely identical to the GDELT 1.0 format, but does have several \nchanges as noted below.  In addition to the Event table there is now a new Mentions table that records \nall mentions of each event.  As an event is mentioned across multiple news reports, each of those \nmentions is recorded in the Mentions table, along with several key indicators about that mention, \nincluding the location within the article where the mention appeared (in the lead paragraph versus \nbeing buried at the bottom) and the “confidence” of the algorithms in their identification of the event \nfrom that specific news report.  The Confidence measure is a new feature in GDELT 2.0 that makes it \npossible to adjust the sensitivity of GDELT towards specific use cases.  Those wishing to find the earliest \nglimmers of breaking events or reports of very small-bore events that tend to only appear as part of \nperiod “round up” reports, can use the entire event stream, while those wishing to find only the largest \nevents with strongly detailed descriptions, can filter the Event stream to find only those events with the \nhighest Confidence measures.  This allows the GDELT Event stream to be dynamically filtered for each \nindividual use case (learn more about the Confidence measure below).  It also makes it possible to \nidentify the “best” news report to return for a given event (filtering all mentions of an event for those \nwith the highest Confidence scores, most prominent positioning within the article, and/or in a specific \nsource language – such as Arabic coverage of a protest versus English coverage of that protest).', '\uf0b7 \nSingle Data File.  Previously there were two separate GKG data files, one containing Counts only \nand one containing the full GKG file.  The original rationale for having two separate files was that \nusers interested only in counts could download a much smaller daily file, but in practice nearly \nall applications use the full GKG file in order to make use of its thematic and other data fields to \ncontextualize those counts and to tie them into the GDELT Event Database.  Thus, we are \neliminating the separate counts-only file to simplify the GKG data environment. \n\uf0b7 \nProduction Status.  The GKG has now moved out of Alpha Experimental Release status and into \nproduction status.  This means that the file format is now stabilized and will not change. \n \nDIFFERENCES FROM GKG 2.0 \n \nThe GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were \nreleased in that format.  With the debut of the GKG 2.1 format in February 2015, the format has \nremained largely the same, but with the addition of several new fields to accommodate a number of \nsignificant enhancements to the GKG system.  While it was originally intended to release these new \nfeatures in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these \nfields, the desire to more closely align some of them with the format used for the Events dataset, and \nthe need to enable structural mapping of several of the fields to a forthcoming new hierarchical \nrepresentation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to \naccommodate these goals.  Users will find that code designed for the GKG 2.0 format can be adapted to \nthe GKG 2.1 format with minimal modification.  Since the GKG 2.0 format was only used for a handful of \nspecial subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 \ncompatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be \nsupported for news content.   \n \nFrom a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 \nrevolve around how entries are clustered and the minimum criteria for an article to be included in the \nGKG stream.  Under the GKG 1.0 format, a deduplication process similar to that used for the Event \nstream was applied to the daily GKG export, grouping together all articles yielding the same GKG \nmetadata.  Thus, two articles listing the same set of locations, themes, people, and organizations would \nbe grouped together in a single row with NumArticles holding a value of 2.  With the introduction of the \nnew GCAM system that assess more than 2,300 emotions and themes for each article, it became clear \nthat the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, \nthemes, people, and organizations might use very different language to discuss them, yielding very \ndifferent GCAM scores.  In addition, the introduction of realtime translation into the GDELT architecture \nnecessitated the ability to identify the provenance of metadata at the document level.  Thus, GKG 2.1 no \nlonger clusters documents together based on shared metadata – if 20 articles all contain the same list of \nextracted locations, themes, people, and organizations, they will appear as 20 separate entries in the \nGKG stream.  The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering.  \nIn addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article \nto appear in the GKG.  Under GKG 1.0 and 2.0, an article was required to have at least one successfully \nidentified and geocoded geographic location before it would be included in the GKG output.  However, \nmany topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy \ndiscussions, often do not have strong geographic centering, with many articles not mentioning even a \nsingle location.  This was excluding a considerable amount of content from the GKG system that is of \nhigh relevance to many GDELT user communities.  Thus, beginning with GKG 2.1, an article is included in \nthe GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional \nscores.  An article that contains no recognizable geographic mentions, but lists several political leaders,', 'THE GDELT GLOBAL KNOWLEDGE GRAPH (GKG) \nDATA FORMAT CODEBOOK V2.1 \n2/19/2015 \nhttp://gdeltproject.org/  \n \nINTRODUCTION \n \nThis codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands \nGDELT’s ability to quantify global human society beyond cataloging physical occurrences towards \nactually representing all of the latent dimensions, geography, and network structure of the global news.  \nIt applies an array of highly sophisticated natural language processing algorithms to each document to \ncompute a range of codified metadata encoding key latent and contextual dimensions of the document.  \nTo sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, \nnews source, and event across the planet into a single massive network that captures what’s happening \naround the world, what its context is and who’s involved, and how the world is feeling about it, every \nsingle day. \n \nIt has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system \non November 3, 2013 and in those fourteen months the GKG system has found application in an \nincredible number and diversity of fields.  The uniqueness of the GKG indicators in capturing the latent \ndimensions of society that precede physical unrest and their global scope has enabled truly \nunimaginable new applications.  We’ve learned a lot over the past year in terms of the features and \ncapabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we \nare both integrating those new features and moving the GKG into production status (from its original \nalpha status) in recognition of the widespread production use of the system today. \n \nDue to the vast number of use cases articulated for the GKG, a decision was made at its release to create \na raw output format that could be processed into the necessary refined formats for a wide array of \nsoftware packages and analysis needs and that would support a diverse assortment of extremely \ncomplex analytic needs in a single file.  Unlike the primary GDELT event stream, which is designed for \ndirect import into major statistical packages like R, the GKG file format requires more sophisticated \npreprocessing and users will likely want to make use of a scripting language like PERL or Python to \nextract and reprocess the data for import into a statistical package.  Thus, users may require more \nadvanced text processing and scripting language skills to work with the GKG data and additional nuance \nmay be required when thinking about how to incorporate these indicators into statistical models and \nnetwork and geographic constructs, as outlined in this codebook.  Encoding the GKG in XML, JSON, RDF, \nor other file formats significantly increases the on-disk footprint of the format due to its complexity and \nsize (thus why the GKG is only available in CSV format), though users requiring access to the GKG in \nthese formats can easily write a PERL or Python or similar script to translate the GKG format to any file \nformat needed.  The GKG is optimized for fast scanning, storing one record per line and using a tab-\ndelimited format to separate the fields. This makes it possible to use highly optimized fully parallelized \nstreamed parsing to rapidly process the GKG.  Similar to the 1.0 format, the files have a “.csv” ending, \ndespite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or \n“.tsv” endings for parsing tasks. \n \nThe new GKG format preserves most of the previous fields in their existing format for backwards \ncompatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but', 'EVENT TABLE \n \nEVENTID AND DATE ATTRIBUTES \n \nThe first few fields of an event record capture its globally unique identifier number, the date the event \ntook place on, and several alternatively formatted versions of the date designed to make it easier to \nwork with the event records in different analytical software programs that may have specific date \nformat requirements.  The parenthetical after each variable name gives the datatype of that field. \n \nNote that even though GDELT 2.0 operates at a 15 minute resolution, the date fields in this section still \nrecord the date at the daily level, since this is the resolution that event analysis has historically been \nperformed at.  To examine events at the 15 minute resolution, use the DATEADDED field (the second \nfrom the last field in this table at the end).  \n \n\uf0b7 \nGlobalEventID.  (integer) Globally unique identifier assigned to each event record that uniquely \nidentifies it in the master dataset.  NOTE: While these will often be sequential with date, this is \nNOT always the case and this field should NOT be used to sort events by date: the date fields \nshould be used for this.  NOTE: There is a large gap in the sequence between February 18, 2015 \nand February 19, 2015 with the switchover to GDELT 2.0 – these are not missing events, the ID \nsequence was simply reset at a higher number so that it is possible to easily distinguish events \ncreated after the switchover to GDELT 2.0 from those created using the older GDELT 1.0 system. \n\uf0b7 \nDay.  (integer) Date the event took place in YYYYMMDD format.  See DATEADDED field for \nYYYYMMDDHHMMSS date. \n\uf0b7 \nMonthYear.  (integer) Alternative formatting of the event date, in YYYYMM format. \n\uf0b7 \nYear.  (integer) Alternative formatting of the event date, in YYYY format. \n\uf0b7 \nFractionDate.  (floating point) Alternative formatting of the event date, computed as YYYY.FFFF, \nwhere FFFF is the percentage of the year completed by that day.  This collapses the month and \nday into a fractional range from 0 to 0.9999, capturing the 365 days of the year.  The fractional \ncomponent (FFFF) is computed as (MONTH * 30 + DAY) / 365.  This is an approximation and does \nnot correctly take into account the differing numbers of days in each month or leap years, but \noffers a simple single-number sorting mechanism for applications that wish to estimate the \nrough temporal distance between dates. \n \n \nACTOR ATTRIBUTES \n \nThe next fields describe attributes and characteristics of the two actors involved in the event.  This \nincludes the complete raw CAMEO code for each actor, its proper name, and associated attributes.  The \nraw CAMEO code for each actor contains an array of coded attributes indicating geographic, ethnic, and \nreligious affiliation and the actor’s role in the environment (political elite, military officer, rebel, etc).  \nThese 3-character codes may be combined in any order and are concatenated together to form the final \nraw actor CAMEO code.  To make it easier to utilize this information in analysis, this section breaks these \ncodes out into a set of individual fields that can be separately queried.  NOTE: all attributes in this \nsection other than CountryCode are derived from the TABARI ACTORS dictionary and are NOT \nsupplemented from information in the text.  Thus, if the text refers to a group as “Radicalized', 'adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening \nentirely new analytic opportunities.  Some of the most significant changes: \n \n\uf0b7 \nRealtime Measurement of 2,300 Emotions and Themes.  The GDELT Global Content Analysis \nMeasures (GCAM) module represents what we believe is the largest deployment of sentiment \nanalysis in the world: bringing together 24 emotional measurement packages that together \nassess more than 2,300 emotions and themes from every article in realtime, multilingual \ndimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, \nFrench, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and \nUrdu).  GCAM is designed to enable unparalleled assessment of the emotional undercurrents \nand reaction at a planetary scale by bringing together an incredible array of dimensions, from \nLIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”. \n\uf0b7 \nRealtime Translation of 65 Languages.  GDELT 2.0 brings with it the public debut of GDELT \nTranslingual, representing what we believe is the largest realtime streaming news machine \ntranslation deployment in the world: all global news that GDELT monitors in 65 languages, \nrepresenting 98.4% of its daily non-English monitoring volume, is translated in realtime into \nEnglish for processing through the entire GDELT Event and GKG/GCAM pipelines.  GDELT \nTranslingual is designed to allow GDELT to monitor the entire planet at full volume, creating the \nvery first glimpses of a world without language barriers.  The GKG system now processes every \nnews report monitored by GDELT across these 65 languages, making it possible to trace people, \norganizations, locations, themes, and emotions across languages and media systems. \n\uf0b7 \nRelevant Imagery, Videos, and Social Embeds.  A large fraction of the world’s news outlets now \nspecify a hand-selected image for each article to appear when it is shared via social media that \nrepresents the core focus of the article.  GDELT identifies this imagery in a wide array of formats \nincluding Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats.  In addition, \nGDELT also uses a set of highly specialized algorithms to analyze the article content itself to \nidentify inline imagery of high likely relevance to the story, along with videos and embedded \nsocial media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is \ncompiled.  This makes it possible to gain a unique ground-level view into emerging situations \nanywhere in the world, even in those areas with very little social media penetration, and to act \nas a kind of curated list of social posts in those areas with strong social use. \n\uf0b7 \nQuotes, Names, and Amounts.  The world’s news contains a wealth of information on food \nprices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable \nitem.  GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to \noffer numeric context to global events.  In parallel, a new Names engine augments the existing \nPerson and Organization names engines by identifying an array of other kinds of proper names, \nsuch as named events (Orange Revolution / Umbrella Movement), occurrences like the World \nCup, named dates like Holocaust Remembrance Day, on through named legislation like Iran \nNuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative.  Finally, \nGDELT also identifies attributable quotes from each article, making it possible to see the \nevolving language used by political leadership across the world. \n\uf0b7 \nDate Mentions.  We’ve heard from many of you the desire to encode the list of date references \nfound in news articles and documents in order to identify repeating mentions of specific dates \nas possible “anniversary violence” indicators.  All day, month, and year dates are now extracted \nfrom each document. \n\uf0b7 \nProximity Context.  Perhaps the greatest change to the overall format from version 1.0 is the \nintroduction of the new Proximity Context capability.  The GKG records an enormously rich array', 'or mentions an argument over constitutionalism or a forthcoming policy announcement, will now be \nincluded in the GKG stream.  Similarly, an article that has no recognizable metadata, but does yield \nGCAM emotional/thematic scores will also be included.  When processing GKG 2.1 files, users should \ntherefore be careful not to include any assumptions in their code as to whether an entry has extracted \ngeographic information and should check the contents of this field for mapping or other geographic \napplications. \n \n \nEXTRACTED FIELDS \n \nThe following section documents each of the fields contained in the GKG 2.1 format.  Note: the former \nformat had a NUMARTS field – this has been discontinued due to the new format’s support of multiple \ntypes of source collections beyond just news media and the requisite need to specify a source collection \nto interpret document identifiers in the new format (as discussed above).  Thus, if multiple documents \nhave identical computed metadata, in 1.0 format they would have been clustered together with \nNumArts used to indicate the multiple entries, while in the 2.1 format each document has a separate \nentry in the file.  Fields prefaced with “V1” indicate they are identical in format and population to the \nprevious GKG format.  Those prefaced with “V1.5” mean they are largely similar, but have some \nchanges.  Those prefaced with “V2” are new to the format.  Each row represents one document codified \nby the GKG and each row is tab-delimited for its major fields.  Note: the “V1/V1.5/V2” designations are \nnot included in the header row of the actual GKG output files.  Note:  the ordering of the fields in the file \nhas substantially changed from Version 2.0 to Version 2.1.  \n \n\uf0b7 \nGKGRECORDID.  (string)  Each GKG record is assigned a globally unique identifier.  Unlike the \nEVENT system, which uses semi-sequential numbering to assign numeric IDs to each event \nrecord, the GKG system uses a date-oriented serial number.  Each GKG record ID takes the form \n“YYYYMMDDHHMMSS-X” or “YYYYMMDDHHMMSS-TX” in which the first portion of the ID is the \nfull date+time of the 15 minute update batch that this record was created in, followed by a \ndash, followed by sequential numbering for all GKG records created as part of that update \nbatch.  Records originating from a document that was translated by GDELT Translingual will have \na capital “T” appearing immediately after the dash to allow filtering of English/non-English \nmaterial simply by its record identifier.  Thus, the fifth GKG record created as part of the update \nbatch generated at 3:30AM on February 3, 2015 would have a GKGRECORDID of \n“20150203033000-5” and if it was based on a French-language document that was translated, it \nwould have the ID “20150203033000-T5”.  This ID can be used to uniquely identify this \nparticular record across the entire GKG database.  Note that due to the presence of the dash, \nthis field should be treated as a string field and NOT as a numeric field. \n\uf0b7 \nV2.1DATE.  (integer)  This is the date in YYYYMMDDHHMMSS format on which the news media \nused to construct this GKG file was published.  NOTE that unlike the main GDELT event stream \nfiles, this date represents the date of publication of the document from which the information \nwas extracted – if the article discusses events in the past, the date is NOT time-shifted as it is for \nthe GDELT event stream.  This date will be the same for all rows in a file and is redundant from a \ndata processing standpoint, but is provided to make it easier to load GKG files directly into an \nSQL database for analysis.  NOTE: for some special collections this value may be 0 indicating that \nthe field is either not applicable or not known for those materials.  For example, OCR’d historical \ndocument collections may not have robust metadata on publication date.  NOTE: the GKG 2.0 \nformat still encoded this date in YYYYMMDD format, while under GKG 2.1 it is now in \nYYYYMMDDHHMMSS format.', 'of contextual details from the news, encoding not only the people, organizations, locations and \nevents driving the news, but also functional roles and underlying thematic context.  However, \nwith the previous GKG system it was difficult to associate those various data points together.   \nFor example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all \nappeared somewhere in an article together and that the United States and Russia appeared in \nthat article and that the roles of President and Secretary of State were mentioned in that article, \nbut there was no way to associate each person with the corresponding location and functional \nroles.  GKG 2.1 addresses this by providing the approximate character offset of each reference \nto an object in the original article.  While not allowing for deeper semantic association, this new \nfield allows for simple proximity-based contextualization.  In the case of the example article \nabove, the mention of United States likely occurs much closer to Barack Obama and John Kerry \nthan to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to \nthe others.  In this way, critical information on role, geographic, thematic association, and other \nconnectivity can be explored.  Pilot tests have already demonstrated that these proximity \nindicators can be highly effective at recovering these kinds of functional, thematic, and \ngeographic affiliations. \n\uf0b7 \nOver 100 New GKG Themes.  There are more than 100 new themes in the GDELT Global \nKnowledge Graph, ranging from economic indicators like price gouging and the price of heating \noil to infrastructure topics like the construction of new power generation capacity to social \nissues like marginalization and burning in effigy.  The list of recognized infectious diseases, \nethnic groups, and terrorism organizations has been considerably expanded, and more than 600 \nglobal humanitarian and development aid organizations have been added, along with global \ncurrencies and massive new taxonomies capturing global animals and plants to aid with tracking \nspecies migration and poaching. \n\uf0b7 \nExtensible XML Block.  GDELT has historically relied primarily on mainstream news coverage for \nits source material.    Whether from print, broadcast, or web-based mediums, news coverage \nacross the world is relatively consistent in the kinds of information it captures.  As GDELT \nencodes an ever-increasing range of materials, including academic journal articles and \ngovernment reports, additional types of information are available to codify.  As a first example \nof this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion \nwords of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and \nthe Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East.  Academic \nliterature contains a list of cited references at the bottom of each article that indicate the \npapers cited within that paper.  This citation list is extremely valuable in constructing citation \ngraphs over the literature to better understand trends and experts.  Yet, such citation lists are \nunique to this class of literature and will not be found in ordinary news material and thus it \nwould be cumbersome to add additional fields to the GKG file format to handle each of these \nkinds of specialized data types.  Instead, the GKG now includes a special field called \nV2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are \napplicable only to subsets of the collection.  Moving forward, this will allow the GKG to encode \nhighly specialized enhanced information from specialized input streams. \n\uf0b7 \nUnique Record Identifiers.  To bring the GKG in line with the practices of the GDELT Event \nDatabase, every GKG record is now assigned a unique identifier.  As with the event database, \nsequential identifiers do not indicate sequential events, but an identifier uniquely identifies a \nrecord across the entire collection.  The addition of unique record identifiers to the GKG will \nmake it easier to uniquely refer to a particular GKG record. \n                                                          \n1 http://dlib.org/dlib/september14/leetaru/09leetaru.html', 'stores reveals that the LLM independently recognizes Brandon Scott as the mayor of Baltimore. For all\nother questions, the language model cannot answer the posed questions by itself due to the recency of the\nbridge collapse.\nTo quantitatively evaluate the quality of the answers generated by our different question-answering methods,\nwe require a set of ground truth answers for the questions posed. Table 2 presents these manually curated\nground truth answers, representing the expected correct responses for each question used in our evalua-\ntion. These ground truth answers serve as the benchmark against which the performance of each system is\nmeasured.\nQuestion\nGround Truth\nWhat is the name of the Bridge that collapsed and\nwhat river was it on?\nThe Francis Scott Key Bridge on the Patapsco River.\nWhat is the name of the ship that collided with the\nbaltimore bridge?\nThe ship was named the Dali.\nHow many articles did CNN publish about the Bal-\ntimore bridge collapse?\nCNN published 5 articles.\nOn what date did the Baltimore Bridge collapse?\nThe collapse occurred on March 26, 2024.\nWho is Brandon Scott?\nBrandon Scott is the Mayor of Baltimore.\nWho is Niki Fennoy?\nNiki Fennoy is a city police spokesman.\nWhat are the top themes present in the data?\nThemes include maritime incidents, manmade disaster, and\nwater-related topics.\nTable 2: Ground Truth Answers for the Baltimore Bridge Collapse Questions\nTo further validate our qualitative findings, Figure 5 presents a quantitative comparison of the semantic\nsimilarity of answers generated by the five different methods when querying the GDELT dataset related\nto the Baltimore bridge collapse. We compute the quality of the result by calculating cosine similarity5, a\nmeasure of the similarity between the embeddings of the predicted answer and the ground truth, with higher\nvalues indicating greater accuracy. The box plots illustrate the distribution of these similarity scores for each\nmethod: Graph Query on DKG, G-Retriever on DKG, RAG using Vector Store, G-Retriever on LKG, and\nGraphRAG Q&A on GRKG. As our qualitative analysis suggested, methods leveraging direct graph queries\non the DKG, standard RAG with a vector store, and GraphRAG Q&A on the GRKG generally exhibit the\nhighest cosine similarity scores, providing quantitative evidence for their superior performance in generating\naccurate and relevant answers compared to the G-Retriever, especially with the LKG. This visualization\nquantitatively confirms the trends observed in the qualitative evaluation presented in Table 1.\n4\nConclusion\nThis work has taken the GDELT GKG database and introduced an ontology to create a knowledge graph\nwith rich structure. We found that while the large KG produced by the GDELT-GKG2 database has rich\ninformation for question-answering, the ad hoc techniques for graph exploration deem further investigation\nfor reliable use. That said, the information stored in the KG produced here is not without flaws, and we\nexpect the example studied here to be useful for the broader synergy between KGs and LLMs as addressed\nby others [18]. While the KGs produced using LlamaIndex captured a summary of the events surrounding\nthe Baltimore bridge collapse, the quality of the resulting structure was not suitable for question-answering.\nThose techniques incorporated into the GraphRAG package did considerably better, but there is room for\nimprovement for answering global questions, resolving duplicate entities, and incorporating ontologically-\nguided relation extraction. We believe the incorporation of the ontology into the relation extraction will\nhave the benefit of allowing tools such as GraphRAG to better answer quantitative questions that only the\nontology based KG pipeline (DKG) was able to answer (e.g., the number of articles published on a topic).\nLarge language models continue to be adapted to solve problems across domains, and the case study on the\nKG built here presents much opportunity for future development. In particular, the debate around using\n5The\nsemantic\nembeddings\nused\nto\ncalculate\nthe\ncosine\nsimilarity\nwere\ngenerated\nusing\nthe\nsentence-transformers/all-MiniLM-L6-v2 model from the Sentence Transformers library.\n9']","The key enhancements introduced in the GKG 2.1 format released in February 2015, as well as the relationship to the availability of GDELT 2.0 event records starting February 19, 2015, are as follows:

### Key Enhancements in GKG 2.1 Format (February 2015)

1. **Single Data File**:  
   - The previous approach of having two separate GKG files (one for counts only and one full file) was eliminated. Now, only a single comprehensive GKG file is provided, simplifying the data environment since most users require the full thematic and contextual data.

2. **Production Status**:  
   - The GKG system moved from Alpha Experimental Release status to production status, meaning the file format is now stable and will not change.

3. **No Document Clustering**:  
   - Unlike GKG 1.0, which clustered multiple articles with identical metadata into a single record (with a count of articles), GKG 2.1 treats each article as a separate entry. This change was necessary due to the introduction of the GCAM system, which assesses over 2,300 emotions and themes per article, making clustering based on shared metadata impractical.

4. **Relaxed Inclusion Criteria**:  
   - Previously (GKG 1.0 and 2.0), an article had to have at least one successfully identified and geocoded location to be included. GKG 2.1 includes articles even if they have no geographic mentions, as long as they contain any extracted information such as GCAM emotional scores or mentions of political leaders, policy discussions, etc. This broadens the scope of the GKG to include content relevant to topics without strong geographic focus (e.g., cybersecurity, constitutional discourse).

5. **New Fields and Structural Changes**:  
   - Several new fields were added to accommodate enhancements such as:
     - **Realtime measurement of 2,300 emotions and themes** via the GCAM module, covering 15 languages.
     - **Realtime translation of 65 languages** into English for processing.
     - **Inclusion of relevant imagery, videos, and social media embeds** linked to articles.
     - **Extraction of quotes, names, amounts, and date mentions** from articles.
     - **Proximity Context**: Approximate character offsets of references in articles to allow proximity-based contextualization of people, places, roles, and themes.
     - **Over 100 new GKG themes** including economic, social, infrastructure, and environmental topics.
     - **Extensible XML block (V2EXTRASXML)** for specialized data types (e.g., academic citations).
     - **Unique record identifiers** for each GKG record, aligning with GDELT Event Database practices.
   - The ordering of fields changed from GKG 2.0 to 2.1, but backward compatibility is largely maintained with minimal code modifications needed.

### Relationship to GDELT 2.0 Event Records Availability (Starting February 19, 2015)

- The GDELT 2.0 event records, which started being available from February 19, 2015, introduced a new event data format with enhanced features such as:
  - 15-minute resolution timestamps (though date fields remain daily for historical compatibility).
  - A new Mentions table recording every mention of an event across news reports, including confidence scores and mention prominence.
  - Reset of GlobalEventID numbering to distinguish GDELT 2.0 events from older GDELT 1.0 events.
  - Enhanced actor and event coding with more detailed breakdowns.

- The release of GKG 2.1 coincided with the rollout of GDELT 2.0 event records, reflecting a coordinated upgrade of the entire GDELT data ecosystem to support richer, more detailed, and more flexible data structures.

- Both GKG 2.1 and GDELT 2.0 formats emphasize:
  - Expanded multilingual and multimedia processing.
  - More granular and nuanced metadata extraction.
  - Improved data structure to support advanced analytics and real-time monitoring.

- While GDELT 2.0 event data is only available from February 19, 2015 onward, GKG 2.1 supports the new data environment by providing a stable, enriched, and more comprehensive knowledge graph that complements the event data.

### Summary

- **GKG 2.1** introduced a stable, production-ready format with richer metadata, no clustering of articles, relaxed geographic inclusion criteria, and new fields for emotions, themes, multimedia, and proximity context.  
- **GDELT 2.0 event records**, available from February 19, 2015, introduced a new event data format with finer temporal resolution, a Mentions table, and enhanced coding.  
- The availability of GDELT 2.0 event records aligns with and complements the GKG 2.1 enhancements, together enabling more powerful and nuanced analysis of global news and events.","The GKG 2.1 format, released in February 2015, introduced several key enhancements over the previous GKG 2.0 format, including the addition of new fields to support significant system improvements such as the GCAM system that assesses over 2,300 emotions and themes per article, and the removal of clustering of documents based on shared metadata. Unlike GKG 1.0 and 2.0, which required at least one geocoded location for article inclusion, GKG 2.1 includes articles with any successfully extracted information, including GCAM emotional scores, thereby broadening content coverage. Concurrently, GDELT 2.0 event records became available starting February 19, 2015, marking a transition to a new file format with expanded features such as a Mentions table and a Confidence measure for event identification. This timing aligns with the GKG 2.1 release, reflecting a broader upgrade in GDELT data formats to enhance real-time event tracking and metadata richness."
