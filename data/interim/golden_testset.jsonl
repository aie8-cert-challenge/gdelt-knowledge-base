{"user_input": "Can you explane the main differnces between GKG 1.0 and the newer versions in terms of data format and usage?", "reference_contexts": ["INTRODUCTION This codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands GDELT’s ability to quantify global human society beyond cataloging physical occurrences towards actually representing all of the latent dimensions, geography, and network structure of the global news. It applies an array of highly sophisticated natural language processing algorithms to each document to compute a range of codified metadata encoding key latent and contextual dimensions of the document. To sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, news source, and event across the planet into a single massive network that captures what’s happening around the world, what its context is and who’s involved, and how the world is feeling about it, every single day. It has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system on November 3, 2013 and in those fourteen months the GKG system has found application in an incredible number and diversity of fields. The uniqueness of the GKG indicators in capturing the latent dimensions of society that precede physical unrest and their global scope has enabled truly unimaginable new applications. We’ve learned a lot over the past year in terms of the features and capabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we are both integrating those new features and moving the GKG into production status (from its original alpha status) in recognition of the widespread production use of the system today. Due to the vast number of use cases articulated for the GKG, a decision was made at its release to create a raw output format that could be processed into the necessary refined formats for a wide array of software packages and analysis needs and that would support a diverse assortment of extremely complex analytic needs in a single file. Unlike the primary GDELT event stream, which is designed for direct import into major statistical packages like R, the GKG file format requires more sophisticated preprocessing and users will likely want to make use of a scripting language like PERL or Python to extract and reprocess the data for import into a statistical package. Thus, users may require more advanced text processing and scripting language skills to work with the GKG data and additional nuance may be required when thinking about how to incorporate these indicators into statistical models and network and geographic constructs, as outlined in this codebook. Encoding the GKG in XML, JSON, RDF, or other file formats significantly increases the on-disk footprint of the format due to its complexity and size (thus why the GKG is only available in CSV format), though users requiring access to the GKG in these formats can easily write a PERL or Python or similar script to translate the GKG format to any file format needed. The GKG is optimized for fast scanning, storing one record per line and using a tab- delimited format to separate the fields. This makes it possible to use highly optimized fully parallelized streamed parsing to rapidly process the GKG. Similar to the 1.0 format, the files have a “.csv” ending, despite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or “.tsv” endings for parsing tasks. The new GKG format preserves most of the previous fields in their existing format for backwards compatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but"], "reference": "The GKG 1.0 system was the original prototype introduced on November 3, 2013, and it has been used in a wide variety of fields due to its unique indicators capturing latent dimensions of society. The newer GKG Version 2.1 expands on this by integrating new features and moving the system into production status from its original alpha status. While the new format preserves most of the previous fields for backwards compatibility and continues to generate daily Version 1.0 files in parallel, the GKG 2.1 format is optimized for fast scanning using a tab-delimited CSV format with one record per line, enabling highly parallelized streamed parsing. Unlike the primary GDELT event stream, the GKG file format requires more sophisticated preprocessing, often needing scripting languages like PERL or Python to extract and reprocess data for statistical packages. Encoding the GKG in XML, JSON, RDF, or other formats significantly increases file size, so the GKG is only available in CSV format, though users can write scripts to convert it if needed.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "Can you explane how RID is used in the GDELT GCAM module for emotion analysis?", "reference_contexts": ["adds a series of new capabilities that greatly enhance what can be done with the GKG data, opening entirely new analytic opportunities. Some of the most significant changes:  Realtime Measurement of 2,300 Emotions and Themes. The GDELT Global Content Analysis Measures (GCAM) module represents what we believe is the largest deployment of sentiment analysis in the world: bringing together 24 emotional measurement packages that together assess more than 2,300 emotions and themes from every article in realtime, multilingual dimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, French, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and Urdu). GCAM is designed to enable unparalleled assessment of the emotional undercurrents and reaction at a planetary scale by bringing together an incredible array of dimensions, from LIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”.  Realtime Translation of 65 Languages. GDELT 2.0 brings with it the public debut of GDELT Translingual, representing what we believe is the largest realtime streaming news machine translation deployment in the world: all global news that GDELT monitors in 65 languages, representing 98.4% of its daily non-English monitoring volume, is translated in realtime into English for processing through the entire GDELT Event and GKG/GCAM pipelines. GDELT Translingual is designed to allow GDELT to monitor the entire planet at full volume, creating the very first glimpses of a world without language barriers. The GKG system now processes every news report monitored by GDELT across these 65 languages, making it possible to trace people, organizations, locations, themes, and emotions across languages and media systems.  Relevant Imagery, Videos, and Social Embeds. A large fraction of the world’s news outlets now specify a hand-selected image for each article to appear when it is shared via social media that represents the core focus of the article. GDELT identifies this imagery in a wide array of formats including Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats. In addition, GDELT also uses a set of highly specialized algorithms to analyze the article content itself to identify inline imagery of high likely relevance to the story, along with videos and embedded social media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is compiled. This makes it possible to gain a unique ground-level view into emerging situations anywhere in the world, even in those areas with very little social media penetration, and to act as a kind of curated list of social posts in those areas with strong social use.  Quotes, Names, and Amounts. The world’s news contains a wealth of information on food prices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable item. GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to offer numeric context to global events. In parallel, a new Names engine augments the existing Person and Organization names engines by identifying an array of other kinds of proper names, such as named events (Orange Revolution / Umbrella Movement), occurrences like the World Cup, named dates like Holocaust Remembrance Day, on through named legislation like Iran Nuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative. Finally, GDELT also identifies attributable quotes from each article, making it possible to see the evolving language used by political leadership across the world. "], "reference": "RID is one of the 24 emotional measurement packages integrated into the GDELT Global Content Analysis Measures (GCAM) module, which together assess more than 2,300 emotions and themes from every article in realtime. Specifically, RID contributes to measuring emotions such as \"Passivity\" within this large-scale sentiment analysis system.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "Could you elaborate on the significant changes introduced in version 1.0, particularly focusing on the new Proximity Context capability and its impact on encoding date mentions in news articles and documents?", "reference_contexts": ["Date Mentions. We’ve heard from many of you the desire to encode the list of date references found in news articles and documents in order to identify repeating mentions of specific dates as possible “anniversary violence” indicators. All day, month, and year dates are now extracted from each document.  Proximity Context. Perhaps the greatest change to the overall format from version 1.0 is the introduction of the new Proximity Context capability. The GKG records an enormously rich array"], "reference": "Version 1.0 introduced a major change with the addition of the Proximity Context capability, which represents the greatest change to the overall format. This version also enhanced the extraction of date mentions by encoding all day, month, and year dates found in news articles and documents. This allows for the identification of repeating mentions of specific dates, which can serve as potential indicators of \"anniversary violence.\" The Proximity Context capability enriches the Global Knowledge Graph (GKG) by recording a highly detailed array of contextual information around these date references.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "How does the GKG 2.1 system improve the association of John Kerry with his functional role and geographic context compared to the previous GKG system?", "reference_contexts": ["of contextual details from the news, encoding not only the people, organizations, locations and events driving the news, but also functional roles and underlying thematic context. However, with the previous GKG system it was difficult to associate those various data points together. For example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all appeared somewhere in an article together and that the United States and Russia appeared in that article and that the roles of President and Secretary of State were mentioned in that article, but there was no way to associate each person with the corresponding location and functional roles. GKG 2.1 addresses this by providing the approximate character offset of each reference to an object in the original article. While not allowing for deeper semantic association, this new field allows for simple proximity-based contextualization. In the case of the example article above, the mention of United States likely occurs much closer to Barack Obama and John Kerry than to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to the others. In this way, critical information on role, geographic, thematic association, and other connectivity can be explored. Pilot tests have already demonstrated that these proximity indicators can be highly effective at recovering these kinds of functional, thematic, and geographic affiliations.  Over 100 New GKG Themes. There are more than 100 new themes in the GDELT Global Knowledge Graph, ranging from economic indicators like price gouging and the price of heating oil to infrastructure topics like the construction of new power generation capacity to social issues like marginalization and burning in effigy. The list of recognized infectious diseases, ethnic groups, and terrorism organizations has been considerably expanded, and more than 600 global humanitarian and development aid organizations have been added, along with global currencies and massive new taxonomies capturing global animals and plants to aid with tracking species migration and poaching.  Extensible XML Block. GDELT has historically relied primarily on mainstream news coverage for its source material. Whether from print, broadcast, or web-based mediums, news coverage across the world is relatively consistent in the kinds of information it captures. As GDELT encodes an ever-increasing range of materials, including academic journal articles and government reports, additional types of information are available to codify. As a first example of this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion words of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and the Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East. Academic literature contains a list of cited references at the bottom of each article that indicate the papers cited within that paper. This citation list is extremely valuable in constructing citation graphs over the literature to better understand trends and experts. Yet, such citation lists are unique to this class of literature and will not be found in ordinary news material and thus it would be cumbersome to add additional fields to the GKG file format to handle each of these kinds of specialized data types. Instead, the GKG now includes a special field called V2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are applicable only to subsets of the collection. Moving forward, this will allow the GKG to encode highly specialized enhanced information from specialized input streams. "], "reference": "The GKG 2.1 system improves the association of John Kerry with his functional role and geographic context by providing the approximate character offset of each reference to an object in the original article. This allows for simple proximity-based contextualization, enabling the system to determine that mentions of the United States likely occur much closer to Barack Obama and John Kerry than to Vladimir Putin, and that the role of Secretary of State likely occurs much closer to John Kerry than to the others. While it does not allow for deeper semantic association, this proximity information helps explore critical details on role, geographic, thematic association, and other connectivity that were difficult to associate in the previous GKG system.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "how the GDELT Event Database integration improved by adding unique record identifiers to the GKG and why they remove the counts-only file in the GDELT Event Database context?", "reference_contexts": ["<1-hop>\n\n Single Data File. Previously there were two separate GKG data files, one containing Counts only and one containing the full GKG file. The original rationale for having two separate files was that users interested only in counts could download a much smaller daily file, but in practice nearly all applications use the full GKG file in order to make use of its thematic and other data fields to contextualize those counts and to tie them into the GDELT Event Database. Thus, we are eliminating the separate counts-only file to simplify the GKG data environment.  Production Status. The GKG has now moved out of Alpha Experimental Release status and into production status. This means that the file format is now stabilized and will not change.", "<2-hop>\n\nUnique Record Identifiers. To bring the GKG in line with the practices of the GDELT Event Database, every GKG record is now assigned a unique identifier. As with the event database, sequential identifiers do not indicate sequential events, but an identifier uniquely identifies a record across the entire collection. The addition of unique record identifiers to the GKG will make it easier to uniquely refer to a particular GKG record. 1 http://dlib.org/dlib/september14/leetaru/09leetaru.html"], "reference": "The GDELT Event Database integration improved by adding unique record identifiers to the GKG, aligning it with the event database practices. Each GKG record now has a unique identifier that allows for easy and unambiguous reference to particular records across the entire collection, even though the identifiers do not indicate sequential events. Additionally, the counts-only file was removed because most applications use the full GKG file to access thematic and other data fields that help contextualize counts and link them to the GDELT Event Database. Removing the separate counts-only file simplifies the GKG data environment.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "How does the Leetaru (2012) algorithm facilitate the extraction of both location and organization names from text, and what are the specific considerations mentioned for accurately identifying these entities?", "reference_contexts": ["<1-hop>\n\nproximity to it. If a theme is mentioned multiple times in a document, each mention will appear separately in this field.  V1LOCATIONS. (semicolon-delimited blocks, with pound symbol (“#”) delimited fields) This is a list of all locations found in the text, extracted through the Leetaru (2012) algorithm. 2 The algorithm is run in a more aggressive stance here than ordinary in order to extract every possible locative referent, so may have a slightly elevated level of false positives. NOTE: some locations have multiple accepted formal or informal names and this field is collapsed on name, rather than feature (since in some applications the understanding of a geographic feature differs based on which name was used to reference it). In cases where it is necessary to collapse by feature, the Geo_FeatureID column should be used, rather than the Geo_Fullname column. This is because the Geo_Fullname column captures the name of the location as expressed in the text and thus reflects differences in transliteration, alternative spellings, and alternative names for the same location. For example, Mecca is often spelled Makkah, while Jeddah is commonly spelled Jiddah or Jaddah. The Geo_Fullname column will reflect each of these different spellings, while the Geo_FeatureID column will resolve them all to the same unique GNS or GNIS feature identification number. For more information on the GNS and GNIS identifiers, see Leetaru (2012). 3 This field is identical in format and population as the corresponding field in the GKG 1.0 format. NOTE: there was an error in this field from 2/19/2015 through midday 3/1/2015 that caused the CountryCode field to list the wrong country code in some cases. o Location Type. (integer) This field specifies the geographic resolution of the match type and holds one of the following values: 1=COUNTRY (match was at the country level), 2=USSTATE (match was to a US state), 3=USCITY (match was to a US city or landmark), 4=WORLDCITY (match was to a city or landmark outside the US), 5=WORLDSTATE (match was to an Administrative Division 1 outside the US – roughly equivalent to a US state). This can be used to filter counts by geographic specificity, for example, extracting only those counts with a landmark-level geographic resolution for mapping. Note that matches with codes 1 (COUNTRY), 2 (USSTATE), and 5 (WORLDSTATE) will still provide a latitude/longitude pair, which will be the centroid of that country or state, but the FeatureID field below will contain its textual country or ADM1 code instead of a numeric featureid. o Location FullName. (text) This is the full human-readable name of the matched location. In the case of a country it is simply the country name. For US and World states it is in the format of “State, Country Name”, while for all other matches it is in the format of “City/Landmark, State, Country”. This can be used to label locations when placing counts on a map. Note: this field reflects the precise name used to refer to the location in the text itself, meaning it may contain multiple spellings of the same location – use the FeatureID column to determine whether two location names refer to the same place. o", "<2-hop>\n\nV1ORGANIZATIONS. (semicolon-delimited) This is the list of all company and organization names found in the text, extracted through the Leetaru (2012) algorithm. 7 This is a combination of corporations, IGOs, NGOs, and any other local organizations such as a local fair 4 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html 5 http://blog.gdeltproject.org/global-second-order-administrative-divisions-now-available-from-gaul/ 6 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html 7 http://www.dlib.org/dlib/september12/leetaru/09leetaru.html"], "reference": "The Leetaru (2012) algorithm is employed to extract both location and organization names from text. For locations, the algorithm is run in a more aggressive stance to capture every possible locative referent, which may result in a slightly elevated level of false positives. Locations are recorded with multiple accepted formal or informal names, and the Geo_Fullname column reflects the exact name as expressed in the text, including alternative spellings and transliterations. To resolve different spellings to a unique geographic feature, the Geo_FeatureID column is used. Location types are categorized by geographic resolution, such as country, US state, US city, world city, or world state, which aids in filtering and mapping. For organizations, the algorithm extracts a semicolon-delimited list of all company and organization names found in the text, including corporations, IGOs, NGOs, and local organizations. This combined extraction approach allows for detailed identification of entities within complex text datasets.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "how GKG data enhancements like realtime measurement of 2,300 emotions and themes relate to the GKG file format evolution from 2.0 to 2.1 and what changes in article inclusion criteria support these enhancements?", "reference_contexts": ["<1-hop>\n\nDIFFERENCES FROM GKG 2.0 The GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were released in that format. With the debut of the GKG 2.1 format in February 2015, the format has remained largely the same, but with the addition of several new fields to accommodate a number of significant enhancements to the GKG system. While it was originally intended to release these new features in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these fields, the desire to more closely align some of them with the format used for the Events dataset, and the need to enable structural mapping of several of the fields to a forthcoming new hierarchical representation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to accommodate these goals. Users will find that code designed for the GKG 2.0 format can be adapted to the GKG 2.1 format with minimal modification. Since the GKG 2.0 format was only used for a handful of special subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 compatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be supported for news content. From a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 revolve around how entries are clustered and the minimum criteria for an article to be included in the GKG stream. Under the GKG 1.0 format, a deduplication process similar to that used for the Event stream was applied to the daily GKG export, grouping together all articles yielding the same GKG metadata. Thus, two articles listing the same set of locations, themes, people, and organizations would be grouped together in a single row with NumArticles holding a value of 2. With the introduction of the new GCAM system that assess more than 2,300 emotions and themes for each article, it became clear that the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, themes, people, and organizations might use very different language to discuss them, yielding very different GCAM scores. In addition, the introduction of realtime translation into the GDELT architecture necessitated the ability to identify the provenance of metadata at the document level. Thus, GKG 2.1 no longer clusters documents together based on shared metadata – if 20 articles all contain the same list of extracted locations, themes, people, and organizations, they will appear as 20 separate entries in the GKG stream. The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering. In addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article to appear in the GKG. Under GKG 1.0 and 2.0, an article was required to have at least one successfully identified and geocoded geographic location before it would be included in the GKG output. However, many topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy discussions, often do not have strong geographic centering, with many articles not mentioning even a single location. This was excluding a considerable amount of content from the GKG system that is of high relevance to many GDELT user communities. Thus, beginning with GKG 2.1, an article is included in the GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional scores. An article that contains no recognizable geographic mentions, but lists several political leaders,", "<2-hop>\n\nadds a series of new capabilities that greatly enhance what can be done with the GKG data, opening entirely new analytic opportunities. Some of the most significant changes:  Realtime Measurement of 2,300 Emotions and Themes. The GDELT Global Content Analysis Measures (GCAM) module represents what we believe is the largest deployment of sentiment analysis in the world: bringing together 24 emotional measurement packages that together assess more than 2,300 emotions and themes from every article in realtime, multilingual dimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, French, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and Urdu). GCAM is designed to enable unparalleled assessment of the emotional undercurrents and reaction at a planetary scale by bringing together an incredible array of dimensions, from LIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”.  Realtime Translation of 65 Languages. GDELT 2.0 brings with it the public debut of GDELT Translingual, representing what we believe is the largest realtime streaming news machine translation deployment in the world: all global news that GDELT monitors in 65 languages, representing 98.4% of its daily non-English monitoring volume, is translated in realtime into English for processing through the entire GDELT Event and GKG/GCAM pipelines. GDELT Translingual is designed to allow GDELT to monitor the entire planet at full volume, creating the very first glimpses of a world without language barriers. The GKG system now processes every news report monitored by GDELT across these 65 languages, making it possible to trace people, organizations, locations, themes, and emotions across languages and media systems.  Relevant Imagery, Videos, and Social Embeds. A large fraction of the world’s news outlets now specify a hand-selected image for each article to appear when it is shared via social media that represents the core focus of the article. GDELT identifies this imagery in a wide array of formats including Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats. In addition, GDELT also uses a set of highly specialized algorithms to analyze the article content itself to identify inline imagery of high likely relevance to the story, along with videos and embedded social media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is compiled. This makes it possible to gain a unique ground-level view into emerging situations anywhere in the world, even in those areas with very little social media penetration, and to act as a kind of curated list of social posts in those areas with strong social use.  Quotes, Names, and Amounts. The world’s news contains a wealth of information on food prices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable item. GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to offer numeric context to global events. In parallel, a new Names engine augments the existing Person and Organization names engines by identifying an array of other kinds of proper names, such as named events (Orange Revolution / Umbrella Movement), occurrences like the World Cup, named dates like Holocaust Remembrance Day, on through named legislation like Iran Nuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative. Finally, GDELT also identifies attributable quotes from each article, making it possible to see the evolving language used by political leadership across the world. "], "reference": "The GKG file format evolved from 2.0 to 2.1 to accommodate significant enhancements in the GKG system, including the addition of several new fields designed to align with the Events dataset format and enable structural mapping for a new hierarchical representation. One major enhancement is the realtime measurement of more than 2,300 emotions and themes through the GCAM module, which assesses emotional undercurrents in multiple languages. To support this, the GKG 2.1 format no longer clusters documents based on shared metadata as in 1.0, allowing each article's unique GCAM scores to be preserved. Additionally, the minimum inclusion criteria changed: whereas GKG 1.0 and 2.0 required at least one geocoded location for an article to be included, GKG 2.1 includes any article with successfully extracted information, including GCAM emotional scores, even if no geographic mentions exist. These changes in the file format and inclusion criteria directly support the enhanced analytic capabilities introduced by the realtime emotion and theme measurements.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "how event sourcing with DATEADDED field help event tracking in mentions table when news report mention same event many times and how confidence in extraction important for tracking event sourcing and event tracking", "reference_contexts": ["<1-hop>\n\nFinally, a set of fields at the end of the record provide additional data management information for the event record.  DATEADDED. (integer) This field stores the date the event was added to the master database in YYYYMMDDHHMMSS format in the UTC timezone. For those needing to access events at 15 minute resolution, this is the field that should be used in queries.  SOURCEURL. (string) This field records the URL or citation of the first news report it found this event in. In most cases this is the first report it saw the article in, but due to the timing and flow of news reports through the processing pipeline, this may not always be the very first report, but is at least in the first few reports.", "<2-hop>\n\nMENTIONS TABLE The Mentions table is a new addition to GDELT 2.0 and records each mention of the events in the Event table, making it possible to track the trajectory and network structure of a story as it flows through the global media system. Each mention of an event receives its own entry in the Mentions table – thus an event which is mentioned in 100 articles will be listed 100 times in the Mentions table. Mentions are recorded irrespective of the date of the original event, meaning that a mention today of an event from a year ago will still be recorded, making it possible to trace discussion of “anniversary events” or historical events being recontextualized into present actions. If a news report mentions multiple events, each mention is recorded separately in this table. For translated documents, all measures below are based on its English translation. Several of the new measures recorded in the Mentions table make it possible to better filter events based on how confident GDELT was in its extraction of that event. When trying to understand news media spanning the entire globe, one finds that journalism is rife with ambiguities, assumed background knowledge, and complex linguistic structures. Not every event mention will take the form of “American President Barack Obama met with Russian President Vladimir Putin yesterday at a trade summit in Paris, France.” Instead, an event mention might more commonly appear as “Obama and Putin were in Paris yesterday for a trade summit. The two leaders met backstage where he discussed his policy on Ukraine.” To which of the two leader(s) do “he” and “his” refer? Is Obama discussing Obama’s policy on Ukraine, or is Obama discussing Putin’s policy on Ukraine, or is it Putin discussing Putin’s policy or perhaps Putin discussing Obama’s policy? While additional cues may be available in the surrounding text, ambiguous event mentions like this are exceptionally common across the world’s media. Similarly, it would be difficult indeed to maintain an exhaustive list of every single political figure in the entire world and thus context is often critical for disambiguating the geographic affiliation of an actor. Even in the case of more senior political leadership, a reference to “Renauld’s press conference this afternoon in Port-au-Prince” most likely refers to Lener Renauld, the Minister of Defense of Haiti, but this disambiguation still carries with it some degree of ambiguity. GDELT makes use of an array of natural language processing algorithms like coreference and deep parsing using whole-of-document context. While these enormously increase GDELT’s ability to understand and extract ambiguous and linguistically complex events, such extractions also come with a higher potential for error. Under GDELT 1.0, the NumMentions field as designed as a composite score of the absolute number of unique documents mentioning an event and the number of revisions to the text required by these various algorithms, up to six revision passes. Under GDELT 2.0, the Mentions table now separates these, with each record in the Mentions table recording an individual mention of an event in an article, while the new Confidence field"], "reference": "Event sourcing is supported by the DATEADDED field, which stores the date the event was added to the master database in YYYYMMDDHHMMSS format in UTC timezone, allowing queries at 15 minute resolution to access events precisely. This precise timestamping helps in event tracking within the Mentions table, which records each mention of events from the Event table, even if an event is mentioned multiple times across different articles or at different times. The Mentions table enables tracking the trajectory and network structure of a story as it flows through global media, including mentions of historical or anniversary events. Additionally, the Confidence field in the Mentions table is important because event mentions often contain linguistic ambiguities and complex references, making extraction challenging. GDELT uses natural language processing algorithms to disambiguate mentions, but this can introduce errors. Therefore, the Confidence measure helps filter and assess the reliability of event mentions, improving the accuracy of event sourcing and event tracking.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "how GKG 1.0 clustering and minimum article inclusion criteria different from GKG 2.0 and 2.1 and why these changes important for GKG system?", "reference_contexts": ["<1-hop>\n\nDIFFERENCES FROM GKG 2.0 The GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were released in that format. With the debut of the GKG 2.1 format in February 2015, the format has remained largely the same, but with the addition of several new fields to accommodate a number of significant enhancements to the GKG system. While it was originally intended to release these new features in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these fields, the desire to more closely align some of them with the format used for the Events dataset, and the need to enable structural mapping of several of the fields to a forthcoming new hierarchical representation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to accommodate these goals. Users will find that code designed for the GKG 2.0 format can be adapted to the GKG 2.1 format with minimal modification. Since the GKG 2.0 format was only used for a handful of special subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 compatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be supported for news content. From a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 revolve around how entries are clustered and the minimum criteria for an article to be included in the GKG stream. Under the GKG 1.0 format, a deduplication process similar to that used for the Event stream was applied to the daily GKG export, grouping together all articles yielding the same GKG metadata. Thus, two articles listing the same set of locations, themes, people, and organizations would be grouped together in a single row with NumArticles holding a value of 2. With the introduction of the new GCAM system that assess more than 2,300 emotions and themes for each article, it became clear that the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, themes, people, and organizations might use very different language to discuss them, yielding very different GCAM scores. In addition, the introduction of realtime translation into the GDELT architecture necessitated the ability to identify the provenance of metadata at the document level. Thus, GKG 2.1 no longer clusters documents together based on shared metadata – if 20 articles all contain the same list of extracted locations, themes, people, and organizations, they will appear as 20 separate entries in the GKG stream. The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering. In addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article to appear in the GKG. Under GKG 1.0 and 2.0, an article was required to have at least one successfully identified and geocoded geographic location before it would be included in the GKG output. However, many topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy discussions, often do not have strong geographic centering, with many articles not mentioning even a single location. This was excluding a considerable amount of content from the GKG system that is of high relevance to many GDELT user communities. Thus, beginning with GKG 2.1, an article is included in the GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional scores. An article that contains no recognizable geographic mentions, but lists several political leaders,", "<2-hop>\n\nINTRODUCTION This codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands GDELT’s ability to quantify global human society beyond cataloging physical occurrences towards actually representing all of the latent dimensions, geography, and network structure of the global news. It applies an array of highly sophisticated natural language processing algorithms to each document to compute a range of codified metadata encoding key latent and contextual dimensions of the document. To sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, news source, and event across the planet into a single massive network that captures what’s happening around the world, what its context is and who’s involved, and how the world is feeling about it, every single day. It has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system on November 3, 2013 and in those fourteen months the GKG system has found application in an incredible number and diversity of fields. The uniqueness of the GKG indicators in capturing the latent dimensions of society that precede physical unrest and their global scope has enabled truly unimaginable new applications. We’ve learned a lot over the past year in terms of the features and capabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we are both integrating those new features and moving the GKG into production status (from its original alpha status) in recognition of the widespread production use of the system today. Due to the vast number of use cases articulated for the GKG, a decision was made at its release to create a raw output format that could be processed into the necessary refined formats for a wide array of software packages and analysis needs and that would support a diverse assortment of extremely complex analytic needs in a single file. Unlike the primary GDELT event stream, which is designed for direct import into major statistical packages like R, the GKG file format requires more sophisticated preprocessing and users will likely want to make use of a scripting language like PERL or Python to extract and reprocess the data for import into a statistical package. Thus, users may require more advanced text processing and scripting language skills to work with the GKG data and additional nuance may be required when thinking about how to incorporate these indicators into statistical models and network and geographic constructs, as outlined in this codebook. Encoding the GKG in XML, JSON, RDF, or other file formats significantly increases the on-disk footprint of the format due to its complexity and size (thus why the GKG is only available in CSV format), though users requiring access to the GKG in these formats can easily write a PERL or Python or similar script to translate the GKG format to any file format needed. The GKG is optimized for fast scanning, storing one record per line and using a tab- delimited format to separate the fields. This makes it possible to use highly optimized fully parallelized streamed parsing to rapidly process the GKG. Similar to the 1.0 format, the files have a “.csv” ending, despite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or “.tsv” endings for parsing tasks. The new GKG format preserves most of the previous fields in their existing format for backwards compatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but"], "reference": "The GKG 1.0 format applied a deduplication process that clustered together all articles yielding the same GKG metadata, grouping them into a single row with a NumArticles count. In contrast, GKG 2.1 no longer clusters documents based on shared metadata; instead, each article appears as a separate entry even if they share the same locations, themes, people, and organizations. This change was necessary because the new GCAM system assesses over 2,300 emotions and themes per article, and articles with the same metadata might have very different GCAM scores. Additionally, real-time translation required identifying metadata provenance at the document level. Regarding minimum inclusion criteria, under GKG 1.0 and 2.0, an article had to have at least one successfully identified and geocoded geographic location to be included. However, many important topics lack strong geographic centering and were excluded. Starting with GKG 2.1, an article is included if it contains any successfully extracted information, including GCAM emotional scores, even if no geographic mentions are present. These changes are important because they allow the GKG system to better capture the full range of relevant content and metadata, improving its ability to represent global human society and support diverse analytic needs.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
{"user_input": "How do the unique record identifiers in the GKG align with the GDELT Event Database, and what role do the Confidence measures in the GDELT Event records play in filtering events for different use cases?", "reference_contexts": ["<1-hop>\n\nUnique Record Identifiers. To bring the GKG in line with the practices of the GDELT Event Database, every GKG record is now assigned a unique identifier. As with the event database, sequential identifiers do not indicate sequential events, but an identifier uniquely identifies a record across the entire collection. The addition of unique record identifiers to the GKG will make it easier to uniquely refer to a particular GKG record. 1 http://dlib.org/dlib/september14/leetaru/09leetaru.html", "<2-hop>\n\nINTRODUCTION This codebook provides a quick overview of the fields in the GDELT Event file format and their descriptions. GDELT Event records are stored in an expanded version of the dyadic CAMEO format, capturing two actors and the action performed by Actor1 upon Actor2. A wide array of variables break out the raw CAMEO actor codes into their respective fields to make it easier to interact with the data, the Action codes are broken out into their hierarchy, the Goldstein ranking score is provided, a unique array of georeferencing fields offer estimated landmark-centroid-level geographic positioning of both actors and the location of the action, and a new “Mentions” table records the network trajectory of the story of each event “in flight” through the global media system. At present, only records from February 19, 2015 onwards are available in the GDELT 2.0 file format, however in late Spring 2015 the entire historical backfile back to 1979 will be released in the GDELT 2.0 format. The Records are stored one per line, separated by a newline (\\n) and are tab-delimited (note that files have a “.csv” extension, but are actually tab-delimited). With the release of GDELT 2.0, the daily GDELT 1.0 Event files will still be generated each morning at least through the end of Spring 2015 to enable existing applications to continue to function without modification. Please note that at present, since GDELT 2.0 files are only available for events beginning February 19, 2015, you will need to use GDELT 1.0 to examine longitudinal patterns (since it stretches back to January 1, 1979) and use GDELT 2.0 moving forward for realtime events. There are now two data tables created every 15 minutes for the GDELT Event dataset. The first is the traditional Event table. This table is largely identical to the GDELT 1.0 format, but does have several changes as noted below. In addition to the Event table there is now a new Mentions table that records all mentions of each event. As an event is mentioned across multiple news reports, each of those mentions is recorded in the Mentions table, along with several key indicators about that mention, including the location within the article where the mention appeared (in the lead paragraph versus being buried at the bottom) and the “confidence” of the algorithms in their identification of the event from that specific news report. The Confidence measure is a new feature in GDELT 2.0 that makes it possible to adjust the sensitivity of GDELT towards specific use cases. Those wishing to find the earliest glimmers of breaking events or reports of very small-bore events that tend to only appear as part of period “round up” reports, can use the entire event stream, while those wishing to find only the largest events with strongly detailed descriptions, can filter the Event stream to find only those events with the highest Confidence measures. This allows the GDELT Event stream to be dynamically filtered for each individual use case (learn more about the Confidence measure below). It also makes it possible to identify the “best” news report to return for a given event (filtering all mentions of an event for those with the highest Confidence scores, most prominent positioning within the article, and/or in a specific source language – such as Arabic coverage of a protest versus English coverage of that protest)."], "reference": "The unique record identifiers in the GKG are assigned to each record to align with the practices of the GDELT Event Database, where every record is uniquely identified across the entire collection, although sequential identifiers do not indicate sequential events. This addition makes it easier to uniquely refer to a particular GKG record. In the GDELT Event records, the Confidence measure is a new feature introduced in GDELT 2.0 that allows users to adjust the sensitivity of the dataset towards specific use cases. It enables filtering of the Event stream to find only the largest events with strongly detailed descriptions by selecting those with the highest Confidence measures, or to include smaller events by using the entire event stream. This dynamic filtering helps identify the 'best' news report for a given event by considering factors such as the highest Confidence scores, prominence within the article, and source language.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
{"user_input": "how GDELT Global Knowledge Graph 2.1 improve role and location association and what new features it bring to GDELT Global Knowledge Graph?", "reference_contexts": ["<1-hop>\n\nof contextual details from the news, encoding not only the people, organizations, locations and events driving the news, but also functional roles and underlying thematic context. However, with the previous GKG system it was difficult to associate those various data points together. For example, an article might record that Barack Obama, John Kerry, and Vladimir Putin all appeared somewhere in an article together and that the United States and Russia appeared in that article and that the roles of President and Secretary of State were mentioned in that article, but there was no way to associate each person with the corresponding location and functional roles. GKG 2.1 addresses this by providing the approximate character offset of each reference to an object in the original article. While not allowing for deeper semantic association, this new field allows for simple proximity-based contextualization. In the case of the example article above, the mention of United States likely occurs much closer to Barack Obama and John Kerry than to Vladimir Putin, while Secretary of State likely occurs much closer to John Kerry than to the others. In this way, critical information on role, geographic, thematic association, and other connectivity can be explored. Pilot tests have already demonstrated that these proximity indicators can be highly effective at recovering these kinds of functional, thematic, and geographic affiliations.  Over 100 New GKG Themes. There are more than 100 new themes in the GDELT Global Knowledge Graph, ranging from economic indicators like price gouging and the price of heating oil to infrastructure topics like the construction of new power generation capacity to social issues like marginalization and burning in effigy. The list of recognized infectious diseases, ethnic groups, and terrorism organizations has been considerably expanded, and more than 600 global humanitarian and development aid organizations have been added, along with global currencies and massive new taxonomies capturing global animals and plants to aid with tracking species migration and poaching.  Extensible XML Block. GDELT has historically relied primarily on mainstream news coverage for its source material. Whether from print, broadcast, or web-based mediums, news coverage across the world is relatively consistent in the kinds of information it captures. As GDELT encodes an ever-increasing range of materials, including academic journal articles and government reports, additional types of information are available to codify. As a first example of this, Leetaru, Perkins and Rewerts (2014) 1 apply the GKG to encode more than 21 billion words of academic literature, including the entire contents of JSTOR, DTIC, CORE, CireSeerX, and the Internet Archive’s 1.6 billion PDFs relevant to Africa and the Middle East. Academic literature contains a list of cited references at the bottom of each article that indicate the papers cited within that paper. This citation list is extremely valuable in constructing citation graphs over the literature to better understand trends and experts. Yet, such citation lists are unique to this class of literature and will not be found in ordinary news material and thus it would be cumbersome to add additional fields to the GKG file format to handle each of these kinds of specialized data types. Instead, the GKG now includes a special field called V2EXTRASXML that is XML formatted and includes these kinds of specialized data types that are applicable only to subsets of the collection. Moving forward, this will allow the GKG to encode highly specialized enhanced information from specialized input streams. ", "<2-hop>\n\nINTRODUCTION This codebook introduces the GDELT Global Knowledge Graph (GKG) Version 2.1, which expands GDELT’s ability to quantify global human society beyond cataloging physical occurrences towards actually representing all of the latent dimensions, geography, and network structure of the global news. It applies an array of highly sophisticated natural language processing algorithms to each document to compute a range of codified metadata encoding key latent and contextual dimensions of the document. To sum up the GKG in a single sentence, it connects every person, organization, location, count, theme, news source, and event across the planet into a single massive network that captures what’s happening around the world, what its context is and who’s involved, and how the world is feeling about it, every single day. It has been just short of sixteen months since the original prototype introduction of the GKG 1.0 system on November 3, 2013 and in those fourteen months the GKG system has found application in an incredible number and diversity of fields. The uniqueness of the GKG indicators in capturing the latent dimensions of society that precede physical unrest and their global scope has enabled truly unimaginable new applications. We’ve learned a lot over the past year in terms of the features and capabilities of greatest interest to the GKG community, and with this Version 2.1 release of the GKG, we are both integrating those new features and moving the GKG into production status (from its original alpha status) in recognition of the widespread production use of the system today. Due to the vast number of use cases articulated for the GKG, a decision was made at its release to create a raw output format that could be processed into the necessary refined formats for a wide array of software packages and analysis needs and that would support a diverse assortment of extremely complex analytic needs in a single file. Unlike the primary GDELT event stream, which is designed for direct import into major statistical packages like R, the GKG file format requires more sophisticated preprocessing and users will likely want to make use of a scripting language like PERL or Python to extract and reprocess the data for import into a statistical package. Thus, users may require more advanced text processing and scripting language skills to work with the GKG data and additional nuance may be required when thinking about how to incorporate these indicators into statistical models and network and geographic constructs, as outlined in this codebook. Encoding the GKG in XML, JSON, RDF, or other file formats significantly increases the on-disk footprint of the format due to its complexity and size (thus why the GKG is only available in CSV format), though users requiring access to the GKG in these formats can easily write a PERL or Python or similar script to translate the GKG format to any file format needed. The GKG is optimized for fast scanning, storing one record per line and using a tab- delimited format to separate the fields. This makes it possible to use highly optimized fully parallelized streamed parsing to rapidly process the GKG. Similar to the 1.0 format, the files have a “.csv” ending, despite being tab-delimited, to address issues with some software packages that cannot handle “.txt” or “.tsv” endings for parsing tasks. The new GKG format preserves most of the previous fields in their existing format for backwards compatibility (and we will continue to generate the daily Version 1.0 files in parallel into the future), but"], "reference": "GDELT Global Knowledge Graph 2.1 improves role and location association by providing the approximate character offset of each reference to an object in the original article, allowing simple proximity-based contextualization. This means mentions of people, locations, and roles can be associated based on how close they appear in the text, enabling exploration of functional, thematic, and geographic affiliations. Additionally, GKG 2.1 introduces over 100 new themes covering economic, infrastructure, social issues, and expanded taxonomies including infectious diseases, ethnic groups, terrorism organizations, humanitarian aid organizations, global currencies, and species tracking. It also includes an extensible XML block called V2EXTRASXML to encode specialized data types from sources like academic literature, enhancing the ability to represent complex and specialized information within the GKG framework.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
{"user_input": "how GCAM real-time measurement of 2,300 emotions and themes affect the changes in GKG 2.1 format and its article inclusion criteria?", "reference_contexts": ["<1-hop>\n\nadds a series of new capabilities that greatly enhance what can be done with the GKG data, opening entirely new analytic opportunities. Some of the most significant changes:  Realtime Measurement of 2,300 Emotions and Themes. The GDELT Global Content Analysis Measures (GCAM) module represents what we believe is the largest deployment of sentiment analysis in the world: bringing together 24 emotional measurement packages that together assess more than 2,300 emotions and themes from every article in realtime, multilingual dimensions natively assessing the emotions of 15 languages (Arabic, Basque, Catalan, Chinese, French, Galician, German, Hindi, Indonesian, Korean, Pashto, Portuguese, Russian, Spanish, and Urdu). GCAM is designed to enable unparalleled assessment of the emotional undercurrents and reaction at a planetary scale by bringing together an incredible array of dimensions, from LIWC’s “Anxiety” to Lexicoder’s “Positivity” to WordNet Affect’s “Smugness” to RID’s “Passivity”.  Realtime Translation of 65 Languages. GDELT 2.0 brings with it the public debut of GDELT Translingual, representing what we believe is the largest realtime streaming news machine translation deployment in the world: all global news that GDELT monitors in 65 languages, representing 98.4% of its daily non-English monitoring volume, is translated in realtime into English for processing through the entire GDELT Event and GKG/GCAM pipelines. GDELT Translingual is designed to allow GDELT to monitor the entire planet at full volume, creating the very first glimpses of a world without language barriers. The GKG system now processes every news report monitored by GDELT across these 65 languages, making it possible to trace people, organizations, locations, themes, and emotions across languages and media systems.  Relevant Imagery, Videos, and Social Embeds. A large fraction of the world’s news outlets now specify a hand-selected image for each article to appear when it is shared via social media that represents the core focus of the article. GDELT identifies this imagery in a wide array of formats including Open Graph, Twitter Cards, Google+, IMAGE_SRC, and SailThru formats. In addition, GDELT also uses a set of highly specialized algorithms to analyze the article content itself to identify inline imagery of high likely relevance to the story, along with videos and embedded social media posts (such as embedded Tweets or YouTube or Vine videos), a list of which is compiled. This makes it possible to gain a unique ground-level view into emerging situations anywhere in the world, even in those areas with very little social media penetration, and to act as a kind of curated list of social posts in those areas with strong social use.  Quotes, Names, and Amounts. The world’s news contains a wealth of information on food prices, aid promises, numbers of troops, tanks, and protesters, and nearly any other countable item. GDELT 2.0 now attempts to compile a list of all “amounts” expressed in each article to offer numeric context to global events. In parallel, a new Names engine augments the existing Person and Organization names engines by identifying an array of other kinds of proper names, such as named events (Orange Revolution / Umbrella Movement), occurrences like the World Cup, named dates like Holocaust Remembrance Day, on through named legislation like Iran Nuclear Weapon Free Act, Affordable Care Act and Rouge National Urban Park Initiative. Finally, GDELT also identifies attributable quotes from each article, making it possible to see the evolving language used by political leadership across the world. ", "<2-hop>\n\nDIFFERENCES FROM GKG 2.0 The GKG 2.0 file format debuted in September 2014 and several special subcollection datasets were released in that format. With the debut of the GKG 2.1 format in February 2015, the format has remained largely the same, but with the addition of several new fields to accommodate a number of significant enhancements to the GKG system. While it was originally intended to release these new features in the GKG 2.0 format through the V2EXTRASXML field, the integral nature of several of these fields, the desire to more closely align some of them with the format used for the Events dataset, and the need to enable structural mapping of several of the fields to a forthcoming new hierarchical representation, necessitated an upgrade to the GKG file format to the new GKG 2.1 format to accommodate these goals. Users will find that code designed for the GKG 2.0 format can be adapted to the GKG 2.1 format with minimal modification. Since the GKG 2.0 format was only used for a handful of special subcollection datasets and never made an appearance for the daily news content, a GKG 2.0 compatibility feed will not be made available and only the GKG 1.0 and GKG 2.1 formats will be supported for news content. From a conceptual standpoint, two critical differences between the GKG 2.1/2.0 format and the GKG 1.0 revolve around how entries are clustered and the minimum criteria for an article to be included in the GKG stream. Under the GKG 1.0 format, a deduplication process similar to that used for the Event stream was applied to the daily GKG export, grouping together all articles yielding the same GKG metadata. Thus, two articles listing the same set of locations, themes, people, and organizations would be grouped together in a single row with NumArticles holding a value of 2. With the introduction of the new GCAM system that assess more than 2,300 emotions and themes for each article, it became clear that the GKG 1.0 approach would no longer work, since multiple articles yielding the same locations, themes, people, and organizations might use very different language to discuss them, yielding very different GCAM scores. In addition, the introduction of realtime translation into the GDELT architecture necessitated the ability to identify the provenance of metadata at the document level. Thus, GKG 2.1 no longer clusters documents together based on shared metadata – if 20 articles all contain the same list of extracted locations, themes, people, and organizations, they will appear as 20 separate entries in the GKG stream. The daily GKG 1.0 compatibility stream will, however, still continue to perform clustering. In addition to the clustering change, GKG 2.1 also changes the minimum inclusion criteria for an article to appear in the GKG. Under GKG 1.0 and 2.0, an article was required to have at least one successfully identified and geocoded geographic location before it would be included in the GKG output. However, many topics monitored by GDELT, such as cybersecurity, constitutional discourse, and major policy discussions, often do not have strong geographic centering, with many articles not mentioning even a single location. This was excluding a considerable amount of content from the GKG system that is of high relevance to many GDELT user communities. Thus, beginning with GKG 2.1, an article is included in the GKG stream if it includes ANY successfully extracted information, INCLUDING GCAM emotional scores. An article that contains no recognizable geographic mentions, but lists several political leaders,"], "reference": "The GCAM module adds real-time measurement of more than 2,300 emotions and themes to the GKG data, representing the largest deployment of sentiment analysis in the world. This capability required significant changes in the GKG 2.1 format compared to earlier versions. Specifically, because multiple articles with the same locations, themes, people, and organizations might express very different language and thus yield very different GCAM scores, the previous clustering approach used in GKG 1.0 was no longer suitable. Therefore, GKG 2.1 no longer clusters documents based on shared metadata; instead, each article appears as a separate entry to preserve the distinct GCAM emotional assessments. Additionally, the inclusion criteria for articles in GKG 2.1 were changed to allow articles without any geocoded geographic location to be included if they contain any successfully extracted information, including GCAM emotional scores. This change enables the system to capture a broader range of relevant content, such as articles on cybersecurity or policy discussions that lack geographic mentions but have important emotional and thematic data measured by GCAM.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
